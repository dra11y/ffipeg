// ignore_for_file: type=lint, doc_directive_unknown, unused_field, unused_element

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
import 'dart:ffi' as ffi;

/// FFmpeg bindings generated using ffipeg
class FFmpeg {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  FFmpeg(ffi.DynamicLibrary dynamicLibrary) : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  FFmpeg.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  /// Rescale a 64-bit integer by 2 rational numbers.
  ///
  /// The operation is mathematically equivalent to `a * bq / cq`.
  ///
  /// This function is equivalent to av_rescale_q_rnd() with #AV_ROUND_NEAR_INF.
  ///
  /// @see av_rescale(), av_rescale_rnd(), av_rescale_q_rnd()
  int av_rescale_q(
    int a,
    AVRational bq,
    AVRational cq,
  ) {
    return _av_rescale_q(
      a,
      bq,
      cq,
    );
  }

  late final _av_rescale_qPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Int64, AVRational, AVRational)>>('av_rescale_q');
  late final _av_rescale_q =
      _av_rescale_qPtr.asFunction<int Function(int, AVRational, AVRational)>();

  /// Rescale a 64-bit integer by 2 rational numbers with specified rounding.
  ///
  /// The operation is mathematically equivalent to `a * bq / cq`.
  ///
  /// @see av_rescale(), av_rescale_rnd(), av_rescale_q()
  int av_rescale_q_rnd(
    int a,
    AVRational bq,
    AVRational cq,
    AVRounding rnd,
  ) {
    return _av_rescale_q_rnd(
      a,
      bq,
      cq,
      rnd.value,
    );
  }

  late final _av_rescale_q_rndPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Int64, AVRational, AVRational,
              ffi.UnsignedInt)>>('av_rescale_q_rnd');
  late final _av_rescale_q_rnd = _av_rescale_q_rndPtr
      .asFunction<int Function(int, AVRational, AVRational, int)>();

  /// Compare two timestamps each in its own time base.
  ///
  /// @return One of the following values:
  /// - -1 if `ts_a` is before `ts_b`
  /// - 1 if `ts_a` is after `ts_b`
  /// - 0 if they represent the same position
  ///
  /// @warning
  /// The result of the function is undefined if one of the timestamps is outside
  /// the `int64_t` range when represented in the other's timebase.
  int av_compare_ts(
    int ts_a,
    AVRational tb_a,
    int ts_b,
    AVRational tb_b,
  ) {
    return _av_compare_ts(
      ts_a,
      tb_a,
      ts_b,
      tb_b,
    );
  }

  late final _av_compare_tsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int64, AVRational, ffi.Int64, AVRational)>>('av_compare_ts');
  late final _av_compare_ts = _av_compare_tsPtr
      .asFunction<int Function(int, AVRational, int, AVRational)>();

  /// Allocate an AVPacket and set its fields to default values.  The resulting
  /// struct must be freed using av_packet_free().
  ///
  /// @return An AVPacket filled with default values or NULL on failure.
  ///
  /// @note this only allocates the AVPacket itself, not the data buffers. Those
  /// must be allocated through other means such as av_new_packet.
  ///
  /// @see av_new_packet
  ffi.Pointer<AVPacket> av_packet_alloc() {
    return _av_packet_alloc();
  }

  late final _av_packet_allocPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<AVPacket> Function()>>(
          'av_packet_alloc');
  late final _av_packet_alloc =
      _av_packet_allocPtr.asFunction<ffi.Pointer<AVPacket> Function()>();

  /// Free the packet, if the packet is reference counted, it will be
  /// unreferenced first.
  ///
  /// @param pkt packet to be freed. The pointer will be set to NULL.
  /// @note passing NULL is a no-op.
  void av_packet_free(
    ffi.Pointer<ffi.Pointer<AVPacket>> pkt,
  ) {
    return _av_packet_free(
      pkt,
    );
  }

  late final _av_packet_freePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Pointer<AVPacket>>)>>('av_packet_free');
  late final _av_packet_free = _av_packet_freePtr
      .asFunction<void Function(ffi.Pointer<ffi.Pointer<AVPacket>>)>();

  /// Wipe the packet.
  ///
  /// Unreference the buffer referenced by the packet and reset the
  /// remaining packet fields to their default values.
  ///
  /// @param pkt The packet to be unreferenced.
  void av_packet_unref(
    ffi.Pointer<AVPacket> pkt,
  ) {
    return _av_packet_unref(
      pkt,
    );
  }

  late final _av_packet_unrefPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<AVPacket>)>>(
          'av_packet_unref');
  late final _av_packet_unref =
      _av_packet_unrefPtr.asFunction<void Function(ffi.Pointer<AVPacket>)>();

  /// Convert valid timing fields (timestamps / durations) in a packet from one
  /// timebase to another. Timestamps with unknown values (AV_NOPTS_VALUE) will be
  /// ignored.
  ///
  /// @param pkt packet on which the conversion will be performed
  /// @param tb_src source timebase, in which the timing fields in pkt are
  /// expressed
  /// @param tb_dst destination timebase, to which the timing fields will be
  /// converted
  void av_packet_rescale_ts(
    ffi.Pointer<AVPacket> pkt,
    AVRational tb_src,
    AVRational tb_dst,
  ) {
    return _av_packet_rescale_ts(
      pkt,
      tb_src,
      tb_dst,
    );
  }

  late final _av_packet_rescale_tsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<AVPacket>, AVRational,
              AVRational)>>('av_packet_rescale_ts');
  late final _av_packet_rescale_ts = _av_packet_rescale_tsPtr.asFunction<
      void Function(ffi.Pointer<AVPacket>, AVRational, AVRational)>();

  /// Copy the contents of src to dst. Any allocated fields in dst are freed and
  /// replaced with newly allocated duplicates of the corresponding fields in src.
  ///
  /// @return >= 0 on success, a negative AVERROR code on failure.
  int avcodec_parameters_copy(
    ffi.Pointer<AVCodecParameters> dst,
    ffi.Pointer<AVCodecParameters> src,
  ) {
    return _avcodec_parameters_copy(
      dst,
      src,
    );
  }

  late final _avcodec_parameters_copyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<AVCodecParameters>,
              ffi.Pointer<AVCodecParameters>)>>('avcodec_parameters_copy');
  late final _avcodec_parameters_copy = _avcodec_parameters_copyPtr.asFunction<
      int Function(
          ffi.Pointer<AVCodecParameters>, ffi.Pointer<AVCodecParameters>)>();

  /// Create and initialize a AVIOContext for accessing the
  /// resource indicated by url.
  /// @note When the resource indicated by url has been opened in
  /// read+write mode, the AVIOContext can be used only for writing.
  ///
  /// @param s Used to return the pointer to the created AVIOContext.
  /// In case of failure the pointed to value is set to NULL.
  /// @param url resource to access
  /// @param flags flags which control how the resource indicated by url
  /// is to be opened
  /// @return >= 0 in case of success, a negative value corresponding to an
  /// AVERROR code in case of failure
  int avio_open(
    ffi.Pointer<ffi.Pointer<AVIOContext>> s,
    ffi.Pointer<ffi.Char> url,
    int flags,
  ) {
    return _avio_open(
      s,
      url,
      flags,
    );
  }

  late final _avio_openPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<AVIOContext>>,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('avio_open');
  late final _avio_open = _avio_openPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Pointer<AVIOContext>>, ffi.Pointer<ffi.Char>, int)>();

  /// Close the resource accessed by the AVIOContext s and free it.
  /// This function can only be used if s was opened by avio_open().
  ///
  /// The internal buffer is automatically flushed before closing the
  /// resource.
  ///
  /// @return 0 on success, an AVERROR < 0 on error.
  /// @see avio_closep
  int avio_close(
    ffi.Pointer<AVIOContext> s,
  ) {
    return _avio_close(
      s,
    );
  }

  late final _avio_closePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<AVIOContext>)>>(
          'avio_close');
  late final _avio_close =
      _avio_closePtr.asFunction<int Function(ffi.Pointer<AVIOContext>)>();

  /// Return the LIBAVFORMAT_VERSION_INT constant.
  int avformat_version() {
    return _avformat_version();
  }

  late final _avformat_versionPtr =
      _lookup<ffi.NativeFunction<ffi.UnsignedInt Function()>>(
          'avformat_version');
  late final _avformat_version =
      _avformat_versionPtr.asFunction<int Function()>();

  /// Return the libavformat build-time configuration.
  ffi.Pointer<ffi.Char> avformat_configuration() {
    return _avformat_configuration();
  }

  late final _avformat_configurationPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'avformat_configuration');
  late final _avformat_configuration =
      _avformat_configurationPtr.asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// Free an AVFormatContext and all its streams.
  /// @param s context to free
  void avformat_free_context(
    ffi.Pointer<AVFormatContext> s,
  ) {
    return _avformat_free_context(
      s,
    );
  }

  late final _avformat_free_contextPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<AVFormatContext>)>>(
      'avformat_free_context');
  late final _avformat_free_context = _avformat_free_contextPtr
      .asFunction<void Function(ffi.Pointer<AVFormatContext>)>();

  /// Add a new stream to a media file.
  ///
  /// When demuxing, it is called by the demuxer in read_header(). If the
  /// flag AVFMTCTX_NOHEADER is set in s.ctx_flags, then it may also
  /// be called in read_packet().
  ///
  /// When muxing, should be called by the user before avformat_write_header().
  ///
  /// User is required to call avformat_free_context() to clean up the allocation
  /// by avformat_new_stream().
  ///
  /// @param s media file handle
  /// @param c unused, does nothing
  ///
  /// @return newly created stream or NULL on error.
  ffi.Pointer<AVStream> avformat_new_stream(
    ffi.Pointer<AVFormatContext> s,
    ffi.Pointer<AVCodec> c,
  ) {
    return _avformat_new_stream(
      s,
      c,
    );
  }

  late final _avformat_new_streamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<AVStream> Function(ffi.Pointer<AVFormatContext>,
              ffi.Pointer<AVCodec>)>>('avformat_new_stream');
  late final _avformat_new_stream = _avformat_new_streamPtr.asFunction<
      ffi.Pointer<AVStream> Function(
          ffi.Pointer<AVFormatContext>, ffi.Pointer<AVCodec>)>();

  /// Allocate an AVFormatContext for an output format.
  /// avformat_free_context() can be used to free the context and
  /// everything allocated by the framework within it.
  ///
  /// @param ctx           pointee is set to the created format context,
  /// or to NULL in case of failure
  /// @param oformat       format to use for allocating the context, if NULL
  /// format_name and filename are used instead
  /// @param format_name   the name of output format to use for allocating the
  /// context, if NULL filename is used instead
  /// @param filename      the name of the filename to use for allocating the
  /// context, may be NULL
  ///
  /// @return  >= 0 in case of success, a negative AVERROR code in case of
  /// failure
  int avformat_alloc_output_context2(
    ffi.Pointer<ffi.Pointer<AVFormatContext>> ctx,
    ffi.Pointer<AVOutputFormat> oformat,
    ffi.Pointer<ffi.Char> format_name,
    ffi.Pointer<ffi.Char> filename,
  ) {
    return _avformat_alloc_output_context2(
      ctx,
      oformat,
      format_name,
      filename,
    );
  }

  late final _avformat_alloc_output_context2Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Pointer<AVFormatContext>>,
              ffi.Pointer<AVOutputFormat>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('avformat_alloc_output_context2');
  late final _avformat_alloc_output_context2 =
      _avformat_alloc_output_context2Ptr.asFunction<
          int Function(
              ffi.Pointer<ffi.Pointer<AVFormatContext>>,
              ffi.Pointer<AVOutputFormat>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>();

  /// Open an input stream and read the header. The codecs are not opened.
  /// The stream must be closed with avformat_close_input().
  ///
  /// @param ps       Pointer to user-supplied AVFormatContext (allocated by
  /// avformat_alloc_context). May be a pointer to NULL, in
  /// which case an AVFormatContext is allocated by this
  /// function and written into ps.
  /// Note that a user-supplied AVFormatContext will be freed
  /// on failure.
  /// @param url      URL of the stream to open.
  /// @param fmt      If non-NULL, this parameter forces a specific input format.
  /// Otherwise the format is autodetected.
  /// @param options  A dictionary filled with AVFormatContext and demuxer-private
  /// options.
  /// On return this parameter will be destroyed and replaced with
  /// a dict containing options that were not found. May be NULL.
  ///
  /// @return 0 on success, a negative AVERROR on failure.
  ///
  /// @note If you want to use custom IO, preallocate the format context and set its pb field.
  int avformat_open_input(
    ffi.Pointer<ffi.Pointer<AVFormatContext>> ps,
    ffi.Pointer<ffi.Char> url,
    ffi.Pointer<AVInputFormat> fmt,
    ffi.Pointer<ffi.Pointer<AVDictionary>> options,
  ) {
    return _avformat_open_input(
      ps,
      url,
      fmt,
      options,
    );
  }

  late final _avformat_open_inputPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Pointer<AVFormatContext>>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<AVInputFormat>,
              ffi.Pointer<ffi.Pointer<AVDictionary>>)>>('avformat_open_input');
  late final _avformat_open_input = _avformat_open_inputPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Pointer<AVFormatContext>>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<AVInputFormat>,
          ffi.Pointer<ffi.Pointer<AVDictionary>>)>();

  /// Read packets of a media file to get stream information. This
  /// is useful for file formats with no headers such as MPEG. This
  /// function also computes the real framerate in case of MPEG-2 repeat
  /// frame mode.
  /// The logical file position is not changed by this function;
  /// examined packets may be buffered for later processing.
  ///
  /// @param ic media file handle
  /// @param options  If non-NULL, an ic.nb_streams long array of pointers to
  /// dictionaries, where i-th member contains options for
  /// codec corresponding to i-th stream.
  /// On return each dictionary will be filled with options that were not found.
  /// @return >=0 if OK, AVERROR_xxx on error
  ///
  /// @note this function isn't guaranteed to open all the codecs, so
  /// options being non-empty at return is a perfectly normal behavior.
  ///
  /// @todo Let the user decide somehow what information is needed so that
  /// we do not waste time getting stuff the user does not need.
  int avformat_find_stream_info(
    ffi.Pointer<AVFormatContext> ic,
    ffi.Pointer<ffi.Pointer<AVDictionary>> options,
  ) {
    return _avformat_find_stream_info(
      ic,
      options,
    );
  }

  late final _avformat_find_stream_infoPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<AVFormatContext>,
                  ffi.Pointer<ffi.Pointer<AVDictionary>>)>>(
      'avformat_find_stream_info');
  late final _avformat_find_stream_info =
      _avformat_find_stream_infoPtr.asFunction<
          int Function(ffi.Pointer<AVFormatContext>,
              ffi.Pointer<ffi.Pointer<AVDictionary>>)>();

  /// Return the next frame of a stream.
  /// This function returns what is stored in the file, and does not validate
  /// that what is there are valid frames for the decoder. It will split what is
  /// stored in the file into frames and return one for each call. It will not
  /// omit invalid data between valid frames so as to give the decoder the maximum
  /// information possible for decoding.
  ///
  /// On success, the returned packet is reference-counted (pkt->buf is set) and
  /// valid indefinitely. The packet must be freed with av_packet_unref() when
  /// it is no longer needed. For video, the packet contains exactly one frame.
  /// For audio, it contains an integer number of frames if each frame has
  /// a known fixed size (e.g. PCM or ADPCM data). If the audio frames have
  /// a variable size (e.g. MPEG audio), then it contains one frame.
  ///
  /// pkt->pts, pkt->dts and pkt->duration are always set to correct
  /// values in AVStream.time_base units (and guessed if the format cannot
  /// provide them). pkt->pts can be AV_NOPTS_VALUE if the video format
  /// has B-frames, so it is better to rely on pkt->dts if you do not
  /// decompress the payload.
  ///
  /// @return 0 if OK, < 0 on error or end of file. On error, pkt will be blank
  /// (as if it came from av_packet_alloc()).
  ///
  /// @note pkt will be initialized, so it may be uninitialized, but it must not
  /// contain data that needs to be freed.
  int av_read_frame(
    ffi.Pointer<AVFormatContext> s,
    ffi.Pointer<AVPacket> pkt,
  ) {
    return _av_read_frame(
      s,
      pkt,
    );
  }

  late final _av_read_framePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<AVFormatContext>,
              ffi.Pointer<AVPacket>)>>('av_read_frame');
  late final _av_read_frame = _av_read_framePtr.asFunction<
      int Function(ffi.Pointer<AVFormatContext>, ffi.Pointer<AVPacket>)>();

  /// Close an opened input AVFormatContext. Free it and all its contents
  /// and set *s to NULL.
  void avformat_close_input(
    ffi.Pointer<ffi.Pointer<AVFormatContext>> s,
  ) {
    return _avformat_close_input(
      s,
    );
  }

  late final _avformat_close_inputPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<ffi.Pointer<AVFormatContext>>)>>(
      'avformat_close_input');
  late final _avformat_close_input = _avformat_close_inputPtr
      .asFunction<void Function(ffi.Pointer<ffi.Pointer<AVFormatContext>>)>();

  /// Allocate the stream private data and write the stream header to
  /// an output media file.
  ///
  /// @param s        Media file handle, must be allocated with
  /// avformat_alloc_context().
  /// Its \ref AVFormatContext.oformat "oformat" field must be set
  /// to the desired output format;
  /// Its \ref AVFormatContext.pb "pb" field must be set to an
  /// already opened ::AVIOContext.
  /// @param options  An ::AVDictionary filled with AVFormatContext and
  /// muxer-private options.
  /// On return this parameter will be destroyed and replaced with
  /// a dict containing options that were not found. May be NULL.
  ///
  /// @retval AVSTREAM_INIT_IN_WRITE_HEADER On success, if the codec had not already been
  /// fully initialized in avformat_init_output().
  /// @retval AVSTREAM_INIT_IN_INIT_OUTPUT  On success, if the codec had already been fully
  /// initialized in avformat_init_output().
  /// @retval AVERROR                       A negative AVERROR on failure.
  ///
  /// @see av_opt_find, av_dict_set, avio_open, av_oformat_next, avformat_init_output.
  int avformat_write_header(
    ffi.Pointer<AVFormatContext> s,
    ffi.Pointer<ffi.Pointer<AVDictionary>> options,
  ) {
    return _avformat_write_header(
      s,
      options,
    );
  }

  late final _avformat_write_headerPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<AVFormatContext>,
                  ffi.Pointer<ffi.Pointer<AVDictionary>>)>>(
      'avformat_write_header');
  late final _avformat_write_header = _avformat_write_headerPtr.asFunction<
      int Function(ffi.Pointer<AVFormatContext>,
          ffi.Pointer<ffi.Pointer<AVDictionary>>)>();

  /// Write a packet to an output media file ensuring correct interleaving.
  ///
  /// This function will buffer the packets internally as needed to make sure the
  /// packets in the output file are properly interleaved, usually ordered by
  /// increasing dts. Callers doing their own interleaving should call
  /// av_write_frame() instead of this function.
  ///
  /// Using this function instead of av_write_frame() can give muxers advance
  /// knowledge of future packets, improving e.g. the behaviour of the mp4
  /// muxer for VFR content in fragmenting mode.
  ///
  /// @param s media file handle
  /// @param pkt The packet containing the data to be written.
  /// <br>
  /// If the packet is reference-counted, this function will take
  /// ownership of this reference and unreference it later when it sees
  /// fit. If the packet is not reference-counted, libavformat will
  /// make a copy.
  /// The returned packet will be blank (as if returned from
  /// av_packet_alloc()), even on error.
  /// <br>
  /// This parameter can be NULL (at any time, not just at the end), to
  /// flush the interleaving queues.
  /// <br>
  /// Packet's @ref AVPacket.stream_index "stream_index" field must be
  /// set to the index of the corresponding stream in @ref
  /// AVFormatContext.streams "s->streams".
  /// <br>
  /// The timestamps (@ref AVPacket.pts "pts", @ref AVPacket.dts "dts")
  /// must be set to correct values in the stream's timebase (unless the
  /// output format is flagged with the AVFMT_NOTIMESTAMPS flag, then
  /// they can be set to AV_NOPTS_VALUE).
  /// The dts for subsequent packets in one stream must be strictly
  /// increasing (unless the output format is flagged with the
  /// AVFMT_TS_NONSTRICT, then they merely have to be nondecreasing).
  /// @ref AVPacket.duration "duration" should also be set if known.
  ///
  /// @return 0 on success, a negative AVERROR on error.
  ///
  /// @see av_write_frame(), AVFormatContext.max_interleave_delta
  int av_interleaved_write_frame(
    ffi.Pointer<AVFormatContext> s,
    ffi.Pointer<AVPacket> pkt,
  ) {
    return _av_interleaved_write_frame(
      s,
      pkt,
    );
  }

  late final _av_interleaved_write_framePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<AVFormatContext>,
              ffi.Pointer<AVPacket>)>>('av_interleaved_write_frame');
  late final _av_interleaved_write_frame =
      _av_interleaved_write_framePtr.asFunction<
          int Function(ffi.Pointer<AVFormatContext>, ffi.Pointer<AVPacket>)>();

  /// Write the stream trailer to an output media file and free the
  /// file private data.
  ///
  /// May only be called after a successful call to avformat_write_header.
  ///
  /// @param s media file handle
  /// @return 0 if OK, AVERROR_xxx on error
  int av_write_trailer(
    ffi.Pointer<AVFormatContext> s,
  ) {
    return _av_write_trailer(
      s,
    );
  }

  late final _av_write_trailerPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<AVFormatContext>)>>(
      'av_write_trailer');
  late final _av_write_trailer = _av_write_trailerPtr
      .asFunction<int Function(ffi.Pointer<AVFormatContext>)>();
}

/// @addtogroup lavu_media Media Type
/// @brief Media Type
enum AVMediaType {
  /// < Usually treated as AVMEDIA_TYPE_DATA
  AVMEDIA_TYPE_UNKNOWN(-1),
  AVMEDIA_TYPE_VIDEO(0),
  AVMEDIA_TYPE_AUDIO(1),

  /// < Opaque data information usually continuous
  AVMEDIA_TYPE_DATA(2),
  AVMEDIA_TYPE_SUBTITLE(3),

  /// < Opaque data information usually sparse
  AVMEDIA_TYPE_ATTACHMENT(4),
  AVMEDIA_TYPE_NB(5);

  final int value;
  const AVMediaType(this.value);

  static AVMediaType fromValue(int value) => switch (value) {
        -1 => AVMEDIA_TYPE_UNKNOWN,
        0 => AVMEDIA_TYPE_VIDEO,
        1 => AVMEDIA_TYPE_AUDIO,
        2 => AVMEDIA_TYPE_DATA,
        3 => AVMEDIA_TYPE_SUBTITLE,
        4 => AVMEDIA_TYPE_ATTACHMENT,
        5 => AVMEDIA_TYPE_NB,
        _ => throw ArgumentError("Unknown value for AVMediaType: $value"),
      };
}

/// Rational number (pair of numerator and denominator).
final class AVRational extends ffi.Struct {
  /// < Numerator
  @ffi.Int()
  external int num;

  /// < Denominator
  @ffi.Int()
  external int den;
}

/// Rounding methods.
enum AVRounding {
  /// < Round toward zero.
  AV_ROUND_ZERO(0),

  /// < Round away from zero.
  AV_ROUND_INF(1),

  /// < Round toward -infinity.
  AV_ROUND_DOWN(2),

  /// < Round toward +infinity.
  AV_ROUND_UP(3),

  /// < Round to nearest and halfway cases away from zero.
  AV_ROUND_NEAR_INF(5),

  /// Flag telling rescaling functions to pass `INT64_MIN`/`MAX` through
  /// unchanged, avoiding special cases for #AV_NOPTS_VALUE.
  ///
  /// Unlike other values of the enumeration AVRounding, this value is a
  /// bitmask that must be used in conjunction with another value of the
  /// enumeration through a bitwise OR, in order to set behavior for normal
  /// cases.
  ///
  /// @code{.c}
  /// av_rescale_rnd(3, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX);
  /// // Rescaling 3:
  /// //     Calculating 3 * 1 / 2
  /// //     3 / 2 is rounded up to 2
  /// //     => 2
  ///
  /// av_rescale_rnd(AV_NOPTS_VALUE, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX);
  /// // Rescaling AV_NOPTS_VALUE:
  /// //     AV_NOPTS_VALUE == INT64_MIN
  /// //     AV_NOPTS_VALUE is passed through
  /// //     => AV_NOPTS_VALUE
  /// @endcode
  AV_ROUND_PASS_MINMAX(8192);

  final int value;
  const AVRounding(this.value);

  static AVRounding fromValue(int value) => switch (value) {
        0 => AV_ROUND_ZERO,
        1 => AV_ROUND_INF,
        2 => AV_ROUND_DOWN,
        3 => AV_ROUND_UP,
        5 => AV_ROUND_NEAR_INF,
        8192 => AV_ROUND_PASS_MINMAX,
        _ => throw ArgumentError("Unknown value for AVRounding: $value"),
      };
}

/// This structure stores compressed data. It is typically exported by demuxers
/// and then passed as input to decoders, or received as output from encoders and
/// then passed to muxers.
///
/// For video, it should typically contain one compressed frame. For audio it may
/// contain several compressed frames. Encoders are allowed to output empty
/// packets, with no compressed data, containing only side data
/// (e.g. to update some stream parameters at the end of encoding).
///
/// The semantics of data ownership depends on the buf field.
/// If it is set, the packet data is dynamically allocated and is
/// valid indefinitely until a call to av_packet_unref() reduces the
/// reference count to 0.
///
/// If the buf field is not set av_packet_ref() would make a copy instead
/// of increasing the reference count.
///
/// The side data is always allocated with av_malloc(), copied by
/// av_packet_ref() and freed by av_packet_unref().
///
/// sizeof(AVPacket) being a part of the public ABI is deprecated. once
/// av_init_packet() is removed, new packets will only be able to be allocated
/// with av_packet_alloc(), and new fields may be added to the end of the struct
/// with a minor bump.
///
/// @see av_packet_alloc
/// @see av_packet_ref
/// @see av_packet_unref
final class AVPacket extends ffi.Struct {
  /// A reference to the reference-counted buffer where the packet data is
  /// stored.
  /// May be NULL, then the packet data is not reference-counted.
  external ffi.Pointer<AVBufferRef> buf;

  /// Presentation timestamp in AVStream->time_base units; the time at which
  /// the decompressed packet will be presented to the user.
  /// Can be AV_NOPTS_VALUE if it is not stored in the file.
  /// pts MUST be larger or equal to dts as presentation cannot happen before
  /// decompression, unless one wants to view hex dumps. Some formats misuse
  /// the terms dts and pts/cts to mean something different. Such timestamps
  /// must be converted to true pts/dts before they are stored in AVPacket.
  @ffi.Int64()
  external int pts;

  /// Decompression timestamp in AVStream->time_base units; the time at which
  /// the packet is decompressed.
  /// Can be AV_NOPTS_VALUE if it is not stored in the file.
  @ffi.Int64()
  external int dts;

  external ffi.Pointer<ffi.Uint8> data;

  @ffi.Int()
  external int size;

  @ffi.Int()
  external int stream_index;

  /// A combination of AV_PKT_FLAG values
  @ffi.Int()
  external int flags;

  /// Additional packet data that can be provided by the container.
  /// Packet can contain several types of side information.
  external ffi.Pointer<AVPacketSideData> side_data;

  @ffi.Int()
  external int side_data_elems;

  /// Duration of this packet in AVStream->time_base units, 0 if unknown.
  /// Equals next_pts - this_pts in presentation order.
  @ffi.Int64()
  external int duration;

  /// < byte position in stream, -1 if unknown
  @ffi.Int64()
  external int pos;

  /// for some private data of the user
  external ffi.Pointer<ffi.Void> opaque;

  /// AVBufferRef for free use by the API user. FFmpeg will never check the
  /// contents of the buffer ref. FFmpeg calls av_buffer_unref() on it when
  /// the packet is unreferenced. av_packet_copy_props() calls create a new
  /// reference with av_buffer_ref() for the target packet's opaque_ref field.
  ///
  /// This is unrelated to the opaque field, although it serves a similar
  /// purpose.
  external ffi.Pointer<AVBufferRef> opaque_ref;

  /// Time base of the packet's timestamps.
  /// In the future, this field may be set on packets output by encoders or
  /// demuxers, but its value will be by default ignored on input to decoders
  /// or muxers.
  external AVRational time_base;
}

/// A reference to a data buffer.
///
/// The size of this struct is not a part of the public ABI and it is not meant
/// to be allocated directly.
final class AVBufferRef extends ffi.Struct {
  external ffi.Pointer<AVBuffer> buffer;

  /// The data buffer. It is considered writable if and only if
  /// this is the only reference to the buffer, in which case
  /// av_buffer_is_writable() returns 1.
  external ffi.Pointer<ffi.Uint8> data;

  /// Size of data in bytes.
  @ffi.Size()
  external int size;
}

final class AVBuffer extends ffi.Opaque {}

/// This structure stores auxiliary information for decoding, presenting, or
/// otherwise processing the coded stream. It is typically exported by demuxers
/// and encoders and can be fed to decoders and muxers either in a per packet
/// basis, or as global side data (applying to the entire coded stream).
///
/// Global side data is handled as follows:
/// - During demuxing, it may be exported through
/// @ref AVStream.codecpar.side_data "AVStream's codec parameters", which can
/// then be passed as input to decoders through the
/// @ref AVCodecContext.coded_side_data "decoder context's side data", for
/// initialization.
/// - For muxing, it can be fed through @ref AVStream.codecpar.side_data
/// "AVStream's codec parameters", typically  the output of encoders through
/// the @ref AVCodecContext.coded_side_data "encoder context's side data", for
/// initialization.
///
/// Packet specific side data is handled as follows:
/// - During demuxing, it may be exported through @ref AVPacket.side_data
/// "AVPacket's side data", which can then be passed as input to decoders.
/// - For muxing, it can be fed through @ref AVPacket.side_data "AVPacket's
/// side data", typically the output of encoders.
///
/// Different modules may accept or export different types of side data
/// depending on media type and codec. Refer to @ref AVPacketSideDataType for a
/// list of defined types and where they may be found or used.
final class AVPacketSideData extends ffi.Struct {
  external ffi.Pointer<ffi.Uint8> data;

  @ffi.Size()
  external int size;

  @ffi.UnsignedInt()
  external int typeAsInt;

  AVPacketSideDataType get type => AVPacketSideDataType.fromValue(typeAsInt);
}

/// @defgroup lavc_packet_side_data AVPacketSideData
///
/// Types and functions for working with AVPacketSideData.
/// @{
enum AVPacketSideDataType {
  /// An AV_PKT_DATA_PALETTE side data packet contains exactly AVPALETTE_SIZE
  /// bytes worth of palette. This side data signals that a new palette is
  /// present.
  AV_PKT_DATA_PALETTE(0),

  /// The AV_PKT_DATA_NEW_EXTRADATA is used to notify the codec or the format
  /// that the extradata buffer was changed and the receiving side should
  /// act upon it appropriately. The new extradata is embedded in the side
  /// data buffer and should be immediately used for processing the current
  /// frame or packet.
  AV_PKT_DATA_NEW_EXTRADATA(1),

  /// An AV_PKT_DATA_PARAM_CHANGE side data packet is laid out as follows:
  /// @code
  /// u32le param_flags
  /// if (param_flags & AV_SIDE_DATA_PARAM_CHANGE_SAMPLE_RATE)
  /// s32le sample_rate
  /// if (param_flags & AV_SIDE_DATA_PARAM_CHANGE_DIMENSIONS)
  /// s32le width
  /// s32le height
  /// @endcode
  AV_PKT_DATA_PARAM_CHANGE(2),

  /// An AV_PKT_DATA_H263_MB_INFO side data packet contains a number of
  /// structures with info about macroblocks relevant to splitting the
  /// packet into smaller packets on macroblock edges (e.g. as for RFC 2190).
  /// That is, it does not necessarily contain info about all macroblocks,
  /// as long as the distance between macroblocks in the info is smaller
  /// than the target payload size.
  /// Each MB info structure is 12 bytes, and is laid out as follows:
  /// @code
  /// u32le bit offset from the start of the packet
  /// u8    current quantizer at the start of the macroblock
  /// u8    GOB number
  /// u16le macroblock address within the GOB
  /// u8    horizontal MV predictor
  /// u8    vertical MV predictor
  /// u8    horizontal MV predictor for block number 3
  /// u8    vertical MV predictor for block number 3
  /// @endcode
  AV_PKT_DATA_H263_MB_INFO(3),

  /// This side data should be associated with an audio stream and contains
  /// ReplayGain information in form of the AVReplayGain struct.
  AV_PKT_DATA_REPLAYGAIN(4),

  /// This side data contains a 3x3 transformation matrix describing an affine
  /// transformation that needs to be applied to the decoded video frames for
  /// correct presentation.
  ///
  /// See libavutil/display.h for a detailed description of the data.
  AV_PKT_DATA_DISPLAYMATRIX(5),

  /// This side data should be associated with a video stream and contains
  /// Stereoscopic 3D information in form of the AVStereo3D struct.
  AV_PKT_DATA_STEREO3D(6),

  /// This side data should be associated with an audio stream and corresponds
  /// to enum AVAudioServiceType.
  AV_PKT_DATA_AUDIO_SERVICE_TYPE(7),

  /// This side data contains quality related information from the encoder.
  /// @code
  /// u32le quality factor of the compressed frame. Allowed range is between 1 (good) and FF_LAMBDA_MAX (bad).
  /// u8    picture type
  /// u8    error count
  /// u16   reserved
  /// u64le[error count] sum of squared differences between encoder in and output
  /// @endcode
  AV_PKT_DATA_QUALITY_STATS(8),

  /// This side data contains an integer value representing the stream index
  /// of a "fallback" track.  A fallback track indicates an alternate
  /// track to use when the current track can not be decoded for some reason.
  /// e.g. no decoder available for codec.
  AV_PKT_DATA_FALLBACK_TRACK(9),

  /// This side data corresponds to the AVCPBProperties struct.
  AV_PKT_DATA_CPB_PROPERTIES(10),

  /// Recommmends skipping the specified number of samples
  /// @code
  /// u32le number of samples to skip from start of this packet
  /// u32le number of samples to skip from end of this packet
  /// u8    reason for start skip
  /// u8    reason for end   skip (0=padding silence, 1=convergence)
  /// @endcode
  AV_PKT_DATA_SKIP_SAMPLES(11),

  /// An AV_PKT_DATA_JP_DUALMONO side data packet indicates that
  /// the packet may contain "dual mono" audio specific to Japanese DTV
  /// and if it is true, recommends only the selected channel to be used.
  /// @code
  /// u8    selected channels (0=main/left, 1=sub/right, 2=both)
  /// @endcode
  AV_PKT_DATA_JP_DUALMONO(12),

  /// A list of zero terminated key/value strings. There is no end marker for
  /// the list, so it is required to rely on the side data size to stop.
  AV_PKT_DATA_STRINGS_METADATA(13),

  /// Subtitle event position
  /// @code
  /// u32le x1
  /// u32le y1
  /// u32le x2
  /// u32le y2
  /// @endcode
  AV_PKT_DATA_SUBTITLE_POSITION(14),

  /// Data found in BlockAdditional element of matroska container. There is
  /// no end marker for the data, so it is required to rely on the side data
  /// size to recognize the end. 8 byte id (as found in BlockAddId) followed
  /// by data.
  AV_PKT_DATA_MATROSKA_BLOCKADDITIONAL(15),

  /// The optional first identifier line of a WebVTT cue.
  AV_PKT_DATA_WEBVTT_IDENTIFIER(16),

  /// The optional settings (rendering instructions) that immediately
  /// follow the timestamp specifier of a WebVTT cue.
  AV_PKT_DATA_WEBVTT_SETTINGS(17),

  /// A list of zero terminated key/value strings. There is no end marker for
  /// the list, so it is required to rely on the side data size to stop. This
  /// side data includes updated metadata which appeared in the stream.
  AV_PKT_DATA_METADATA_UPDATE(18),

  /// MPEGTS stream ID as uint8_t, this is required to pass the stream ID
  /// information from the demuxer to the corresponding muxer.
  AV_PKT_DATA_MPEGTS_STREAM_ID(19),

  /// Mastering display metadata (based on SMPTE-2086:2014). This metadata
  /// should be associated with a video stream and contains data in the form
  /// of the AVMasteringDisplayMetadata struct.
  AV_PKT_DATA_MASTERING_DISPLAY_METADATA(20),

  /// This side data should be associated with a video stream and corresponds
  /// to the AVSphericalMapping structure.
  AV_PKT_DATA_SPHERICAL(21),

  /// Content light level (based on CTA-861.3). This metadata should be
  /// associated with a video stream and contains data in the form of the
  /// AVContentLightMetadata struct.
  AV_PKT_DATA_CONTENT_LIGHT_LEVEL(22),

  /// ATSC A53 Part 4 Closed Captions. This metadata should be associated with
  /// a video stream. A53 CC bitstream is stored as uint8_t in AVPacketSideData.data.
  /// The number of bytes of CC data is AVPacketSideData.size.
  AV_PKT_DATA_A53_CC(23),

  /// This side data is encryption initialization data.
  /// The format is not part of ABI, use av_encryption_init_info_* methods to
  /// access.
  AV_PKT_DATA_ENCRYPTION_INIT_INFO(24),

  /// This side data contains encryption info for how to decrypt the packet.
  /// The format is not part of ABI, use av_encryption_info_* methods to access.
  AV_PKT_DATA_ENCRYPTION_INFO(25),

  /// Active Format Description data consisting of a single byte as specified
  /// in ETSI TS 101 154 using AVActiveFormatDescription enum.
  AV_PKT_DATA_AFD(26),

  /// Producer Reference Time data corresponding to the AVProducerReferenceTime struct,
  /// usually exported by some encoders (on demand through the prft flag set in the
  /// AVCodecContext export_side_data field).
  AV_PKT_DATA_PRFT(27),

  /// ICC profile data consisting of an opaque octet buffer following the
  /// format described by ISO 15076-1.
  AV_PKT_DATA_ICC_PROFILE(28),

  /// DOVI configuration
  /// ref:
  /// dolby-vision-bitstreams-within-the-iso-base-media-file-format-v2.1.2, section 2.2
  /// dolby-vision-bitstreams-in-mpeg-2-transport-stream-multiplex-v1.2, section 3.3
  /// Tags are stored in struct AVDOVIDecoderConfigurationRecord.
  AV_PKT_DATA_DOVI_CONF(29),

  /// Timecode which conforms to SMPTE ST 12-1:2014. The data is an array of 4 uint32_t
  /// where the first uint32_t describes how many (1-3) of the other timecodes are used.
  /// The timecode format is described in the documentation of av_timecode_get_smpte_from_framenum()
  /// function in libavutil/timecode.h.
  AV_PKT_DATA_S12M_TIMECODE(30),

  /// HDR10+ dynamic metadata associated with a video frame. The metadata is in
  /// the form of the AVDynamicHDRPlus struct and contains
  /// information for color volume transform - application 4 of
  /// SMPTE 2094-40:2016 standard.
  AV_PKT_DATA_DYNAMIC_HDR10_PLUS(31),

  /// IAMF Mix Gain Parameter Data associated with the audio frame. This metadata
  /// is in the form of the AVIAMFParamDefinition struct and contains information
  /// defined in sections 3.6.1 and 3.8.1 of the Immersive Audio Model and
  /// Formats standard.
  AV_PKT_DATA_IAMF_MIX_GAIN_PARAM(32),

  /// IAMF Demixing Info Parameter Data associated with the audio frame. This
  /// metadata is in the form of the AVIAMFParamDefinition struct and contains
  /// information defined in sections 3.6.1 and 3.8.2 of the Immersive Audio Model
  /// and Formats standard.
  AV_PKT_DATA_IAMF_DEMIXING_INFO_PARAM(33),

  /// IAMF Recon Gain Info Parameter Data associated with the audio frame. This
  /// metadata is in the form of the AVIAMFParamDefinition struct and contains
  /// information defined in sections 3.6.1 and 3.8.3 of the Immersive Audio Model
  /// and Formats standard.
  AV_PKT_DATA_IAMF_RECON_GAIN_INFO_PARAM(34),

  /// Ambient viewing environment metadata, as defined by H.274. This metadata
  /// should be associated with a video stream and contains data in the form
  /// of the AVAmbientViewingEnvironment struct.
  AV_PKT_DATA_AMBIENT_VIEWING_ENVIRONMENT(35),

  /// The number of pixels to discard from the top/bottom/left/right border of the
  /// decoded frame to obtain the sub-rectangle intended for presentation.
  ///
  /// @code
  /// u32le crop_top
  /// u32le crop_bottom
  /// u32le crop_left
  /// u32le crop_right
  /// @endcode
  AV_PKT_DATA_FRAME_CROPPING(36),

  /// Raw LCEVC payload data, as a uint8_t array, with NAL emulation
  /// bytes intact.
  AV_PKT_DATA_LCEVC(37),

  /// The number of side data types.
  /// This is not part of the public API/ABI in the sense that it may
  /// change when new side data types are added.
  /// This must stay the last enum value.
  /// If its value becomes huge, some code using it
  /// needs to be updated as it assumes it to be smaller than other limits.
  AV_PKT_DATA_NB(38);

  final int value;
  const AVPacketSideDataType(this.value);

  static AVPacketSideDataType fromValue(int value) => switch (value) {
        0 => AV_PKT_DATA_PALETTE,
        1 => AV_PKT_DATA_NEW_EXTRADATA,
        2 => AV_PKT_DATA_PARAM_CHANGE,
        3 => AV_PKT_DATA_H263_MB_INFO,
        4 => AV_PKT_DATA_REPLAYGAIN,
        5 => AV_PKT_DATA_DISPLAYMATRIX,
        6 => AV_PKT_DATA_STEREO3D,
        7 => AV_PKT_DATA_AUDIO_SERVICE_TYPE,
        8 => AV_PKT_DATA_QUALITY_STATS,
        9 => AV_PKT_DATA_FALLBACK_TRACK,
        10 => AV_PKT_DATA_CPB_PROPERTIES,
        11 => AV_PKT_DATA_SKIP_SAMPLES,
        12 => AV_PKT_DATA_JP_DUALMONO,
        13 => AV_PKT_DATA_STRINGS_METADATA,
        14 => AV_PKT_DATA_SUBTITLE_POSITION,
        15 => AV_PKT_DATA_MATROSKA_BLOCKADDITIONAL,
        16 => AV_PKT_DATA_WEBVTT_IDENTIFIER,
        17 => AV_PKT_DATA_WEBVTT_SETTINGS,
        18 => AV_PKT_DATA_METADATA_UPDATE,
        19 => AV_PKT_DATA_MPEGTS_STREAM_ID,
        20 => AV_PKT_DATA_MASTERING_DISPLAY_METADATA,
        21 => AV_PKT_DATA_SPHERICAL,
        22 => AV_PKT_DATA_CONTENT_LIGHT_LEVEL,
        23 => AV_PKT_DATA_A53_CC,
        24 => AV_PKT_DATA_ENCRYPTION_INIT_INFO,
        25 => AV_PKT_DATA_ENCRYPTION_INFO,
        26 => AV_PKT_DATA_AFD,
        27 => AV_PKT_DATA_PRFT,
        28 => AV_PKT_DATA_ICC_PROFILE,
        29 => AV_PKT_DATA_DOVI_CONF,
        30 => AV_PKT_DATA_S12M_TIMECODE,
        31 => AV_PKT_DATA_DYNAMIC_HDR10_PLUS,
        32 => AV_PKT_DATA_IAMF_MIX_GAIN_PARAM,
        33 => AV_PKT_DATA_IAMF_DEMIXING_INFO_PARAM,
        34 => AV_PKT_DATA_IAMF_RECON_GAIN_INFO_PARAM,
        35 => AV_PKT_DATA_AMBIENT_VIEWING_ENVIRONMENT,
        36 => AV_PKT_DATA_FRAME_CROPPING,
        37 => AV_PKT_DATA_LCEVC,
        38 => AV_PKT_DATA_NB,
        _ =>
          throw ArgumentError("Unknown value for AVPacketSideDataType: $value"),
      };
}

/// This struct describes the properties of an encoded stream.
///
/// sizeof(AVCodecParameters) is not a part of the public ABI, this struct must
/// be allocated with avcodec_parameters_alloc() and freed with
/// avcodec_parameters_free().
final class AVCodecParameters extends ffi.Struct {
  /// General type of the encoded data.
  @ffi.Int()
  external int codec_typeAsInt;

  AVMediaType get codec_type => AVMediaType.fromValue(codec_typeAsInt);

  /// Specific type of the encoded data (the codec used).
  @ffi.UnsignedInt()
  external int codec_idAsInt;

  AVCodecID get codec_id => AVCodecID.fromValue(codec_idAsInt);

  /// Additional information about the codec (corresponds to the AVI FOURCC).
  @ffi.Uint32()
  external int codec_tag;

  /// Extra binary data needed for initializing the decoder, codec-dependent.
  ///
  /// Must be allocated with av_malloc() and will be freed by
  /// avcodec_parameters_free(). The allocated size of extradata must be at
  /// least extradata_size + AV_INPUT_BUFFER_PADDING_SIZE, with the padding
  /// bytes zeroed.
  external ffi.Pointer<ffi.Uint8> extradata;

  /// Size of the extradata content in bytes.
  @ffi.Int()
  external int extradata_size;

  /// Additional data associated with the entire stream.
  ///
  /// Should be allocated with av_packet_side_data_new() or
  /// av_packet_side_data_add(), and will be freed by avcodec_parameters_free().
  external ffi.Pointer<AVPacketSideData> coded_side_data;

  /// Amount of entries in @ref coded_side_data.
  @ffi.Int()
  external int nb_coded_side_data;

  /// - video: the pixel format, the value corresponds to enum AVPixelFormat.
  /// - audio: the sample format, the value corresponds to enum AVSampleFormat.
  @ffi.Int()
  external int format;

  /// The average bitrate of the encoded data (in bits per second).
  @ffi.Int64()
  external int bit_rate;

  /// The number of bits per sample in the codedwords.
  ///
  /// This is basically the bitrate per sample. It is mandatory for a bunch of
  /// formats to actually decode them. It's the number of bits for one sample in
  /// the actual coded bitstream.
  ///
  /// This could be for example 4 for ADPCM
  /// For PCM formats this matches bits_per_raw_sample
  /// Can be 0
  @ffi.Int()
  external int bits_per_coded_sample;

  /// This is the number of valid bits in each output sample. If the
  /// sample format has more bits, the least significant bits are additional
  /// padding bits, which are always 0. Use right shifts to reduce the sample
  /// to its actual size. For example, audio formats with 24 bit samples will
  /// have bits_per_raw_sample set to 24, and format set to AV_SAMPLE_FMT_S32.
  /// To get the original sample use "(int32_t)sample >> 8"."
  ///
  /// For ADPCM this might be 12 or 16 or similar
  /// Can be 0
  @ffi.Int()
  external int bits_per_raw_sample;

  /// Codec-specific bitstream restrictions that the stream conforms to.
  @ffi.Int()
  external int profile;

  @ffi.Int()
  external int level;

  /// Video only. The dimensions of the video frame in pixels.
  @ffi.Int()
  external int width;

  @ffi.Int()
  external int height;

  /// Video only. The aspect ratio (width / height) which a single pixel
  /// should have when displayed.
  ///
  /// When the aspect ratio is unknown / undefined, the numerator should be
  /// set to 0 (the denominator may have any value).
  external AVRational sample_aspect_ratio;

  /// Video only. Number of frames per second, for streams with constant frame
  /// durations. Should be set to { 0, 1 } when some frames have differing
  /// durations or if the value is not known.
  ///
  /// @note This field correponds to values that are stored in codec-level
  /// headers and is typically overridden by container/transport-layer
  /// timestamps, when available. It should thus be used only as a last resort,
  /// when no higher-level timing information is available.
  external AVRational framerate;

  /// Video only. The order of the fields in interlaced video.
  @ffi.UnsignedInt()
  external int field_orderAsInt;

  AVFieldOrder get field_order => AVFieldOrder.fromValue(field_orderAsInt);

  /// Video only. Additional colorspace characteristics.
  @ffi.UnsignedInt()
  external int color_rangeAsInt;

  AVColorRange get color_range => AVColorRange.fromValue(color_rangeAsInt);

  @ffi.UnsignedInt()
  external int color_primariesAsInt;

  AVColorPrimaries get color_primaries =>
      AVColorPrimaries.fromValue(color_primariesAsInt);

  @ffi.UnsignedInt()
  external int color_trcAsInt;

  AVColorTransferCharacteristic get color_trc =>
      AVColorTransferCharacteristic.fromValue(color_trcAsInt);

  @ffi.UnsignedInt()
  external int color_spaceAsInt;

  AVColorSpace get color_space => AVColorSpace.fromValue(color_spaceAsInt);

  @ffi.UnsignedInt()
  external int chroma_locationAsInt;

  AVChromaLocation get chroma_location =>
      AVChromaLocation.fromValue(chroma_locationAsInt);

  /// Video only. Number of delayed frames.
  @ffi.Int()
  external int video_delay;

  /// Audio only. The channel layout and number of channels.
  external AVChannelLayout ch_layout;

  /// Audio only. The number of audio samples per second.
  @ffi.Int()
  external int sample_rate;

  /// Audio only. The number of bytes per coded audio frame, required by some
  /// formats.
  ///
  /// Corresponds to nBlockAlign in WAVEFORMATEX.
  @ffi.Int()
  external int block_align;

  /// Audio only. Audio frame size, if known. Required by some formats to be static.
  @ffi.Int()
  external int frame_size;

  /// Audio only. The amount of padding (in samples) inserted by the encoder at
  /// the beginning of the audio. I.e. this number of leading decoded samples
  /// must be discarded by the caller to get the original audio without leading
  /// padding.
  @ffi.Int()
  external int initial_padding;

  /// Audio only. The amount of padding (in samples) appended by the encoder to
  /// the end of the audio. I.e. this number of decoded samples must be
  /// discarded by the caller from the end of the stream to get the original
  /// audio without any trailing padding.
  @ffi.Int()
  external int trailing_padding;

  /// Audio only. Number of samples to skip after a discontinuity.
  @ffi.Int()
  external int seek_preroll;
}

/// Identify the syntax and semantics of the bitstream.
/// The principle is roughly:
/// Two decoders with the same ID can decode the same streams.
/// Two encoders with the same ID can encode compatible streams.
/// There may be slight deviations from the principle due to implementation
/// details.
///
/// If you add a codec ID to this list, add it so that
/// 1. no value of an existing codec ID changes (that would break ABI),
/// 2. it is as close as possible to similar codecs
///
/// After adding new codec IDs, do not forget to add an entry to the codec
/// descriptor list and bump libavcodec minor version.
enum AVCodecID {
  AV_CODEC_ID_NONE(0),
  AV_CODEC_ID_MPEG1VIDEO(1),

  /// < preferred ID for MPEG-1/2 video decoding
  AV_CODEC_ID_MPEG2VIDEO(2),
  AV_CODEC_ID_H261(3),
  AV_CODEC_ID_H263(4),
  AV_CODEC_ID_RV10(5),
  AV_CODEC_ID_RV20(6),
  AV_CODEC_ID_MJPEG(7),
  AV_CODEC_ID_MJPEGB(8),
  AV_CODEC_ID_LJPEG(9),
  AV_CODEC_ID_SP5X(10),
  AV_CODEC_ID_JPEGLS(11),
  AV_CODEC_ID_MPEG4(12),
  AV_CODEC_ID_RAWVIDEO(13),
  AV_CODEC_ID_MSMPEG4V1(14),
  AV_CODEC_ID_MSMPEG4V2(15),
  AV_CODEC_ID_MSMPEG4V3(16),
  AV_CODEC_ID_WMV1(17),
  AV_CODEC_ID_WMV2(18),
  AV_CODEC_ID_H263P(19),
  AV_CODEC_ID_H263I(20),
  AV_CODEC_ID_FLV1(21),
  AV_CODEC_ID_SVQ1(22),
  AV_CODEC_ID_SVQ3(23),
  AV_CODEC_ID_DVVIDEO(24),
  AV_CODEC_ID_HUFFYUV(25),
  AV_CODEC_ID_CYUV(26),
  AV_CODEC_ID_H264(27),
  AV_CODEC_ID_INDEO3(28),
  AV_CODEC_ID_VP3(29),
  AV_CODEC_ID_THEORA(30),
  AV_CODEC_ID_ASV1(31),
  AV_CODEC_ID_ASV2(32),
  AV_CODEC_ID_FFV1(33),
  AV_CODEC_ID_4XM(34),
  AV_CODEC_ID_VCR1(35),
  AV_CODEC_ID_CLJR(36),
  AV_CODEC_ID_MDEC(37),
  AV_CODEC_ID_ROQ(38),
  AV_CODEC_ID_INTERPLAY_VIDEO(39),
  AV_CODEC_ID_XAN_WC3(40),
  AV_CODEC_ID_XAN_WC4(41),
  AV_CODEC_ID_RPZA(42),
  AV_CODEC_ID_CINEPAK(43),
  AV_CODEC_ID_WS_VQA(44),
  AV_CODEC_ID_MSRLE(45),
  AV_CODEC_ID_MSVIDEO1(46),
  AV_CODEC_ID_IDCIN(47),
  AV_CODEC_ID_8BPS(48),
  AV_CODEC_ID_SMC(49),
  AV_CODEC_ID_FLIC(50),
  AV_CODEC_ID_TRUEMOTION1(51),
  AV_CODEC_ID_VMDVIDEO(52),
  AV_CODEC_ID_MSZH(53),
  AV_CODEC_ID_ZLIB(54),
  AV_CODEC_ID_QTRLE(55),
  AV_CODEC_ID_TSCC(56),
  AV_CODEC_ID_ULTI(57),
  AV_CODEC_ID_QDRAW(58),
  AV_CODEC_ID_VIXL(59),
  AV_CODEC_ID_QPEG(60),
  AV_CODEC_ID_PNG(61),
  AV_CODEC_ID_PPM(62),
  AV_CODEC_ID_PBM(63),
  AV_CODEC_ID_PGM(64),
  AV_CODEC_ID_PGMYUV(65),
  AV_CODEC_ID_PAM(66),
  AV_CODEC_ID_FFVHUFF(67),
  AV_CODEC_ID_RV30(68),
  AV_CODEC_ID_RV40(69),
  AV_CODEC_ID_VC1(70),
  AV_CODEC_ID_WMV3(71),
  AV_CODEC_ID_LOCO(72),
  AV_CODEC_ID_WNV1(73),
  AV_CODEC_ID_AASC(74),
  AV_CODEC_ID_INDEO2(75),
  AV_CODEC_ID_FRAPS(76),
  AV_CODEC_ID_TRUEMOTION2(77),
  AV_CODEC_ID_BMP(78),
  AV_CODEC_ID_CSCD(79),
  AV_CODEC_ID_MMVIDEO(80),
  AV_CODEC_ID_ZMBV(81),
  AV_CODEC_ID_AVS(82),
  AV_CODEC_ID_SMACKVIDEO(83),
  AV_CODEC_ID_NUV(84),
  AV_CODEC_ID_KMVC(85),
  AV_CODEC_ID_FLASHSV(86),
  AV_CODEC_ID_CAVS(87),
  AV_CODEC_ID_JPEG2000(88),
  AV_CODEC_ID_VMNC(89),
  AV_CODEC_ID_VP5(90),
  AV_CODEC_ID_VP6(91),
  AV_CODEC_ID_VP6F(92),
  AV_CODEC_ID_TARGA(93),
  AV_CODEC_ID_DSICINVIDEO(94),
  AV_CODEC_ID_TIERTEXSEQVIDEO(95),
  AV_CODEC_ID_TIFF(96),
  AV_CODEC_ID_GIF(97),
  AV_CODEC_ID_DXA(98),
  AV_CODEC_ID_DNXHD(99),
  AV_CODEC_ID_THP(100),
  AV_CODEC_ID_SGI(101),
  AV_CODEC_ID_C93(102),
  AV_CODEC_ID_BETHSOFTVID(103),
  AV_CODEC_ID_PTX(104),
  AV_CODEC_ID_TXD(105),
  AV_CODEC_ID_VP6A(106),
  AV_CODEC_ID_AMV(107),
  AV_CODEC_ID_VB(108),
  AV_CODEC_ID_PCX(109),
  AV_CODEC_ID_SUNRAST(110),
  AV_CODEC_ID_INDEO4(111),
  AV_CODEC_ID_INDEO5(112),
  AV_CODEC_ID_MIMIC(113),
  AV_CODEC_ID_RL2(114),
  AV_CODEC_ID_ESCAPE124(115),
  AV_CODEC_ID_DIRAC(116),
  AV_CODEC_ID_BFI(117),
  AV_CODEC_ID_CMV(118),
  AV_CODEC_ID_MOTIONPIXELS(119),
  AV_CODEC_ID_TGV(120),
  AV_CODEC_ID_TGQ(121),
  AV_CODEC_ID_TQI(122),
  AV_CODEC_ID_AURA(123),
  AV_CODEC_ID_AURA2(124),
  AV_CODEC_ID_V210X(125),
  AV_CODEC_ID_TMV(126),
  AV_CODEC_ID_V210(127),
  AV_CODEC_ID_DPX(128),
  AV_CODEC_ID_MAD(129),
  AV_CODEC_ID_FRWU(130),
  AV_CODEC_ID_FLASHSV2(131),
  AV_CODEC_ID_CDGRAPHICS(132),
  AV_CODEC_ID_R210(133),
  AV_CODEC_ID_ANM(134),
  AV_CODEC_ID_BINKVIDEO(135),
  AV_CODEC_ID_IFF_ILBM(136),
  AV_CODEC_ID_KGV1(137),
  AV_CODEC_ID_YOP(138),
  AV_CODEC_ID_VP8(139),
  AV_CODEC_ID_PICTOR(140),
  AV_CODEC_ID_ANSI(141),
  AV_CODEC_ID_A64_MULTI(142),
  AV_CODEC_ID_A64_MULTI5(143),
  AV_CODEC_ID_R10K(144),
  AV_CODEC_ID_MXPEG(145),
  AV_CODEC_ID_LAGARITH(146),
  AV_CODEC_ID_PRORES(147),
  AV_CODEC_ID_JV(148),
  AV_CODEC_ID_DFA(149),
  AV_CODEC_ID_WMV3IMAGE(150),
  AV_CODEC_ID_VC1IMAGE(151),
  AV_CODEC_ID_UTVIDEO(152),
  AV_CODEC_ID_BMV_VIDEO(153),
  AV_CODEC_ID_VBLE(154),
  AV_CODEC_ID_DXTORY(155),
  AV_CODEC_ID_V410(156),
  AV_CODEC_ID_XWD(157),
  AV_CODEC_ID_CDXL(158),
  AV_CODEC_ID_XBM(159),
  AV_CODEC_ID_ZEROCODEC(160),
  AV_CODEC_ID_MSS1(161),
  AV_CODEC_ID_MSA1(162),
  AV_CODEC_ID_TSCC2(163),
  AV_CODEC_ID_MTS2(164),
  AV_CODEC_ID_CLLC(165),
  AV_CODEC_ID_MSS2(166),
  AV_CODEC_ID_VP9(167),
  AV_CODEC_ID_AIC(168),
  AV_CODEC_ID_ESCAPE130(169),
  AV_CODEC_ID_G2M(170),
  AV_CODEC_ID_WEBP(171),
  AV_CODEC_ID_HNM4_VIDEO(172),
  AV_CODEC_ID_HEVC(173),
  AV_CODEC_ID_FIC(174),
  AV_CODEC_ID_ALIAS_PIX(175),
  AV_CODEC_ID_BRENDER_PIX(176),
  AV_CODEC_ID_PAF_VIDEO(177),
  AV_CODEC_ID_EXR(178),
  AV_CODEC_ID_VP7(179),
  AV_CODEC_ID_SANM(180),
  AV_CODEC_ID_SGIRLE(181),
  AV_CODEC_ID_MVC1(182),
  AV_CODEC_ID_MVC2(183),
  AV_CODEC_ID_HQX(184),
  AV_CODEC_ID_TDSC(185),
  AV_CODEC_ID_HQ_HQA(186),
  AV_CODEC_ID_HAP(187),
  AV_CODEC_ID_DDS(188),
  AV_CODEC_ID_DXV(189),
  AV_CODEC_ID_SCREENPRESSO(190),
  AV_CODEC_ID_RSCC(191),
  AV_CODEC_ID_AVS2(192),
  AV_CODEC_ID_PGX(193),
  AV_CODEC_ID_AVS3(194),
  AV_CODEC_ID_MSP2(195),
  AV_CODEC_ID_VVC(196),
  AV_CODEC_ID_Y41P(197),
  AV_CODEC_ID_AVRP(198),
  AV_CODEC_ID_012V(199),
  AV_CODEC_ID_AVUI(200),
  AV_CODEC_ID_TARGA_Y216(201),
  AV_CODEC_ID_V308(202),
  AV_CODEC_ID_V408(203),
  AV_CODEC_ID_YUV4(204),
  AV_CODEC_ID_AVRN(205),
  AV_CODEC_ID_CPIA(206),
  AV_CODEC_ID_XFACE(207),
  AV_CODEC_ID_SNOW(208),
  AV_CODEC_ID_SMVJPEG(209),
  AV_CODEC_ID_APNG(210),
  AV_CODEC_ID_DAALA(211),
  AV_CODEC_ID_CFHD(212),
  AV_CODEC_ID_TRUEMOTION2RT(213),
  AV_CODEC_ID_M101(214),
  AV_CODEC_ID_MAGICYUV(215),
  AV_CODEC_ID_SHEERVIDEO(216),
  AV_CODEC_ID_YLC(217),
  AV_CODEC_ID_PSD(218),
  AV_CODEC_ID_PIXLET(219),
  AV_CODEC_ID_SPEEDHQ(220),
  AV_CODEC_ID_FMVC(221),
  AV_CODEC_ID_SCPR(222),
  AV_CODEC_ID_CLEARVIDEO(223),
  AV_CODEC_ID_XPM(224),
  AV_CODEC_ID_AV1(225),
  AV_CODEC_ID_BITPACKED(226),
  AV_CODEC_ID_MSCC(227),
  AV_CODEC_ID_SRGC(228),
  AV_CODEC_ID_SVG(229),
  AV_CODEC_ID_GDV(230),
  AV_CODEC_ID_FITS(231),
  AV_CODEC_ID_IMM4(232),
  AV_CODEC_ID_PROSUMER(233),
  AV_CODEC_ID_MWSC(234),
  AV_CODEC_ID_WCMV(235),
  AV_CODEC_ID_RASC(236),
  AV_CODEC_ID_HYMT(237),
  AV_CODEC_ID_ARBC(238),
  AV_CODEC_ID_AGM(239),
  AV_CODEC_ID_LSCR(240),
  AV_CODEC_ID_VP4(241),
  AV_CODEC_ID_IMM5(242),
  AV_CODEC_ID_MVDV(243),
  AV_CODEC_ID_MVHA(244),
  AV_CODEC_ID_CDTOONS(245),
  AV_CODEC_ID_MV30(246),
  AV_CODEC_ID_NOTCHLC(247),
  AV_CODEC_ID_PFM(248),
  AV_CODEC_ID_MOBICLIP(249),
  AV_CODEC_ID_PHOTOCD(250),
  AV_CODEC_ID_IPU(251),
  AV_CODEC_ID_ARGO(252),
  AV_CODEC_ID_CRI(253),
  AV_CODEC_ID_SIMBIOSIS_IMX(254),
  AV_CODEC_ID_SGA_VIDEO(255),
  AV_CODEC_ID_GEM(256),
  AV_CODEC_ID_VBN(257),
  AV_CODEC_ID_JPEGXL(258),
  AV_CODEC_ID_QOI(259),
  AV_CODEC_ID_PHM(260),
  AV_CODEC_ID_RADIANCE_HDR(261),
  AV_CODEC_ID_WBMP(262),
  AV_CODEC_ID_MEDIA100(263),
  AV_CODEC_ID_VQC(264),
  AV_CODEC_ID_PDV(265),
  AV_CODEC_ID_EVC(266),
  AV_CODEC_ID_RTV1(267),
  AV_CODEC_ID_VMIX(268),
  AV_CODEC_ID_LEAD(269),

  /// < A dummy id pointing at the start of audio codecs
  AV_CODEC_ID_FIRST_AUDIO(65536),
  AV_CODEC_ID_PCM_S16BE(65537),
  AV_CODEC_ID_PCM_U16LE(65538),
  AV_CODEC_ID_PCM_U16BE(65539),
  AV_CODEC_ID_PCM_S8(65540),
  AV_CODEC_ID_PCM_U8(65541),
  AV_CODEC_ID_PCM_MULAW(65542),
  AV_CODEC_ID_PCM_ALAW(65543),
  AV_CODEC_ID_PCM_S32LE(65544),
  AV_CODEC_ID_PCM_S32BE(65545),
  AV_CODEC_ID_PCM_U32LE(65546),
  AV_CODEC_ID_PCM_U32BE(65547),
  AV_CODEC_ID_PCM_S24LE(65548),
  AV_CODEC_ID_PCM_S24BE(65549),
  AV_CODEC_ID_PCM_U24LE(65550),
  AV_CODEC_ID_PCM_U24BE(65551),
  AV_CODEC_ID_PCM_S24DAUD(65552),
  AV_CODEC_ID_PCM_ZORK(65553),
  AV_CODEC_ID_PCM_S16LE_PLANAR(65554),
  AV_CODEC_ID_PCM_DVD(65555),
  AV_CODEC_ID_PCM_F32BE(65556),
  AV_CODEC_ID_PCM_F32LE(65557),
  AV_CODEC_ID_PCM_F64BE(65558),
  AV_CODEC_ID_PCM_F64LE(65559),
  AV_CODEC_ID_PCM_BLURAY(65560),
  AV_CODEC_ID_PCM_LXF(65561),
  AV_CODEC_ID_S302M(65562),
  AV_CODEC_ID_PCM_S8_PLANAR(65563),
  AV_CODEC_ID_PCM_S24LE_PLANAR(65564),
  AV_CODEC_ID_PCM_S32LE_PLANAR(65565),
  AV_CODEC_ID_PCM_S16BE_PLANAR(65566),
  AV_CODEC_ID_PCM_S64LE(65567),
  AV_CODEC_ID_PCM_S64BE(65568),
  AV_CODEC_ID_PCM_F16LE(65569),
  AV_CODEC_ID_PCM_F24LE(65570),
  AV_CODEC_ID_PCM_VIDC(65571),
  AV_CODEC_ID_PCM_SGA(65572),
  AV_CODEC_ID_ADPCM_IMA_QT(69632),
  AV_CODEC_ID_ADPCM_IMA_WAV(69633),
  AV_CODEC_ID_ADPCM_IMA_DK3(69634),
  AV_CODEC_ID_ADPCM_IMA_DK4(69635),
  AV_CODEC_ID_ADPCM_IMA_WS(69636),
  AV_CODEC_ID_ADPCM_IMA_SMJPEG(69637),
  AV_CODEC_ID_ADPCM_MS(69638),
  AV_CODEC_ID_ADPCM_4XM(69639),
  AV_CODEC_ID_ADPCM_XA(69640),
  AV_CODEC_ID_ADPCM_ADX(69641),
  AV_CODEC_ID_ADPCM_EA(69642),
  AV_CODEC_ID_ADPCM_G726(69643),
  AV_CODEC_ID_ADPCM_CT(69644),
  AV_CODEC_ID_ADPCM_SWF(69645),
  AV_CODEC_ID_ADPCM_YAMAHA(69646),
  AV_CODEC_ID_ADPCM_SBPRO_4(69647),
  AV_CODEC_ID_ADPCM_SBPRO_3(69648),
  AV_CODEC_ID_ADPCM_SBPRO_2(69649),
  AV_CODEC_ID_ADPCM_THP(69650),
  AV_CODEC_ID_ADPCM_IMA_AMV(69651),
  AV_CODEC_ID_ADPCM_EA_R1(69652),
  AV_CODEC_ID_ADPCM_EA_R3(69653),
  AV_CODEC_ID_ADPCM_EA_R2(69654),
  AV_CODEC_ID_ADPCM_IMA_EA_SEAD(69655),
  AV_CODEC_ID_ADPCM_IMA_EA_EACS(69656),
  AV_CODEC_ID_ADPCM_EA_XAS(69657),
  AV_CODEC_ID_ADPCM_EA_MAXIS_XA(69658),
  AV_CODEC_ID_ADPCM_IMA_ISS(69659),
  AV_CODEC_ID_ADPCM_G722(69660),
  AV_CODEC_ID_ADPCM_IMA_APC(69661),
  AV_CODEC_ID_ADPCM_VIMA(69662),
  AV_CODEC_ID_ADPCM_AFC(69663),
  AV_CODEC_ID_ADPCM_IMA_OKI(69664),
  AV_CODEC_ID_ADPCM_DTK(69665),
  AV_CODEC_ID_ADPCM_IMA_RAD(69666),
  AV_CODEC_ID_ADPCM_G726LE(69667),
  AV_CODEC_ID_ADPCM_THP_LE(69668),
  AV_CODEC_ID_ADPCM_PSX(69669),
  AV_CODEC_ID_ADPCM_AICA(69670),
  AV_CODEC_ID_ADPCM_IMA_DAT4(69671),
  AV_CODEC_ID_ADPCM_MTAF(69672),
  AV_CODEC_ID_ADPCM_AGM(69673),
  AV_CODEC_ID_ADPCM_ARGO(69674),
  AV_CODEC_ID_ADPCM_IMA_SSI(69675),
  AV_CODEC_ID_ADPCM_ZORK(69676),
  AV_CODEC_ID_ADPCM_IMA_APM(69677),
  AV_CODEC_ID_ADPCM_IMA_ALP(69678),
  AV_CODEC_ID_ADPCM_IMA_MTF(69679),
  AV_CODEC_ID_ADPCM_IMA_CUNNING(69680),
  AV_CODEC_ID_ADPCM_IMA_MOFLEX(69681),
  AV_CODEC_ID_ADPCM_IMA_ACORN(69682),
  AV_CODEC_ID_ADPCM_XMD(69683),
  AV_CODEC_ID_AMR_NB(73728),
  AV_CODEC_ID_AMR_WB(73729),
  AV_CODEC_ID_RA_144(77824),
  AV_CODEC_ID_RA_288(77825),
  AV_CODEC_ID_ROQ_DPCM(81920),
  AV_CODEC_ID_INTERPLAY_DPCM(81921),
  AV_CODEC_ID_XAN_DPCM(81922),
  AV_CODEC_ID_SOL_DPCM(81923),
  AV_CODEC_ID_SDX2_DPCM(81924),
  AV_CODEC_ID_GREMLIN_DPCM(81925),
  AV_CODEC_ID_DERF_DPCM(81926),
  AV_CODEC_ID_WADY_DPCM(81927),
  AV_CODEC_ID_CBD2_DPCM(81928),
  AV_CODEC_ID_MP2(86016),

  /// < preferred ID for decoding MPEG audio layer 1, 2 or 3
  AV_CODEC_ID_MP3(86017),
  AV_CODEC_ID_AAC(86018),
  AV_CODEC_ID_AC3(86019),
  AV_CODEC_ID_DTS(86020),
  AV_CODEC_ID_VORBIS(86021),
  AV_CODEC_ID_DVAUDIO(86022),
  AV_CODEC_ID_WMAV1(86023),
  AV_CODEC_ID_WMAV2(86024),
  AV_CODEC_ID_MACE3(86025),
  AV_CODEC_ID_MACE6(86026),
  AV_CODEC_ID_VMDAUDIO(86027),
  AV_CODEC_ID_FLAC(86028),
  AV_CODEC_ID_MP3ADU(86029),
  AV_CODEC_ID_MP3ON4(86030),
  AV_CODEC_ID_SHORTEN(86031),
  AV_CODEC_ID_ALAC(86032),
  AV_CODEC_ID_WESTWOOD_SND1(86033),

  /// < as in Berlin toast format
  AV_CODEC_ID_GSM(86034),
  AV_CODEC_ID_QDM2(86035),
  AV_CODEC_ID_COOK(86036),
  AV_CODEC_ID_TRUESPEECH(86037),
  AV_CODEC_ID_TTA(86038),
  AV_CODEC_ID_SMACKAUDIO(86039),
  AV_CODEC_ID_QCELP(86040),
  AV_CODEC_ID_WAVPACK(86041),
  AV_CODEC_ID_DSICINAUDIO(86042),
  AV_CODEC_ID_IMC(86043),
  AV_CODEC_ID_MUSEPACK7(86044),
  AV_CODEC_ID_MLP(86045),
  AV_CODEC_ID_GSM_MS(86046),
  AV_CODEC_ID_ATRAC3(86047),
  AV_CODEC_ID_APE(86048),
  AV_CODEC_ID_NELLYMOSER(86049),
  AV_CODEC_ID_MUSEPACK8(86050),
  AV_CODEC_ID_SPEEX(86051),
  AV_CODEC_ID_WMAVOICE(86052),
  AV_CODEC_ID_WMAPRO(86053),
  AV_CODEC_ID_WMALOSSLESS(86054),
  AV_CODEC_ID_ATRAC3P(86055),
  AV_CODEC_ID_EAC3(86056),
  AV_CODEC_ID_SIPR(86057),
  AV_CODEC_ID_MP1(86058),
  AV_CODEC_ID_TWINVQ(86059),
  AV_CODEC_ID_TRUEHD(86060),
  AV_CODEC_ID_MP4ALS(86061),
  AV_CODEC_ID_ATRAC1(86062),
  AV_CODEC_ID_BINKAUDIO_RDFT(86063),
  AV_CODEC_ID_BINKAUDIO_DCT(86064),
  AV_CODEC_ID_AAC_LATM(86065),
  AV_CODEC_ID_QDMC(86066),
  AV_CODEC_ID_CELT(86067),
  AV_CODEC_ID_G723_1(86068),
  AV_CODEC_ID_G729(86069),
  AV_CODEC_ID_8SVX_EXP(86070),
  AV_CODEC_ID_8SVX_FIB(86071),
  AV_CODEC_ID_BMV_AUDIO(86072),
  AV_CODEC_ID_RALF(86073),
  AV_CODEC_ID_IAC(86074),
  AV_CODEC_ID_ILBC(86075),
  AV_CODEC_ID_OPUS(86076),
  AV_CODEC_ID_COMFORT_NOISE(86077),
  AV_CODEC_ID_TAK(86078),
  AV_CODEC_ID_METASOUND(86079),
  AV_CODEC_ID_PAF_AUDIO(86080),
  AV_CODEC_ID_ON2AVC(86081),
  AV_CODEC_ID_DSS_SP(86082),
  AV_CODEC_ID_CODEC2(86083),
  AV_CODEC_ID_FFWAVESYNTH(86084),
  AV_CODEC_ID_SONIC(86085),
  AV_CODEC_ID_SONIC_LS(86086),
  AV_CODEC_ID_EVRC(86087),
  AV_CODEC_ID_SMV(86088),
  AV_CODEC_ID_DSD_LSBF(86089),
  AV_CODEC_ID_DSD_MSBF(86090),
  AV_CODEC_ID_DSD_LSBF_PLANAR(86091),
  AV_CODEC_ID_DSD_MSBF_PLANAR(86092),
  AV_CODEC_ID_4GV(86093),
  AV_CODEC_ID_INTERPLAY_ACM(86094),
  AV_CODEC_ID_XMA1(86095),
  AV_CODEC_ID_XMA2(86096),
  AV_CODEC_ID_DST(86097),
  AV_CODEC_ID_ATRAC3AL(86098),
  AV_CODEC_ID_ATRAC3PAL(86099),
  AV_CODEC_ID_DOLBY_E(86100),
  AV_CODEC_ID_APTX(86101),
  AV_CODEC_ID_APTX_HD(86102),
  AV_CODEC_ID_SBC(86103),
  AV_CODEC_ID_ATRAC9(86104),
  AV_CODEC_ID_HCOM(86105),
  AV_CODEC_ID_ACELP_KELVIN(86106),
  AV_CODEC_ID_MPEGH_3D_AUDIO(86107),
  AV_CODEC_ID_SIREN(86108),
  AV_CODEC_ID_HCA(86109),
  AV_CODEC_ID_FASTAUDIO(86110),
  AV_CODEC_ID_MSNSIREN(86111),
  AV_CODEC_ID_DFPWM(86112),
  AV_CODEC_ID_BONK(86113),
  AV_CODEC_ID_MISC4(86114),
  AV_CODEC_ID_APAC(86115),
  AV_CODEC_ID_FTR(86116),
  AV_CODEC_ID_WAVARC(86117),
  AV_CODEC_ID_RKA(86118),
  AV_CODEC_ID_AC4(86119),
  AV_CODEC_ID_OSQ(86120),
  AV_CODEC_ID_QOA(86121),
  AV_CODEC_ID_LC3(86122),

  /// < A dummy ID pointing at the start of subtitle codecs.
  AV_CODEC_ID_FIRST_SUBTITLE(94208),
  AV_CODEC_ID_DVB_SUBTITLE(94209),

  /// < raw UTF-8 text
  AV_CODEC_ID_TEXT(94210),
  AV_CODEC_ID_XSUB(94211),
  AV_CODEC_ID_SSA(94212),
  AV_CODEC_ID_MOV_TEXT(94213),
  AV_CODEC_ID_HDMV_PGS_SUBTITLE(94214),
  AV_CODEC_ID_DVB_TELETEXT(94215),
  AV_CODEC_ID_SRT(94216),
  AV_CODEC_ID_MICRODVD(94217),
  AV_CODEC_ID_EIA_608(94218),
  AV_CODEC_ID_JACOSUB(94219),
  AV_CODEC_ID_SAMI(94220),
  AV_CODEC_ID_REALTEXT(94221),
  AV_CODEC_ID_STL(94222),
  AV_CODEC_ID_SUBVIEWER1(94223),
  AV_CODEC_ID_SUBVIEWER(94224),
  AV_CODEC_ID_SUBRIP(94225),
  AV_CODEC_ID_WEBVTT(94226),
  AV_CODEC_ID_MPL2(94227),
  AV_CODEC_ID_VPLAYER(94228),
  AV_CODEC_ID_PJS(94229),
  AV_CODEC_ID_ASS(94230),
  AV_CODEC_ID_HDMV_TEXT_SUBTITLE(94231),
  AV_CODEC_ID_TTML(94232),
  AV_CODEC_ID_ARIB_CAPTION(94233),

  /// < A dummy ID pointing at the start of various fake codecs.
  AV_CODEC_ID_FIRST_UNKNOWN(98304),

  /// < Contain timestamp estimated through PCR of program stream.
  AV_CODEC_ID_SCTE_35(98305),
  AV_CODEC_ID_EPG(98306),
  AV_CODEC_ID_BINTEXT(98307),
  AV_CODEC_ID_XBIN(98308),
  AV_CODEC_ID_IDF(98309),
  AV_CODEC_ID_OTF(98310),
  AV_CODEC_ID_SMPTE_KLV(98311),
  AV_CODEC_ID_DVD_NAV(98312),
  AV_CODEC_ID_TIMED_ID3(98313),
  AV_CODEC_ID_BIN_DATA(98314),
  AV_CODEC_ID_SMPTE_2038(98315),
  AV_CODEC_ID_LCEVC(98316),

  /// < codec_id is not known (like AV_CODEC_ID_NONE) but lavf should attempt to identify it
  AV_CODEC_ID_PROBE(102400),

  /// < _FAKE_ codec to indicate a raw MPEG-2 TS
  /// stream (only used by libavformat)
  AV_CODEC_ID_MPEG2TS(131072),

  /// < _FAKE_ codec to indicate a MPEG-4 Systems
  /// stream (only used by libavformat)
  AV_CODEC_ID_MPEG4SYSTEMS(131073),

  /// < Dummy codec for streams containing only metadata information.
  AV_CODEC_ID_FFMETADATA(135168),

  /// < Passthrough codec, AVFrames wrapped in AVPacket
  AV_CODEC_ID_WRAPPED_AVFRAME(135169),

  /// Dummy null video codec, useful mainly for development and debugging.
  /// Null encoder/decoder discard all input and never return any output.
  AV_CODEC_ID_VNULL(135170),

  /// Dummy null audio codec, useful mainly for development and debugging.
  /// Null encoder/decoder discard all input and never return any output.
  AV_CODEC_ID_ANULL(135171);

  static const AV_CODEC_ID_PCM_S16LE = AV_CODEC_ID_FIRST_AUDIO;
  static const AV_CODEC_ID_DVD_SUBTITLE = AV_CODEC_ID_FIRST_SUBTITLE;
  static const AV_CODEC_ID_TTF = AV_CODEC_ID_FIRST_UNKNOWN;

  final int value;
  const AVCodecID(this.value);

  static AVCodecID fromValue(int value) => switch (value) {
        0 => AV_CODEC_ID_NONE,
        1 => AV_CODEC_ID_MPEG1VIDEO,
        2 => AV_CODEC_ID_MPEG2VIDEO,
        3 => AV_CODEC_ID_H261,
        4 => AV_CODEC_ID_H263,
        5 => AV_CODEC_ID_RV10,
        6 => AV_CODEC_ID_RV20,
        7 => AV_CODEC_ID_MJPEG,
        8 => AV_CODEC_ID_MJPEGB,
        9 => AV_CODEC_ID_LJPEG,
        10 => AV_CODEC_ID_SP5X,
        11 => AV_CODEC_ID_JPEGLS,
        12 => AV_CODEC_ID_MPEG4,
        13 => AV_CODEC_ID_RAWVIDEO,
        14 => AV_CODEC_ID_MSMPEG4V1,
        15 => AV_CODEC_ID_MSMPEG4V2,
        16 => AV_CODEC_ID_MSMPEG4V3,
        17 => AV_CODEC_ID_WMV1,
        18 => AV_CODEC_ID_WMV2,
        19 => AV_CODEC_ID_H263P,
        20 => AV_CODEC_ID_H263I,
        21 => AV_CODEC_ID_FLV1,
        22 => AV_CODEC_ID_SVQ1,
        23 => AV_CODEC_ID_SVQ3,
        24 => AV_CODEC_ID_DVVIDEO,
        25 => AV_CODEC_ID_HUFFYUV,
        26 => AV_CODEC_ID_CYUV,
        27 => AV_CODEC_ID_H264,
        28 => AV_CODEC_ID_INDEO3,
        29 => AV_CODEC_ID_VP3,
        30 => AV_CODEC_ID_THEORA,
        31 => AV_CODEC_ID_ASV1,
        32 => AV_CODEC_ID_ASV2,
        33 => AV_CODEC_ID_FFV1,
        34 => AV_CODEC_ID_4XM,
        35 => AV_CODEC_ID_VCR1,
        36 => AV_CODEC_ID_CLJR,
        37 => AV_CODEC_ID_MDEC,
        38 => AV_CODEC_ID_ROQ,
        39 => AV_CODEC_ID_INTERPLAY_VIDEO,
        40 => AV_CODEC_ID_XAN_WC3,
        41 => AV_CODEC_ID_XAN_WC4,
        42 => AV_CODEC_ID_RPZA,
        43 => AV_CODEC_ID_CINEPAK,
        44 => AV_CODEC_ID_WS_VQA,
        45 => AV_CODEC_ID_MSRLE,
        46 => AV_CODEC_ID_MSVIDEO1,
        47 => AV_CODEC_ID_IDCIN,
        48 => AV_CODEC_ID_8BPS,
        49 => AV_CODEC_ID_SMC,
        50 => AV_CODEC_ID_FLIC,
        51 => AV_CODEC_ID_TRUEMOTION1,
        52 => AV_CODEC_ID_VMDVIDEO,
        53 => AV_CODEC_ID_MSZH,
        54 => AV_CODEC_ID_ZLIB,
        55 => AV_CODEC_ID_QTRLE,
        56 => AV_CODEC_ID_TSCC,
        57 => AV_CODEC_ID_ULTI,
        58 => AV_CODEC_ID_QDRAW,
        59 => AV_CODEC_ID_VIXL,
        60 => AV_CODEC_ID_QPEG,
        61 => AV_CODEC_ID_PNG,
        62 => AV_CODEC_ID_PPM,
        63 => AV_CODEC_ID_PBM,
        64 => AV_CODEC_ID_PGM,
        65 => AV_CODEC_ID_PGMYUV,
        66 => AV_CODEC_ID_PAM,
        67 => AV_CODEC_ID_FFVHUFF,
        68 => AV_CODEC_ID_RV30,
        69 => AV_CODEC_ID_RV40,
        70 => AV_CODEC_ID_VC1,
        71 => AV_CODEC_ID_WMV3,
        72 => AV_CODEC_ID_LOCO,
        73 => AV_CODEC_ID_WNV1,
        74 => AV_CODEC_ID_AASC,
        75 => AV_CODEC_ID_INDEO2,
        76 => AV_CODEC_ID_FRAPS,
        77 => AV_CODEC_ID_TRUEMOTION2,
        78 => AV_CODEC_ID_BMP,
        79 => AV_CODEC_ID_CSCD,
        80 => AV_CODEC_ID_MMVIDEO,
        81 => AV_CODEC_ID_ZMBV,
        82 => AV_CODEC_ID_AVS,
        83 => AV_CODEC_ID_SMACKVIDEO,
        84 => AV_CODEC_ID_NUV,
        85 => AV_CODEC_ID_KMVC,
        86 => AV_CODEC_ID_FLASHSV,
        87 => AV_CODEC_ID_CAVS,
        88 => AV_CODEC_ID_JPEG2000,
        89 => AV_CODEC_ID_VMNC,
        90 => AV_CODEC_ID_VP5,
        91 => AV_CODEC_ID_VP6,
        92 => AV_CODEC_ID_VP6F,
        93 => AV_CODEC_ID_TARGA,
        94 => AV_CODEC_ID_DSICINVIDEO,
        95 => AV_CODEC_ID_TIERTEXSEQVIDEO,
        96 => AV_CODEC_ID_TIFF,
        97 => AV_CODEC_ID_GIF,
        98 => AV_CODEC_ID_DXA,
        99 => AV_CODEC_ID_DNXHD,
        100 => AV_CODEC_ID_THP,
        101 => AV_CODEC_ID_SGI,
        102 => AV_CODEC_ID_C93,
        103 => AV_CODEC_ID_BETHSOFTVID,
        104 => AV_CODEC_ID_PTX,
        105 => AV_CODEC_ID_TXD,
        106 => AV_CODEC_ID_VP6A,
        107 => AV_CODEC_ID_AMV,
        108 => AV_CODEC_ID_VB,
        109 => AV_CODEC_ID_PCX,
        110 => AV_CODEC_ID_SUNRAST,
        111 => AV_CODEC_ID_INDEO4,
        112 => AV_CODEC_ID_INDEO5,
        113 => AV_CODEC_ID_MIMIC,
        114 => AV_CODEC_ID_RL2,
        115 => AV_CODEC_ID_ESCAPE124,
        116 => AV_CODEC_ID_DIRAC,
        117 => AV_CODEC_ID_BFI,
        118 => AV_CODEC_ID_CMV,
        119 => AV_CODEC_ID_MOTIONPIXELS,
        120 => AV_CODEC_ID_TGV,
        121 => AV_CODEC_ID_TGQ,
        122 => AV_CODEC_ID_TQI,
        123 => AV_CODEC_ID_AURA,
        124 => AV_CODEC_ID_AURA2,
        125 => AV_CODEC_ID_V210X,
        126 => AV_CODEC_ID_TMV,
        127 => AV_CODEC_ID_V210,
        128 => AV_CODEC_ID_DPX,
        129 => AV_CODEC_ID_MAD,
        130 => AV_CODEC_ID_FRWU,
        131 => AV_CODEC_ID_FLASHSV2,
        132 => AV_CODEC_ID_CDGRAPHICS,
        133 => AV_CODEC_ID_R210,
        134 => AV_CODEC_ID_ANM,
        135 => AV_CODEC_ID_BINKVIDEO,
        136 => AV_CODEC_ID_IFF_ILBM,
        137 => AV_CODEC_ID_KGV1,
        138 => AV_CODEC_ID_YOP,
        139 => AV_CODEC_ID_VP8,
        140 => AV_CODEC_ID_PICTOR,
        141 => AV_CODEC_ID_ANSI,
        142 => AV_CODEC_ID_A64_MULTI,
        143 => AV_CODEC_ID_A64_MULTI5,
        144 => AV_CODEC_ID_R10K,
        145 => AV_CODEC_ID_MXPEG,
        146 => AV_CODEC_ID_LAGARITH,
        147 => AV_CODEC_ID_PRORES,
        148 => AV_CODEC_ID_JV,
        149 => AV_CODEC_ID_DFA,
        150 => AV_CODEC_ID_WMV3IMAGE,
        151 => AV_CODEC_ID_VC1IMAGE,
        152 => AV_CODEC_ID_UTVIDEO,
        153 => AV_CODEC_ID_BMV_VIDEO,
        154 => AV_CODEC_ID_VBLE,
        155 => AV_CODEC_ID_DXTORY,
        156 => AV_CODEC_ID_V410,
        157 => AV_CODEC_ID_XWD,
        158 => AV_CODEC_ID_CDXL,
        159 => AV_CODEC_ID_XBM,
        160 => AV_CODEC_ID_ZEROCODEC,
        161 => AV_CODEC_ID_MSS1,
        162 => AV_CODEC_ID_MSA1,
        163 => AV_CODEC_ID_TSCC2,
        164 => AV_CODEC_ID_MTS2,
        165 => AV_CODEC_ID_CLLC,
        166 => AV_CODEC_ID_MSS2,
        167 => AV_CODEC_ID_VP9,
        168 => AV_CODEC_ID_AIC,
        169 => AV_CODEC_ID_ESCAPE130,
        170 => AV_CODEC_ID_G2M,
        171 => AV_CODEC_ID_WEBP,
        172 => AV_CODEC_ID_HNM4_VIDEO,
        173 => AV_CODEC_ID_HEVC,
        174 => AV_CODEC_ID_FIC,
        175 => AV_CODEC_ID_ALIAS_PIX,
        176 => AV_CODEC_ID_BRENDER_PIX,
        177 => AV_CODEC_ID_PAF_VIDEO,
        178 => AV_CODEC_ID_EXR,
        179 => AV_CODEC_ID_VP7,
        180 => AV_CODEC_ID_SANM,
        181 => AV_CODEC_ID_SGIRLE,
        182 => AV_CODEC_ID_MVC1,
        183 => AV_CODEC_ID_MVC2,
        184 => AV_CODEC_ID_HQX,
        185 => AV_CODEC_ID_TDSC,
        186 => AV_CODEC_ID_HQ_HQA,
        187 => AV_CODEC_ID_HAP,
        188 => AV_CODEC_ID_DDS,
        189 => AV_CODEC_ID_DXV,
        190 => AV_CODEC_ID_SCREENPRESSO,
        191 => AV_CODEC_ID_RSCC,
        192 => AV_CODEC_ID_AVS2,
        193 => AV_CODEC_ID_PGX,
        194 => AV_CODEC_ID_AVS3,
        195 => AV_CODEC_ID_MSP2,
        196 => AV_CODEC_ID_VVC,
        197 => AV_CODEC_ID_Y41P,
        198 => AV_CODEC_ID_AVRP,
        199 => AV_CODEC_ID_012V,
        200 => AV_CODEC_ID_AVUI,
        201 => AV_CODEC_ID_TARGA_Y216,
        202 => AV_CODEC_ID_V308,
        203 => AV_CODEC_ID_V408,
        204 => AV_CODEC_ID_YUV4,
        205 => AV_CODEC_ID_AVRN,
        206 => AV_CODEC_ID_CPIA,
        207 => AV_CODEC_ID_XFACE,
        208 => AV_CODEC_ID_SNOW,
        209 => AV_CODEC_ID_SMVJPEG,
        210 => AV_CODEC_ID_APNG,
        211 => AV_CODEC_ID_DAALA,
        212 => AV_CODEC_ID_CFHD,
        213 => AV_CODEC_ID_TRUEMOTION2RT,
        214 => AV_CODEC_ID_M101,
        215 => AV_CODEC_ID_MAGICYUV,
        216 => AV_CODEC_ID_SHEERVIDEO,
        217 => AV_CODEC_ID_YLC,
        218 => AV_CODEC_ID_PSD,
        219 => AV_CODEC_ID_PIXLET,
        220 => AV_CODEC_ID_SPEEDHQ,
        221 => AV_CODEC_ID_FMVC,
        222 => AV_CODEC_ID_SCPR,
        223 => AV_CODEC_ID_CLEARVIDEO,
        224 => AV_CODEC_ID_XPM,
        225 => AV_CODEC_ID_AV1,
        226 => AV_CODEC_ID_BITPACKED,
        227 => AV_CODEC_ID_MSCC,
        228 => AV_CODEC_ID_SRGC,
        229 => AV_CODEC_ID_SVG,
        230 => AV_CODEC_ID_GDV,
        231 => AV_CODEC_ID_FITS,
        232 => AV_CODEC_ID_IMM4,
        233 => AV_CODEC_ID_PROSUMER,
        234 => AV_CODEC_ID_MWSC,
        235 => AV_CODEC_ID_WCMV,
        236 => AV_CODEC_ID_RASC,
        237 => AV_CODEC_ID_HYMT,
        238 => AV_CODEC_ID_ARBC,
        239 => AV_CODEC_ID_AGM,
        240 => AV_CODEC_ID_LSCR,
        241 => AV_CODEC_ID_VP4,
        242 => AV_CODEC_ID_IMM5,
        243 => AV_CODEC_ID_MVDV,
        244 => AV_CODEC_ID_MVHA,
        245 => AV_CODEC_ID_CDTOONS,
        246 => AV_CODEC_ID_MV30,
        247 => AV_CODEC_ID_NOTCHLC,
        248 => AV_CODEC_ID_PFM,
        249 => AV_CODEC_ID_MOBICLIP,
        250 => AV_CODEC_ID_PHOTOCD,
        251 => AV_CODEC_ID_IPU,
        252 => AV_CODEC_ID_ARGO,
        253 => AV_CODEC_ID_CRI,
        254 => AV_CODEC_ID_SIMBIOSIS_IMX,
        255 => AV_CODEC_ID_SGA_VIDEO,
        256 => AV_CODEC_ID_GEM,
        257 => AV_CODEC_ID_VBN,
        258 => AV_CODEC_ID_JPEGXL,
        259 => AV_CODEC_ID_QOI,
        260 => AV_CODEC_ID_PHM,
        261 => AV_CODEC_ID_RADIANCE_HDR,
        262 => AV_CODEC_ID_WBMP,
        263 => AV_CODEC_ID_MEDIA100,
        264 => AV_CODEC_ID_VQC,
        265 => AV_CODEC_ID_PDV,
        266 => AV_CODEC_ID_EVC,
        267 => AV_CODEC_ID_RTV1,
        268 => AV_CODEC_ID_VMIX,
        269 => AV_CODEC_ID_LEAD,
        65536 => AV_CODEC_ID_FIRST_AUDIO,
        65537 => AV_CODEC_ID_PCM_S16BE,
        65538 => AV_CODEC_ID_PCM_U16LE,
        65539 => AV_CODEC_ID_PCM_U16BE,
        65540 => AV_CODEC_ID_PCM_S8,
        65541 => AV_CODEC_ID_PCM_U8,
        65542 => AV_CODEC_ID_PCM_MULAW,
        65543 => AV_CODEC_ID_PCM_ALAW,
        65544 => AV_CODEC_ID_PCM_S32LE,
        65545 => AV_CODEC_ID_PCM_S32BE,
        65546 => AV_CODEC_ID_PCM_U32LE,
        65547 => AV_CODEC_ID_PCM_U32BE,
        65548 => AV_CODEC_ID_PCM_S24LE,
        65549 => AV_CODEC_ID_PCM_S24BE,
        65550 => AV_CODEC_ID_PCM_U24LE,
        65551 => AV_CODEC_ID_PCM_U24BE,
        65552 => AV_CODEC_ID_PCM_S24DAUD,
        65553 => AV_CODEC_ID_PCM_ZORK,
        65554 => AV_CODEC_ID_PCM_S16LE_PLANAR,
        65555 => AV_CODEC_ID_PCM_DVD,
        65556 => AV_CODEC_ID_PCM_F32BE,
        65557 => AV_CODEC_ID_PCM_F32LE,
        65558 => AV_CODEC_ID_PCM_F64BE,
        65559 => AV_CODEC_ID_PCM_F64LE,
        65560 => AV_CODEC_ID_PCM_BLURAY,
        65561 => AV_CODEC_ID_PCM_LXF,
        65562 => AV_CODEC_ID_S302M,
        65563 => AV_CODEC_ID_PCM_S8_PLANAR,
        65564 => AV_CODEC_ID_PCM_S24LE_PLANAR,
        65565 => AV_CODEC_ID_PCM_S32LE_PLANAR,
        65566 => AV_CODEC_ID_PCM_S16BE_PLANAR,
        65567 => AV_CODEC_ID_PCM_S64LE,
        65568 => AV_CODEC_ID_PCM_S64BE,
        65569 => AV_CODEC_ID_PCM_F16LE,
        65570 => AV_CODEC_ID_PCM_F24LE,
        65571 => AV_CODEC_ID_PCM_VIDC,
        65572 => AV_CODEC_ID_PCM_SGA,
        69632 => AV_CODEC_ID_ADPCM_IMA_QT,
        69633 => AV_CODEC_ID_ADPCM_IMA_WAV,
        69634 => AV_CODEC_ID_ADPCM_IMA_DK3,
        69635 => AV_CODEC_ID_ADPCM_IMA_DK4,
        69636 => AV_CODEC_ID_ADPCM_IMA_WS,
        69637 => AV_CODEC_ID_ADPCM_IMA_SMJPEG,
        69638 => AV_CODEC_ID_ADPCM_MS,
        69639 => AV_CODEC_ID_ADPCM_4XM,
        69640 => AV_CODEC_ID_ADPCM_XA,
        69641 => AV_CODEC_ID_ADPCM_ADX,
        69642 => AV_CODEC_ID_ADPCM_EA,
        69643 => AV_CODEC_ID_ADPCM_G726,
        69644 => AV_CODEC_ID_ADPCM_CT,
        69645 => AV_CODEC_ID_ADPCM_SWF,
        69646 => AV_CODEC_ID_ADPCM_YAMAHA,
        69647 => AV_CODEC_ID_ADPCM_SBPRO_4,
        69648 => AV_CODEC_ID_ADPCM_SBPRO_3,
        69649 => AV_CODEC_ID_ADPCM_SBPRO_2,
        69650 => AV_CODEC_ID_ADPCM_THP,
        69651 => AV_CODEC_ID_ADPCM_IMA_AMV,
        69652 => AV_CODEC_ID_ADPCM_EA_R1,
        69653 => AV_CODEC_ID_ADPCM_EA_R3,
        69654 => AV_CODEC_ID_ADPCM_EA_R2,
        69655 => AV_CODEC_ID_ADPCM_IMA_EA_SEAD,
        69656 => AV_CODEC_ID_ADPCM_IMA_EA_EACS,
        69657 => AV_CODEC_ID_ADPCM_EA_XAS,
        69658 => AV_CODEC_ID_ADPCM_EA_MAXIS_XA,
        69659 => AV_CODEC_ID_ADPCM_IMA_ISS,
        69660 => AV_CODEC_ID_ADPCM_G722,
        69661 => AV_CODEC_ID_ADPCM_IMA_APC,
        69662 => AV_CODEC_ID_ADPCM_VIMA,
        69663 => AV_CODEC_ID_ADPCM_AFC,
        69664 => AV_CODEC_ID_ADPCM_IMA_OKI,
        69665 => AV_CODEC_ID_ADPCM_DTK,
        69666 => AV_CODEC_ID_ADPCM_IMA_RAD,
        69667 => AV_CODEC_ID_ADPCM_G726LE,
        69668 => AV_CODEC_ID_ADPCM_THP_LE,
        69669 => AV_CODEC_ID_ADPCM_PSX,
        69670 => AV_CODEC_ID_ADPCM_AICA,
        69671 => AV_CODEC_ID_ADPCM_IMA_DAT4,
        69672 => AV_CODEC_ID_ADPCM_MTAF,
        69673 => AV_CODEC_ID_ADPCM_AGM,
        69674 => AV_CODEC_ID_ADPCM_ARGO,
        69675 => AV_CODEC_ID_ADPCM_IMA_SSI,
        69676 => AV_CODEC_ID_ADPCM_ZORK,
        69677 => AV_CODEC_ID_ADPCM_IMA_APM,
        69678 => AV_CODEC_ID_ADPCM_IMA_ALP,
        69679 => AV_CODEC_ID_ADPCM_IMA_MTF,
        69680 => AV_CODEC_ID_ADPCM_IMA_CUNNING,
        69681 => AV_CODEC_ID_ADPCM_IMA_MOFLEX,
        69682 => AV_CODEC_ID_ADPCM_IMA_ACORN,
        69683 => AV_CODEC_ID_ADPCM_XMD,
        73728 => AV_CODEC_ID_AMR_NB,
        73729 => AV_CODEC_ID_AMR_WB,
        77824 => AV_CODEC_ID_RA_144,
        77825 => AV_CODEC_ID_RA_288,
        81920 => AV_CODEC_ID_ROQ_DPCM,
        81921 => AV_CODEC_ID_INTERPLAY_DPCM,
        81922 => AV_CODEC_ID_XAN_DPCM,
        81923 => AV_CODEC_ID_SOL_DPCM,
        81924 => AV_CODEC_ID_SDX2_DPCM,
        81925 => AV_CODEC_ID_GREMLIN_DPCM,
        81926 => AV_CODEC_ID_DERF_DPCM,
        81927 => AV_CODEC_ID_WADY_DPCM,
        81928 => AV_CODEC_ID_CBD2_DPCM,
        86016 => AV_CODEC_ID_MP2,
        86017 => AV_CODEC_ID_MP3,
        86018 => AV_CODEC_ID_AAC,
        86019 => AV_CODEC_ID_AC3,
        86020 => AV_CODEC_ID_DTS,
        86021 => AV_CODEC_ID_VORBIS,
        86022 => AV_CODEC_ID_DVAUDIO,
        86023 => AV_CODEC_ID_WMAV1,
        86024 => AV_CODEC_ID_WMAV2,
        86025 => AV_CODEC_ID_MACE3,
        86026 => AV_CODEC_ID_MACE6,
        86027 => AV_CODEC_ID_VMDAUDIO,
        86028 => AV_CODEC_ID_FLAC,
        86029 => AV_CODEC_ID_MP3ADU,
        86030 => AV_CODEC_ID_MP3ON4,
        86031 => AV_CODEC_ID_SHORTEN,
        86032 => AV_CODEC_ID_ALAC,
        86033 => AV_CODEC_ID_WESTWOOD_SND1,
        86034 => AV_CODEC_ID_GSM,
        86035 => AV_CODEC_ID_QDM2,
        86036 => AV_CODEC_ID_COOK,
        86037 => AV_CODEC_ID_TRUESPEECH,
        86038 => AV_CODEC_ID_TTA,
        86039 => AV_CODEC_ID_SMACKAUDIO,
        86040 => AV_CODEC_ID_QCELP,
        86041 => AV_CODEC_ID_WAVPACK,
        86042 => AV_CODEC_ID_DSICINAUDIO,
        86043 => AV_CODEC_ID_IMC,
        86044 => AV_CODEC_ID_MUSEPACK7,
        86045 => AV_CODEC_ID_MLP,
        86046 => AV_CODEC_ID_GSM_MS,
        86047 => AV_CODEC_ID_ATRAC3,
        86048 => AV_CODEC_ID_APE,
        86049 => AV_CODEC_ID_NELLYMOSER,
        86050 => AV_CODEC_ID_MUSEPACK8,
        86051 => AV_CODEC_ID_SPEEX,
        86052 => AV_CODEC_ID_WMAVOICE,
        86053 => AV_CODEC_ID_WMAPRO,
        86054 => AV_CODEC_ID_WMALOSSLESS,
        86055 => AV_CODEC_ID_ATRAC3P,
        86056 => AV_CODEC_ID_EAC3,
        86057 => AV_CODEC_ID_SIPR,
        86058 => AV_CODEC_ID_MP1,
        86059 => AV_CODEC_ID_TWINVQ,
        86060 => AV_CODEC_ID_TRUEHD,
        86061 => AV_CODEC_ID_MP4ALS,
        86062 => AV_CODEC_ID_ATRAC1,
        86063 => AV_CODEC_ID_BINKAUDIO_RDFT,
        86064 => AV_CODEC_ID_BINKAUDIO_DCT,
        86065 => AV_CODEC_ID_AAC_LATM,
        86066 => AV_CODEC_ID_QDMC,
        86067 => AV_CODEC_ID_CELT,
        86068 => AV_CODEC_ID_G723_1,
        86069 => AV_CODEC_ID_G729,
        86070 => AV_CODEC_ID_8SVX_EXP,
        86071 => AV_CODEC_ID_8SVX_FIB,
        86072 => AV_CODEC_ID_BMV_AUDIO,
        86073 => AV_CODEC_ID_RALF,
        86074 => AV_CODEC_ID_IAC,
        86075 => AV_CODEC_ID_ILBC,
        86076 => AV_CODEC_ID_OPUS,
        86077 => AV_CODEC_ID_COMFORT_NOISE,
        86078 => AV_CODEC_ID_TAK,
        86079 => AV_CODEC_ID_METASOUND,
        86080 => AV_CODEC_ID_PAF_AUDIO,
        86081 => AV_CODEC_ID_ON2AVC,
        86082 => AV_CODEC_ID_DSS_SP,
        86083 => AV_CODEC_ID_CODEC2,
        86084 => AV_CODEC_ID_FFWAVESYNTH,
        86085 => AV_CODEC_ID_SONIC,
        86086 => AV_CODEC_ID_SONIC_LS,
        86087 => AV_CODEC_ID_EVRC,
        86088 => AV_CODEC_ID_SMV,
        86089 => AV_CODEC_ID_DSD_LSBF,
        86090 => AV_CODEC_ID_DSD_MSBF,
        86091 => AV_CODEC_ID_DSD_LSBF_PLANAR,
        86092 => AV_CODEC_ID_DSD_MSBF_PLANAR,
        86093 => AV_CODEC_ID_4GV,
        86094 => AV_CODEC_ID_INTERPLAY_ACM,
        86095 => AV_CODEC_ID_XMA1,
        86096 => AV_CODEC_ID_XMA2,
        86097 => AV_CODEC_ID_DST,
        86098 => AV_CODEC_ID_ATRAC3AL,
        86099 => AV_CODEC_ID_ATRAC3PAL,
        86100 => AV_CODEC_ID_DOLBY_E,
        86101 => AV_CODEC_ID_APTX,
        86102 => AV_CODEC_ID_APTX_HD,
        86103 => AV_CODEC_ID_SBC,
        86104 => AV_CODEC_ID_ATRAC9,
        86105 => AV_CODEC_ID_HCOM,
        86106 => AV_CODEC_ID_ACELP_KELVIN,
        86107 => AV_CODEC_ID_MPEGH_3D_AUDIO,
        86108 => AV_CODEC_ID_SIREN,
        86109 => AV_CODEC_ID_HCA,
        86110 => AV_CODEC_ID_FASTAUDIO,
        86111 => AV_CODEC_ID_MSNSIREN,
        86112 => AV_CODEC_ID_DFPWM,
        86113 => AV_CODEC_ID_BONK,
        86114 => AV_CODEC_ID_MISC4,
        86115 => AV_CODEC_ID_APAC,
        86116 => AV_CODEC_ID_FTR,
        86117 => AV_CODEC_ID_WAVARC,
        86118 => AV_CODEC_ID_RKA,
        86119 => AV_CODEC_ID_AC4,
        86120 => AV_CODEC_ID_OSQ,
        86121 => AV_CODEC_ID_QOA,
        86122 => AV_CODEC_ID_LC3,
        94208 => AV_CODEC_ID_FIRST_SUBTITLE,
        94209 => AV_CODEC_ID_DVB_SUBTITLE,
        94210 => AV_CODEC_ID_TEXT,
        94211 => AV_CODEC_ID_XSUB,
        94212 => AV_CODEC_ID_SSA,
        94213 => AV_CODEC_ID_MOV_TEXT,
        94214 => AV_CODEC_ID_HDMV_PGS_SUBTITLE,
        94215 => AV_CODEC_ID_DVB_TELETEXT,
        94216 => AV_CODEC_ID_SRT,
        94217 => AV_CODEC_ID_MICRODVD,
        94218 => AV_CODEC_ID_EIA_608,
        94219 => AV_CODEC_ID_JACOSUB,
        94220 => AV_CODEC_ID_SAMI,
        94221 => AV_CODEC_ID_REALTEXT,
        94222 => AV_CODEC_ID_STL,
        94223 => AV_CODEC_ID_SUBVIEWER1,
        94224 => AV_CODEC_ID_SUBVIEWER,
        94225 => AV_CODEC_ID_SUBRIP,
        94226 => AV_CODEC_ID_WEBVTT,
        94227 => AV_CODEC_ID_MPL2,
        94228 => AV_CODEC_ID_VPLAYER,
        94229 => AV_CODEC_ID_PJS,
        94230 => AV_CODEC_ID_ASS,
        94231 => AV_CODEC_ID_HDMV_TEXT_SUBTITLE,
        94232 => AV_CODEC_ID_TTML,
        94233 => AV_CODEC_ID_ARIB_CAPTION,
        98304 => AV_CODEC_ID_FIRST_UNKNOWN,
        98305 => AV_CODEC_ID_SCTE_35,
        98306 => AV_CODEC_ID_EPG,
        98307 => AV_CODEC_ID_BINTEXT,
        98308 => AV_CODEC_ID_XBIN,
        98309 => AV_CODEC_ID_IDF,
        98310 => AV_CODEC_ID_OTF,
        98311 => AV_CODEC_ID_SMPTE_KLV,
        98312 => AV_CODEC_ID_DVD_NAV,
        98313 => AV_CODEC_ID_TIMED_ID3,
        98314 => AV_CODEC_ID_BIN_DATA,
        98315 => AV_CODEC_ID_SMPTE_2038,
        98316 => AV_CODEC_ID_LCEVC,
        102400 => AV_CODEC_ID_PROBE,
        131072 => AV_CODEC_ID_MPEG2TS,
        131073 => AV_CODEC_ID_MPEG4SYSTEMS,
        135168 => AV_CODEC_ID_FFMETADATA,
        135169 => AV_CODEC_ID_WRAPPED_AVFRAME,
        135170 => AV_CODEC_ID_VNULL,
        135171 => AV_CODEC_ID_ANULL,
        _ => throw ArgumentError("Unknown value for AVCodecID: $value"),
      };

  @override
  String toString() {
    if (this == AV_CODEC_ID_FIRST_AUDIO)
      return "AVCodecID.AV_CODEC_ID_FIRST_AUDIO, AVCodecID.AV_CODEC_ID_PCM_S16LE";
    if (this == AV_CODEC_ID_FIRST_SUBTITLE)
      return "AVCodecID.AV_CODEC_ID_FIRST_SUBTITLE, AVCodecID.AV_CODEC_ID_DVD_SUBTITLE";
    if (this == AV_CODEC_ID_FIRST_UNKNOWN)
      return "AVCodecID.AV_CODEC_ID_FIRST_UNKNOWN, AVCodecID.AV_CODEC_ID_TTF";
    return super.toString();
  }
}

enum AVFieldOrder {
  AV_FIELD_UNKNOWN(0),
  AV_FIELD_PROGRESSIVE(1),

  /// < Top coded_first, top displayed first
  AV_FIELD_TT(2),

  /// < Bottom coded first, bottom displayed first
  AV_FIELD_BB(3),

  /// < Top coded first, bottom displayed first
  AV_FIELD_TB(4),

  /// < Bottom coded first, top displayed first
  AV_FIELD_BT(5);

  final int value;
  const AVFieldOrder(this.value);

  static AVFieldOrder fromValue(int value) => switch (value) {
        0 => AV_FIELD_UNKNOWN,
        1 => AV_FIELD_PROGRESSIVE,
        2 => AV_FIELD_TT,
        3 => AV_FIELD_BB,
        4 => AV_FIELD_TB,
        5 => AV_FIELD_BT,
        _ => throw ArgumentError("Unknown value for AVFieldOrder: $value"),
      };
}

/// Visual content value range.
///
/// These values are based on definitions that can be found in multiple
/// specifications, such as ITU-T BT.709 (3.4 - Quantization of RGB, luminance
/// and colour-difference signals), ITU-T BT.2020 (Table 5 - Digital
/// Representation) as well as ITU-T BT.2100 (Table 9 - Digital 10- and 12-bit
/// integer representation). At the time of writing, the BT.2100 one is
/// recommended, as it also defines the full range representation.
///
/// Common definitions:
/// - For RGB and luma planes such as Y in YCbCr and I in ICtCp,
/// 'E' is the original value in range of 0.0 to 1.0.
/// - For chroma planes such as Cb,Cr and Ct,Cp, 'E' is the original
/// value in range of -0.5 to 0.5.
/// - 'n' is the output bit depth.
/// - For additional definitions such as rounding and clipping to valid n
/// bit unsigned integer range, please refer to BT.2100 (Table 9).
enum AVColorRange {
  AVCOL_RANGE_UNSPECIFIED(0),

  /// Narrow or limited range content.
  ///
  /// - For luma planes:
  ///
  /// (219 * E + 16) * 2^(n-8)
  ///
  /// F.ex. the range of 16-235 for 8 bits
  ///
  /// - For chroma planes:
  ///
  /// (224 * E + 128) * 2^(n-8)
  ///
  /// F.ex. the range of 16-240 for 8 bits
  AVCOL_RANGE_MPEG(1),

  /// Full range content.
  ///
  /// - For RGB and luma planes:
  ///
  /// (2^n - 1) * E
  ///
  /// F.ex. the range of 0-255 for 8 bits
  ///
  /// - For chroma planes:
  ///
  /// (2^n - 1) * E + 2^(n - 1)
  ///
  /// F.ex. the range of 1-255 for 8 bits
  AVCOL_RANGE_JPEG(2),

  /// < Not part of ABI
  AVCOL_RANGE_NB(3);

  final int value;
  const AVColorRange(this.value);

  static AVColorRange fromValue(int value) => switch (value) {
        0 => AVCOL_RANGE_UNSPECIFIED,
        1 => AVCOL_RANGE_MPEG,
        2 => AVCOL_RANGE_JPEG,
        3 => AVCOL_RANGE_NB,
        _ => throw ArgumentError("Unknown value for AVColorRange: $value"),
      };
}

/// Chromaticity coordinates of the source primaries.
/// These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.1 and ITU-T H.273.
enum AVColorPrimaries {
  AVCOL_PRI_RESERVED0(0),

  /// < also ITU-R BT1361 / IEC 61966-2-4 / SMPTE RP 177 Annex B
  AVCOL_PRI_BT709(1),
  AVCOL_PRI_UNSPECIFIED(2),
  AVCOL_PRI_RESERVED(3),

  /// < also FCC Title 47 Code of Federal Regulations 73.682 (a)(20)
  AVCOL_PRI_BT470M(4),

  /// < also ITU-R BT601-6 625 / ITU-R BT1358 625 / ITU-R BT1700 625 PAL & SECAM
  AVCOL_PRI_BT470BG(5),

  /// < also ITU-R BT601-6 525 / ITU-R BT1358 525 / ITU-R BT1700 NTSC
  AVCOL_PRI_SMPTE170M(6),

  /// < identical to above, also called "SMPTE C" even though it uses D65
  AVCOL_PRI_SMPTE240M(7),

  /// < colour filters using Illuminant C
  AVCOL_PRI_FILM(8),

  /// < ITU-R BT2020
  AVCOL_PRI_BT2020(9),

  /// < SMPTE ST 428-1 (CIE 1931 XYZ)
  AVCOL_PRI_SMPTE428(10),

  /// < SMPTE ST 431-2 (2011) / DCI P3
  AVCOL_PRI_SMPTE431(11),

  /// < SMPTE ST 432-1 (2010) / P3 D65 / Display P3
  AVCOL_PRI_SMPTE432(12),

  /// < EBU Tech. 3213-E (nothing there) / one of JEDEC P22 group phosphors
  AVCOL_PRI_EBU3213(22),

  /// < Not part of ABI
  AVCOL_PRI_NB(23);

  static const AVCOL_PRI_SMPTEST428_1 = AVCOL_PRI_SMPTE428;
  static const AVCOL_PRI_JEDEC_P22 = AVCOL_PRI_EBU3213;

  final int value;
  const AVColorPrimaries(this.value);

  static AVColorPrimaries fromValue(int value) => switch (value) {
        0 => AVCOL_PRI_RESERVED0,
        1 => AVCOL_PRI_BT709,
        2 => AVCOL_PRI_UNSPECIFIED,
        3 => AVCOL_PRI_RESERVED,
        4 => AVCOL_PRI_BT470M,
        5 => AVCOL_PRI_BT470BG,
        6 => AVCOL_PRI_SMPTE170M,
        7 => AVCOL_PRI_SMPTE240M,
        8 => AVCOL_PRI_FILM,
        9 => AVCOL_PRI_BT2020,
        10 => AVCOL_PRI_SMPTE428,
        11 => AVCOL_PRI_SMPTE431,
        12 => AVCOL_PRI_SMPTE432,
        22 => AVCOL_PRI_EBU3213,
        23 => AVCOL_PRI_NB,
        _ => throw ArgumentError("Unknown value for AVColorPrimaries: $value"),
      };

  @override
  String toString() {
    if (this == AVCOL_PRI_SMPTE428)
      return "AVColorPrimaries.AVCOL_PRI_SMPTE428, AVColorPrimaries.AVCOL_PRI_SMPTEST428_1";
    if (this == AVCOL_PRI_EBU3213)
      return "AVColorPrimaries.AVCOL_PRI_EBU3213, AVColorPrimaries.AVCOL_PRI_JEDEC_P22";
    return super.toString();
  }
}

/// Color Transfer Characteristic.
/// These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.2.
enum AVColorTransferCharacteristic {
  AVCOL_TRC_RESERVED0(0),

  /// < also ITU-R BT1361
  AVCOL_TRC_BT709(1),
  AVCOL_TRC_UNSPECIFIED(2),
  AVCOL_TRC_RESERVED(3),

  /// < also ITU-R BT470M / ITU-R BT1700 625 PAL & SECAM
  AVCOL_TRC_GAMMA22(4),

  /// < also ITU-R BT470BG
  AVCOL_TRC_GAMMA28(5),

  /// < also ITU-R BT601-6 525 or 625 / ITU-R BT1358 525 or 625 / ITU-R BT1700 NTSC
  AVCOL_TRC_SMPTE170M(6),
  AVCOL_TRC_SMPTE240M(7),

  /// < "Linear transfer characteristics"
  AVCOL_TRC_LINEAR(8),

  /// < "Logarithmic transfer characteristic (100:1 range)"
  AVCOL_TRC_LOG(9),

  /// < "Logarithmic transfer characteristic (100 * Sqrt(10) : 1 range)"
  AVCOL_TRC_LOG_SQRT(10),

  /// < IEC 61966-2-4
  AVCOL_TRC_IEC61966_2_4(11),

  /// < ITU-R BT1361 Extended Colour Gamut
  AVCOL_TRC_BT1361_ECG(12),

  /// < IEC 61966-2-1 (sRGB or sYCC)
  AVCOL_TRC_IEC61966_2_1(13),

  /// < ITU-R BT2020 for 10-bit system
  AVCOL_TRC_BT2020_10(14),

  /// < ITU-R BT2020 for 12-bit system
  AVCOL_TRC_BT2020_12(15),

  /// < SMPTE ST 2084 for 10-, 12-, 14- and 16-bit systems
  AVCOL_TRC_SMPTE2084(16),

  /// < SMPTE ST 428-1
  AVCOL_TRC_SMPTE428(17),

  /// < ARIB STD-B67, known as "Hybrid log-gamma"
  AVCOL_TRC_ARIB_STD_B67(18),

  /// < Not part of ABI
  AVCOL_TRC_NB(19);

  static const AVCOL_TRC_SMPTEST2084 = AVCOL_TRC_SMPTE2084;
  static const AVCOL_TRC_SMPTEST428_1 = AVCOL_TRC_SMPTE428;

  final int value;
  const AVColorTransferCharacteristic(this.value);

  static AVColorTransferCharacteristic fromValue(int value) => switch (value) {
        0 => AVCOL_TRC_RESERVED0,
        1 => AVCOL_TRC_BT709,
        2 => AVCOL_TRC_UNSPECIFIED,
        3 => AVCOL_TRC_RESERVED,
        4 => AVCOL_TRC_GAMMA22,
        5 => AVCOL_TRC_GAMMA28,
        6 => AVCOL_TRC_SMPTE170M,
        7 => AVCOL_TRC_SMPTE240M,
        8 => AVCOL_TRC_LINEAR,
        9 => AVCOL_TRC_LOG,
        10 => AVCOL_TRC_LOG_SQRT,
        11 => AVCOL_TRC_IEC61966_2_4,
        12 => AVCOL_TRC_BT1361_ECG,
        13 => AVCOL_TRC_IEC61966_2_1,
        14 => AVCOL_TRC_BT2020_10,
        15 => AVCOL_TRC_BT2020_12,
        16 => AVCOL_TRC_SMPTE2084,
        17 => AVCOL_TRC_SMPTE428,
        18 => AVCOL_TRC_ARIB_STD_B67,
        19 => AVCOL_TRC_NB,
        _ => throw ArgumentError(
            "Unknown value for AVColorTransferCharacteristic: $value"),
      };

  @override
  String toString() {
    if (this == AVCOL_TRC_SMPTE2084)
      return "AVColorTransferCharacteristic.AVCOL_TRC_SMPTE2084, AVColorTransferCharacteristic.AVCOL_TRC_SMPTEST2084";
    if (this == AVCOL_TRC_SMPTE428)
      return "AVColorTransferCharacteristic.AVCOL_TRC_SMPTE428, AVColorTransferCharacteristic.AVCOL_TRC_SMPTEST428_1";
    return super.toString();
  }
}

/// YUV colorspace type.
/// These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.3.
enum AVColorSpace {
  /// < order of coefficients is actually GBR, also IEC 61966-2-1 (sRGB), YZX and ST 428-1
  AVCOL_SPC_RGB(0),

  /// < also ITU-R BT1361 / IEC 61966-2-4 xvYCC709 / derived in SMPTE RP 177 Annex B
  AVCOL_SPC_BT709(1),
  AVCOL_SPC_UNSPECIFIED(2),

  /// < reserved for future use by ITU-T and ISO/IEC just like 15-255 are
  AVCOL_SPC_RESERVED(3),

  /// < FCC Title 47 Code of Federal Regulations 73.682 (a)(20)
  AVCOL_SPC_FCC(4),

  /// < also ITU-R BT601-6 625 / ITU-R BT1358 625 / ITU-R BT1700 625 PAL & SECAM / IEC 61966-2-4 xvYCC601
  AVCOL_SPC_BT470BG(5),

  /// < also ITU-R BT601-6 525 / ITU-R BT1358 525 / ITU-R BT1700 NTSC / functionally identical to above
  AVCOL_SPC_SMPTE170M(6),

  /// < derived from 170M primaries and D65 white point, 170M is derived from BT470 System M's primaries
  AVCOL_SPC_SMPTE240M(7),

  /// < used by Dirac / VC-2 and H.264 FRext, see ITU-T SG16
  AVCOL_SPC_YCGCO(8),

  /// < ITU-R BT2020 non-constant luminance system
  AVCOL_SPC_BT2020_NCL(9),

  /// < ITU-R BT2020 constant luminance system
  AVCOL_SPC_BT2020_CL(10),

  /// < SMPTE 2085, Y'D'zD'x
  AVCOL_SPC_SMPTE2085(11),

  /// < Chromaticity-derived non-constant luminance system
  AVCOL_SPC_CHROMA_DERIVED_NCL(12),

  /// < Chromaticity-derived constant luminance system
  AVCOL_SPC_CHROMA_DERIVED_CL(13),

  /// < ITU-R BT.2100-0, ICtCp
  AVCOL_SPC_ICTCP(14),

  /// < SMPTE ST 2128, IPT-C2
  AVCOL_SPC_IPT_C2(15),

  /// < YCgCo-R, even addition of bits
  AVCOL_SPC_YCGCO_RE(16),

  /// < YCgCo-R, odd addition of bits
  AVCOL_SPC_YCGCO_RO(17),

  /// < Not part of ABI
  AVCOL_SPC_NB(18);

  static const AVCOL_SPC_YCOCG = AVCOL_SPC_YCGCO;

  final int value;
  const AVColorSpace(this.value);

  static AVColorSpace fromValue(int value) => switch (value) {
        0 => AVCOL_SPC_RGB,
        1 => AVCOL_SPC_BT709,
        2 => AVCOL_SPC_UNSPECIFIED,
        3 => AVCOL_SPC_RESERVED,
        4 => AVCOL_SPC_FCC,
        5 => AVCOL_SPC_BT470BG,
        6 => AVCOL_SPC_SMPTE170M,
        7 => AVCOL_SPC_SMPTE240M,
        8 => AVCOL_SPC_YCGCO,
        9 => AVCOL_SPC_BT2020_NCL,
        10 => AVCOL_SPC_BT2020_CL,
        11 => AVCOL_SPC_SMPTE2085,
        12 => AVCOL_SPC_CHROMA_DERIVED_NCL,
        13 => AVCOL_SPC_CHROMA_DERIVED_CL,
        14 => AVCOL_SPC_ICTCP,
        15 => AVCOL_SPC_IPT_C2,
        16 => AVCOL_SPC_YCGCO_RE,
        17 => AVCOL_SPC_YCGCO_RO,
        18 => AVCOL_SPC_NB,
        _ => throw ArgumentError("Unknown value for AVColorSpace: $value"),
      };

  @override
  String toString() {
    if (this == AVCOL_SPC_YCGCO)
      return "AVColorSpace.AVCOL_SPC_YCGCO, AVColorSpace.AVCOL_SPC_YCOCG";
    return super.toString();
  }
}

/// Location of chroma samples.
///
/// Illustration showing the location of the first (top left) chroma sample of the
/// image, the left shows only luma, the right
/// shows the location of the chroma sample, the 2 could be imagined to overlay
/// each other but are drawn separately due to limitations of ASCII
///
/// 1st 2nd       1st 2nd horizontal luma sample positions
/// v   v         v   v
/// ______        ______
/// 1st luma line > |X   X ...    |3 4 X ...     X are luma samples,
/// |             |1 2           1-6 are possible chroma positions
/// 2nd luma line > |X   X ...    |5 6 X ...     0 is undefined/unknown position
enum AVChromaLocation {
  AVCHROMA_LOC_UNSPECIFIED(0),

  /// < MPEG-2/4 4:2:0, H.264 default for 4:2:0
  AVCHROMA_LOC_LEFT(1),

  /// < MPEG-1 4:2:0, JPEG 4:2:0, H.263 4:2:0
  AVCHROMA_LOC_CENTER(2),

  /// < ITU-R 601, SMPTE 274M 296M S314M(DV 4:1:1), mpeg2 4:2:2
  AVCHROMA_LOC_TOPLEFT(3),
  AVCHROMA_LOC_TOP(4),
  AVCHROMA_LOC_BOTTOMLEFT(5),
  AVCHROMA_LOC_BOTTOM(6),

  /// < Not part of ABI
  AVCHROMA_LOC_NB(7);

  final int value;
  const AVChromaLocation(this.value);

  static AVChromaLocation fromValue(int value) => switch (value) {
        0 => AVCHROMA_LOC_UNSPECIFIED,
        1 => AVCHROMA_LOC_LEFT,
        2 => AVCHROMA_LOC_CENTER,
        3 => AVCHROMA_LOC_TOPLEFT,
        4 => AVCHROMA_LOC_TOP,
        5 => AVCHROMA_LOC_BOTTOMLEFT,
        6 => AVCHROMA_LOC_BOTTOM,
        7 => AVCHROMA_LOC_NB,
        _ => throw ArgumentError("Unknown value for AVChromaLocation: $value"),
      };
}

/// An AVChannelLayout holds information about the channel layout of audio data.
///
/// A channel layout here is defined as a set of channels ordered in a specific
/// way (unless the channel order is AV_CHANNEL_ORDER_UNSPEC, in which case an
/// AVChannelLayout carries only the channel count).
/// All orders may be treated as if they were AV_CHANNEL_ORDER_UNSPEC by
/// ignoring everything but the channel count, as long as av_channel_layout_check()
/// considers they are valid.
///
/// Unlike most structures in FFmpeg, sizeof(AVChannelLayout) is a part of the
/// public ABI and may be used by the caller. E.g. it may be allocated on stack
/// or embedded in caller-defined structs.
///
/// AVChannelLayout can be initialized as follows:
/// - default initialization with {0}, followed by setting all used fields
/// correctly;
/// - by assigning one of the predefined AV_CHANNEL_LAYOUT_* initializers;
/// - with a constructor function, such as av_channel_layout_default(),
/// av_channel_layout_from_mask() or av_channel_layout_from_string().
///
/// The channel layout must be unitialized with av_channel_layout_uninit()
///
/// Copying an AVChannelLayout via assigning is forbidden,
/// av_channel_layout_copy() must be used instead (and its return value should
/// be checked)
///
/// No new fields may be added to it without a major version bump, except for
/// new elements of the union fitting in sizeof(uint64_t).
final class AVChannelLayout extends ffi.Struct {
  /// Channel order used in this layout.
  /// This is a mandatory field.
  @ffi.UnsignedInt()
  external int orderAsInt;

  AVChannelOrder get order => AVChannelOrder.fromValue(orderAsInt);

  /// Number of channels in this layout. Mandatory field.
  @ffi.Int()
  external int nb_channels;

  external UnnamedUnion1 u;

  /// For some private data of the user.
  external ffi.Pointer<ffi.Void> opaque;
}

enum AVChannelOrder {
  /// Only the channel count is specified, without any further information
  /// about the channel order.
  AV_CHANNEL_ORDER_UNSPEC(0),

  /// The native channel order, i.e. the channels are in the same order in
  /// which they are defined in the AVChannel enum. This supports up to 63
  /// different channels.
  AV_CHANNEL_ORDER_NATIVE(1),

  /// The channel order does not correspond to any other predefined order and
  /// is stored as an explicit map. For example, this could be used to support
  /// layouts with 64 or more channels, or with empty/skipped (AV_CHAN_UNUSED)
  /// channels at arbitrary positions.
  AV_CHANNEL_ORDER_CUSTOM(2),

  /// The audio is represented as the decomposition of the sound field into
  /// spherical harmonics. Each channel corresponds to a single expansion
  /// component. Channels are ordered according to ACN (Ambisonic Channel
  /// Number).
  ///
  /// The channel with the index n in the stream contains the spherical
  /// harmonic of degree l and order m given by
  /// @code{.unparsed}
  /// l   = floor(sqrt(n)),
  /// m   = n - l * (l + 1).
  /// @endcode
  ///
  /// Conversely given a spherical harmonic of degree l and order m, the
  /// corresponding channel index n is given by
  /// @code{.unparsed}
  /// n = l * (l + 1) + m.
  /// @endcode
  ///
  /// Normalization is assumed to be SN3D (Schmidt Semi-Normalization)
  /// as defined in AmbiX format $ 2.1.
  AV_CHANNEL_ORDER_AMBISONIC(3),

  /// Number of channel orders, not part of ABI/API
  FF_CHANNEL_ORDER_NB(4);

  final int value;
  const AVChannelOrder(this.value);

  static AVChannelOrder fromValue(int value) => switch (value) {
        0 => AV_CHANNEL_ORDER_UNSPEC,
        1 => AV_CHANNEL_ORDER_NATIVE,
        2 => AV_CHANNEL_ORDER_CUSTOM,
        3 => AV_CHANNEL_ORDER_AMBISONIC,
        4 => FF_CHANNEL_ORDER_NB,
        _ => throw ArgumentError("Unknown value for AVChannelOrder: $value"),
      };
}

/// Details about which channels are present in this layout.
/// For AV_CHANNEL_ORDER_UNSPEC, this field is undefined and must not be
/// used.
final class UnnamedUnion1 extends ffi.Union {
  /// This member must be used for AV_CHANNEL_ORDER_NATIVE, and may be used
  /// for AV_CHANNEL_ORDER_AMBISONIC to signal non-diegetic channels.
  /// It is a bitmask, where the position of each set bit means that the
  /// AVChannel with the corresponding value is present.
  ///
  /// I.e. when (mask & (1 << AV_CHAN_FOO)) is non-zero, then AV_CHAN_FOO
  /// is present in the layout. Otherwise it is not present.
  ///
  /// @note when a channel layout using a bitmask is constructed or
  /// modified manually (i.e.  not using any of the av_channel_layout_*
  /// functions), the code doing it must ensure that the number of set bits
  /// is equal to nb_channels.
  @ffi.Uint64()
  external int mask;

  /// This member must be used when the channel order is
  /// AV_CHANNEL_ORDER_CUSTOM. It is a nb_channels-sized array, with each
  /// element signalling the presence of the AVChannel with the
  /// corresponding value in map[i].id.
  ///
  /// I.e. when map[i].id is equal to AV_CHAN_FOO, then AV_CH_FOO is the
  /// i-th channel in the audio data.
  ///
  /// When map[i].id is in the range between AV_CHAN_AMBISONIC_BASE and
  /// AV_CHAN_AMBISONIC_END (inclusive), the channel contains an ambisonic
  /// component with ACN index (as defined above)
  /// n = map[i].id - AV_CHAN_AMBISONIC_BASE.
  ///
  /// map[i].name may be filled with a 0-terminated string, in which case
  /// it will be used for the purpose of identifying the channel with the
  /// convenience functions below. Otherise it must be zeroed.
  external ffi.Pointer<AVChannelCustom> map;
}

/// An AVChannelCustom defines a single channel within a custom order layout
///
/// Unlike most structures in FFmpeg, sizeof(AVChannelCustom) is a part of the
/// public ABI.
///
/// No new fields may be added to it without a major version bump.
final class AVChannelCustom extends ffi.Struct {
  @ffi.Int()
  external int idAsInt;

  AVChannel get id => AVChannel.fromValue(idAsInt);

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Char> name;

  external ffi.Pointer<ffi.Void> opaque;
}

/// @defgroup lavu_audio_channels Audio channels
/// @ingroup lavu_audio
///
/// Audio channel layout utility functions
///
/// @{
enum AVChannel {
  AV_CHAN_NONE(-1),
  AV_CHAN_FRONT_LEFT(0),
  AV_CHAN_FRONT_RIGHT(1),
  AV_CHAN_FRONT_CENTER(2),
  AV_CHAN_LOW_FREQUENCY(3),
  AV_CHAN_BACK_LEFT(4),
  AV_CHAN_BACK_RIGHT(5),
  AV_CHAN_FRONT_LEFT_OF_CENTER(6),
  AV_CHAN_FRONT_RIGHT_OF_CENTER(7),
  AV_CHAN_BACK_CENTER(8),
  AV_CHAN_SIDE_LEFT(9),
  AV_CHAN_SIDE_RIGHT(10),
  AV_CHAN_TOP_CENTER(11),
  AV_CHAN_TOP_FRONT_LEFT(12),
  AV_CHAN_TOP_FRONT_CENTER(13),
  AV_CHAN_TOP_FRONT_RIGHT(14),
  AV_CHAN_TOP_BACK_LEFT(15),
  AV_CHAN_TOP_BACK_CENTER(16),
  AV_CHAN_TOP_BACK_RIGHT(17),

  /// Stereo downmix.
  AV_CHAN_STEREO_LEFT(29),

  /// See above.
  AV_CHAN_STEREO_RIGHT(30),
  AV_CHAN_WIDE_LEFT(31),
  AV_CHAN_WIDE_RIGHT(32),
  AV_CHAN_SURROUND_DIRECT_LEFT(33),
  AV_CHAN_SURROUND_DIRECT_RIGHT(34),
  AV_CHAN_LOW_FREQUENCY_2(35),
  AV_CHAN_TOP_SIDE_LEFT(36),
  AV_CHAN_TOP_SIDE_RIGHT(37),
  AV_CHAN_BOTTOM_FRONT_CENTER(38),
  AV_CHAN_BOTTOM_FRONT_LEFT(39),
  AV_CHAN_BOTTOM_FRONT_RIGHT(40),

  /// <  +90 degrees, Lss, SiL
  AV_CHAN_SIDE_SURROUND_LEFT(41),

  /// <  -90 degrees, Rss, SiR
  AV_CHAN_SIDE_SURROUND_RIGHT(42),

  /// < +110 degrees, Lvs, TpLS
  AV_CHAN_TOP_SURROUND_LEFT(43),

  /// < -110 degrees, Rvs, TpRS
  AV_CHAN_TOP_SURROUND_RIGHT(44),

  /// Channel is empty can be safely skipped.
  AV_CHAN_UNUSED(512),

  /// Channel contains data, but its position is unknown.
  AV_CHAN_UNKNOWN(768),

  /// Range of channels between AV_CHAN_AMBISONIC_BASE and
  /// AV_CHAN_AMBISONIC_END represent Ambisonic components using the ACN system.
  ///
  /// Given a channel id `<i>` between AV_CHAN_AMBISONIC_BASE and
  /// AV_CHAN_AMBISONIC_END (inclusive), the ACN index of the channel `<n>` is
  /// `<n> = <i> - AV_CHAN_AMBISONIC_BASE`.
  ///
  /// @note these values are only used for AV_CHANNEL_ORDER_CUSTOM channel
  /// orderings, the AV_CHANNEL_ORDER_AMBISONIC ordering orders the channels
  /// implicitly by their position in the stream.
  AV_CHAN_AMBISONIC_BASE(1024),
  AV_CHAN_AMBISONIC_END(2047);

  final int value;
  const AVChannel(this.value);

  static AVChannel fromValue(int value) => switch (value) {
        -1 => AV_CHAN_NONE,
        0 => AV_CHAN_FRONT_LEFT,
        1 => AV_CHAN_FRONT_RIGHT,
        2 => AV_CHAN_FRONT_CENTER,
        3 => AV_CHAN_LOW_FREQUENCY,
        4 => AV_CHAN_BACK_LEFT,
        5 => AV_CHAN_BACK_RIGHT,
        6 => AV_CHAN_FRONT_LEFT_OF_CENTER,
        7 => AV_CHAN_FRONT_RIGHT_OF_CENTER,
        8 => AV_CHAN_BACK_CENTER,
        9 => AV_CHAN_SIDE_LEFT,
        10 => AV_CHAN_SIDE_RIGHT,
        11 => AV_CHAN_TOP_CENTER,
        12 => AV_CHAN_TOP_FRONT_LEFT,
        13 => AV_CHAN_TOP_FRONT_CENTER,
        14 => AV_CHAN_TOP_FRONT_RIGHT,
        15 => AV_CHAN_TOP_BACK_LEFT,
        16 => AV_CHAN_TOP_BACK_CENTER,
        17 => AV_CHAN_TOP_BACK_RIGHT,
        29 => AV_CHAN_STEREO_LEFT,
        30 => AV_CHAN_STEREO_RIGHT,
        31 => AV_CHAN_WIDE_LEFT,
        32 => AV_CHAN_WIDE_RIGHT,
        33 => AV_CHAN_SURROUND_DIRECT_LEFT,
        34 => AV_CHAN_SURROUND_DIRECT_RIGHT,
        35 => AV_CHAN_LOW_FREQUENCY_2,
        36 => AV_CHAN_TOP_SIDE_LEFT,
        37 => AV_CHAN_TOP_SIDE_RIGHT,
        38 => AV_CHAN_BOTTOM_FRONT_CENTER,
        39 => AV_CHAN_BOTTOM_FRONT_LEFT,
        40 => AV_CHAN_BOTTOM_FRONT_RIGHT,
        41 => AV_CHAN_SIDE_SURROUND_LEFT,
        42 => AV_CHAN_SIDE_SURROUND_RIGHT,
        43 => AV_CHAN_TOP_SURROUND_LEFT,
        44 => AV_CHAN_TOP_SURROUND_RIGHT,
        512 => AV_CHAN_UNUSED,
        768 => AV_CHAN_UNKNOWN,
        1024 => AV_CHAN_AMBISONIC_BASE,
        2047 => AV_CHAN_AMBISONIC_END,
        _ => throw ArgumentError("Unknown value for AVChannel: $value"),
      };
}

/// Bytestream IO Context.
/// New public fields can be added with minor version bumps.
/// Removal, reordering and changes to existing public fields require
/// a major version bump.
/// sizeof(AVIOContext) must not be used outside libav*.
///
/// @note None of the function pointers in AVIOContext should be called
/// directly, they should only be set by the client application
/// when implementing custom I/O. Normally these are set to the
/// function pointers specified in avio_alloc_context()
final class AVIOContext extends ffi.Struct {
  /// A class for private options.
  ///
  /// If this AVIOContext is created by avio_open2(), av_class is set and
  /// passes the options down to protocols.
  ///
  /// If this AVIOContext is manually allocated, then av_class may be set by
  /// the caller.
  ///
  /// warning -- this field can be NULL, be sure to not pass this AVIOContext
  /// to any av_opt_* functions in that case.
  external ffi.Pointer<AVClass> av_class;

  /// < Start of the buffer.
  external ffi.Pointer<ffi.UnsignedChar> buffer;

  /// < Maximum buffer size
  @ffi.Int()
  external int buffer_size;

  /// < Current position in the buffer
  external ffi.Pointer<ffi.UnsignedChar> buf_ptr;

  /// < End of the data, may be less than
  /// buffer+buffer_size if the read function returned
  /// less data than requested, e.g. for streams where
  /// no more data has been received yet.
  external ffi.Pointer<ffi.UnsignedChar> buf_end;

  /// < A private pointer, passed to the read/write/seek/...
  /// functions.
  external ffi.Pointer<ffi.Void> opaque;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Void> opaque,
              ffi.Pointer<ffi.Uint8> buf, ffi.Int buf_size)>> read_packet;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Void> opaque,
              ffi.Pointer<ffi.Uint8> buf, ffi.Int buf_size)>> write_packet;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Void> opaque, ffi.Int64 offset,
              ffi.Int whence)>> seek;

  /// < position in the file of the current buffer
  @ffi.Int64()
  external int pos;

  /// < true if was unable to read due to error or eof
  @ffi.Int()
  external int eof_reached;

  /// < contains the error code or 0 if no error happened
  @ffi.Int()
  external int error;

  /// < true if open for writing
  @ffi.Int()
  external int write_flag;

  @ffi.Int()
  external int max_packet_size;

  /// < Try to buffer at least this amount of data
  /// before flushing it.
  @ffi.Int()
  external int min_packet_size;

  @ffi.UnsignedLong()
  external int checksum;

  external ffi.Pointer<ffi.UnsignedChar> checksum_ptr;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.UnsignedLong Function(
              ffi.UnsignedLong checksum,
              ffi.Pointer<ffi.Uint8> buf,
              ffi.UnsignedInt size)>> update_checksum;

  /// Pause or resume playback for network streaming protocols - e.g. MMS.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<ffi.Void> opaque, ffi.Int pause)>>
      read_pause;

  /// Seek to a given timestamp in stream with the specified stream_index.
  /// Needed for some network streaming protocols which don't support seeking
  /// to byte position.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Void> opaque, ffi.Int stream_index,
              ffi.Int64 timestamp, ffi.Int flags)>> read_seek;

  /// A combination of AVIO_SEEKABLE_ flags or 0 when the stream is not seekable.
  @ffi.Int()
  external int seekable;

  /// avio_read and avio_write should if possible be satisfied directly
  /// instead of going through a buffer, and avio_seek will always
  /// call the underlying seek function directly.
  @ffi.Int()
  external int direct;

  /// ',' separated list of allowed protocols.
  external ffi.Pointer<ffi.Char> protocol_whitelist;

  /// ',' separated list of disallowed protocols.
  external ffi.Pointer<ffi.Char> protocol_blacklist;

  /// A callback that is used instead of write_packet.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void> opaque,
              ffi.Pointer<ffi.Uint8> buf,
              ffi.Int buf_size,
              ffi.UnsignedInt type,
              ffi.Int64 time)>> write_data_type;

  /// If set, don't call write_data_type separately for AVIO_DATA_MARKER_BOUNDARY_POINT,
  /// but ignore them and treat them as AVIO_DATA_MARKER_UNKNOWN (to avoid needlessly
  /// small chunks of data returned from the callback).
  @ffi.Int()
  external int ignore_boundary_point;

  /// Maximum reached position before a backward seek in the write buffer,
  /// used keeping track of already written data for a later flush.
  external ffi.Pointer<ffi.UnsignedChar> buf_ptr_max;

  /// Read-only statistic of bytes read for this AVIOContext.
  @ffi.Int64()
  external int bytes_read;

  /// Read-only statistic of bytes written for this AVIOContext.
  @ffi.Int64()
  external int bytes_written;
}

/// Describe the class of an AVClass context structure. That is an
/// arbitrary struct of which the first field is a pointer to an
/// AVClass struct (e.g. AVCodecContext, AVFormatContext etc.).
final class AVClass extends ffi.Struct {
  /// The name of the class; usually it is the same name as the
  /// context structure type to which the AVClass is associated.
  external ffi.Pointer<ffi.Char> class_name;

  /// A pointer to a function which returns the name of a context
  /// instance ctx associated with the class.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Void> ctx)>> item_name;

  /// a pointer to the first option specified in the class if any or NULL
  ///
  /// @see av_set_default_options()
  external ffi.Pointer<AVOption> option;

  /// LIBAVUTIL_VERSION with which this structure was created.
  /// This is used to allow fields to be added without requiring major
  /// version bumps everywhere.
  @ffi.Int()
  external int version;

  /// Offset in the structure where log_level_offset is stored.
  /// 0 means there is no such variable
  @ffi.Int()
  external int log_level_offset_offset;

  /// Offset in the structure where a pointer to the parent context for
  /// logging is stored. For example a decoder could pass its AVCodecContext
  /// to eval as such a parent context, which an av_log() implementation
  /// could then leverage to display the parent context.
  /// The offset can be NULL.
  @ffi.Int()
  external int parent_log_context_offset;

  /// Category used for visualization (like color)
  /// This is only set if the category is equal for all objects using this class.
  /// available since version (51 << 16 | 56 << 8 | 100)
  @ffi.UnsignedInt()
  external int categoryAsInt;

  AVClassCategory get category => AVClassCategory.fromValue(categoryAsInt);

  /// Callback to return the category.
  /// available since version (51 << 16 | 59 << 8 | 100)
  external ffi.Pointer<
          ffi
          .NativeFunction<ffi.UnsignedInt Function(ffi.Pointer<ffi.Void> ctx)>>
      get_category;

  /// Callback to return the supported/allowed ranges.
  /// available since version (52.12)
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Pointer<AVOptionRanges>>,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>> query_ranges;

  /// Return next AVOptions-enabled child or NULL
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<ffi.Void> obj, ffi.Pointer<ffi.Void> prev)>>
      child_next;

  /// Iterate over the AVClasses corresponding to potential AVOptions-enabled
  /// children.
  ///
  /// @param iter pointer to opaque iteration state. The caller must initialize
  /// *iter to NULL before the first call.
  /// @return AVClass for the next AVOptions-enabled child or NULL if there are
  /// no more such children.
  ///
  /// @note The difference between child_next and this is that child_next
  /// iterates over _already existing_ objects, while child_class_iterate
  /// iterates over _all possible_ children.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Pointer<AVClass> Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>> iter)>> child_class_iterate;
}

/// AVOption
final class AVOption extends ffi.Struct {
  external ffi.Pointer<ffi.Char> name;

  /// short English help text
  /// @todo What about other languages?
  external ffi.Pointer<ffi.Char> help;

  /// Native access only.
  ///
  /// The offset relative to the context structure where the option
  /// value is stored. It should be 0 for named constants.
  @ffi.Int()
  external int offset;

  @ffi.UnsignedInt()
  external int typeAsInt;

  AVOptionType get type => AVOptionType.fromValue(typeAsInt);

  external UnnamedUnion2 default_val;

  /// < minimum valid value for the option
  @ffi.Double()
  external double min;

  /// < maximum valid value for the option
  @ffi.Double()
  external double max;

  /// A combination of AV_OPT_FLAG_*.
  @ffi.Int()
  external int flags;

  /// The logical unit to which the option belongs. Non-constant
  /// options and corresponding named constants share the same
  /// unit. May be NULL.
  external ffi.Pointer<ffi.Char> unit;
}

/// An option type determines:
/// - for native access, the underlying C type of the field that an AVOption
/// refers to;
/// - for foreign access, the semantics of accessing the option through this API,
/// e.g. which av_opt_get_*() and av_opt_set_*() functions can be called, or
/// what format will av_opt_get()/av_opt_set() expect/produce.
enum AVOptionType {
  /// Underlying C type is unsigned int.
  AV_OPT_TYPE_FLAGS(1),

  /// Underlying C type is int.
  AV_OPT_TYPE_INT(2),

  /// Underlying C type is int64_t.
  AV_OPT_TYPE_INT64(3),

  /// Underlying C type is double.
  AV_OPT_TYPE_DOUBLE(4),

  /// Underlying C type is float.
  AV_OPT_TYPE_FLOAT(5),

  /// Underlying C type is a uint8_t* that is either NULL or points to a C
  /// string allocated with the av_malloc() family of functions.
  AV_OPT_TYPE_STRING(6),

  /// Underlying C type is AVRational.
  AV_OPT_TYPE_RATIONAL(7),

  /// Underlying C type is a uint8_t* that is either NULL or points to an array
  /// allocated with the av_malloc() family of functions. The pointer is
  /// immediately followed by an int containing the array length in bytes.
  AV_OPT_TYPE_BINARY(8),

  /// Underlying C type is AVDictionary*.
  AV_OPT_TYPE_DICT(9),

  /// Underlying C type is uint64_t.
  AV_OPT_TYPE_UINT64(10),

  /// Special option type for declaring named constants. Does not correspond to
  /// an actual field in the object, offset must be 0.
  AV_OPT_TYPE_CONST(11),

  /// Underlying C type is two consecutive integers.
  AV_OPT_TYPE_IMAGE_SIZE(12),

  /// Underlying C type is enum AVPixelFormat.
  AV_OPT_TYPE_PIXEL_FMT(13),

  /// Underlying C type is enum AVSampleFormat.
  AV_OPT_TYPE_SAMPLE_FMT(14),

  /// Underlying C type is AVRational.
  AV_OPT_TYPE_VIDEO_RATE(15),

  /// Underlying C type is int64_t.
  AV_OPT_TYPE_DURATION(16),

  /// Underlying C type is uint8_t[4].
  AV_OPT_TYPE_COLOR(17),

  /// Underlying C type is int.
  AV_OPT_TYPE_BOOL(18),

  /// Underlying C type is AVChannelLayout.
  AV_OPT_TYPE_CHLAYOUT(19),

  /// Underlying C type is unsigned int.
  AV_OPT_TYPE_UINT(20),

  /// May be combined with another regular option type to declare an array
  /// option.
  ///
  /// For array options, @ref AVOption.offset should refer to a pointer
  /// corresponding to the option type. The pointer should be immediately
  /// followed by an unsigned int that will store the number of elements in the
  /// array.
  AV_OPT_TYPE_FLAG_ARRAY(65536);

  final int value;
  const AVOptionType(this.value);

  static AVOptionType fromValue(int value) => switch (value) {
        1 => AV_OPT_TYPE_FLAGS,
        2 => AV_OPT_TYPE_INT,
        3 => AV_OPT_TYPE_INT64,
        4 => AV_OPT_TYPE_DOUBLE,
        5 => AV_OPT_TYPE_FLOAT,
        6 => AV_OPT_TYPE_STRING,
        7 => AV_OPT_TYPE_RATIONAL,
        8 => AV_OPT_TYPE_BINARY,
        9 => AV_OPT_TYPE_DICT,
        10 => AV_OPT_TYPE_UINT64,
        11 => AV_OPT_TYPE_CONST,
        12 => AV_OPT_TYPE_IMAGE_SIZE,
        13 => AV_OPT_TYPE_PIXEL_FMT,
        14 => AV_OPT_TYPE_SAMPLE_FMT,
        15 => AV_OPT_TYPE_VIDEO_RATE,
        16 => AV_OPT_TYPE_DURATION,
        17 => AV_OPT_TYPE_COLOR,
        18 => AV_OPT_TYPE_BOOL,
        19 => AV_OPT_TYPE_CHLAYOUT,
        20 => AV_OPT_TYPE_UINT,
        65536 => AV_OPT_TYPE_FLAG_ARRAY,
        _ => throw ArgumentError("Unknown value for AVOptionType: $value"),
      };
}

/// Native access only, except when documented otherwise.
/// the default value for scalar options
final class UnnamedUnion2 extends ffi.Union {
  @ffi.Int64()
  external int i64;

  @ffi.Double()
  external double dbl;

  external ffi.Pointer<ffi.Char> str;

  external AVRational q;

  /// Used for AV_OPT_TYPE_FLAG_ARRAY options. May be NULL.
  ///
  /// Foreign access to some members allowed, as noted in AVOptionArrayDef
  /// documentation.
  external ffi.Pointer<AVOptionArrayDef> arr;
}

/// May be set as default_val for AV_OPT_TYPE_FLAG_ARRAY options.
final class AVOptionArrayDef extends ffi.Struct {
  /// Native access only.
  ///
  /// Default value of the option, as would be serialized by av_opt_get() (i.e.
  /// using the value of sep as the separator).
  external ffi.Pointer<ffi.Char> def;

  /// Minimum number of elements in the array. When this field is non-zero, def
  /// must be non-NULL and contain at least this number of elements.
  @ffi.UnsignedInt()
  external int size_min;

  /// Maximum number of elements in the array, 0 when unlimited.
  @ffi.UnsignedInt()
  external int size_max;

  /// Separator between array elements in string representations of this
  /// option, used by av_opt_set() and av_opt_get(). It must be a printable
  /// ASCII character, excluding alphanumeric and the backslash. A comma is
  /// used when sep=0.
  ///
  /// The separator and the backslash must be backslash-escaped in order to
  /// appear in string representations of the option value.
  @ffi.Char()
  external int sep;
}

enum AVClassCategory {
  AV_CLASS_CATEGORY_NA(0),
  AV_CLASS_CATEGORY_INPUT(1),
  AV_CLASS_CATEGORY_OUTPUT(2),
  AV_CLASS_CATEGORY_MUXER(3),
  AV_CLASS_CATEGORY_DEMUXER(4),
  AV_CLASS_CATEGORY_ENCODER(5),
  AV_CLASS_CATEGORY_DECODER(6),
  AV_CLASS_CATEGORY_FILTER(7),
  AV_CLASS_CATEGORY_BITSTREAM_FILTER(8),
  AV_CLASS_CATEGORY_SWSCALER(9),
  AV_CLASS_CATEGORY_SWRESAMPLER(10),
  AV_CLASS_CATEGORY_DEVICE_VIDEO_OUTPUT(40),
  AV_CLASS_CATEGORY_DEVICE_VIDEO_INPUT(41),
  AV_CLASS_CATEGORY_DEVICE_AUDIO_OUTPUT(42),
  AV_CLASS_CATEGORY_DEVICE_AUDIO_INPUT(43),
  AV_CLASS_CATEGORY_DEVICE_OUTPUT(44),
  AV_CLASS_CATEGORY_DEVICE_INPUT(45),

  /// < not part of ABI/API
  AV_CLASS_CATEGORY_NB(46);

  final int value;
  const AVClassCategory(this.value);

  static AVClassCategory fromValue(int value) => switch (value) {
        0 => AV_CLASS_CATEGORY_NA,
        1 => AV_CLASS_CATEGORY_INPUT,
        2 => AV_CLASS_CATEGORY_OUTPUT,
        3 => AV_CLASS_CATEGORY_MUXER,
        4 => AV_CLASS_CATEGORY_DEMUXER,
        5 => AV_CLASS_CATEGORY_ENCODER,
        6 => AV_CLASS_CATEGORY_DECODER,
        7 => AV_CLASS_CATEGORY_FILTER,
        8 => AV_CLASS_CATEGORY_BITSTREAM_FILTER,
        9 => AV_CLASS_CATEGORY_SWSCALER,
        10 => AV_CLASS_CATEGORY_SWRESAMPLER,
        40 => AV_CLASS_CATEGORY_DEVICE_VIDEO_OUTPUT,
        41 => AV_CLASS_CATEGORY_DEVICE_VIDEO_INPUT,
        42 => AV_CLASS_CATEGORY_DEVICE_AUDIO_OUTPUT,
        43 => AV_CLASS_CATEGORY_DEVICE_AUDIO_INPUT,
        44 => AV_CLASS_CATEGORY_DEVICE_OUTPUT,
        45 => AV_CLASS_CATEGORY_DEVICE_INPUT,
        46 => AV_CLASS_CATEGORY_NB,
        _ => throw ArgumentError("Unknown value for AVClassCategory: $value"),
      };
}

/// List of AVOptionRange structs.
final class AVOptionRanges extends ffi.Struct {
  /// Array of option ranges.
  ///
  /// Most of option types use just one component.
  /// Following describes multi-component option types:
  ///
  /// AV_OPT_TYPE_IMAGE_SIZE:
  /// component index 0: range of pixel count (width * height).
  /// component index 1: range of width.
  /// component index 2: range of height.
  ///
  /// @note To obtain multi-component version of this structure, user must
  /// provide AV_OPT_MULTI_COMPONENT_RANGE to av_opt_query_ranges or
  /// av_opt_query_ranges_default function.
  ///
  /// Multi-component range can be read as in following example:
  ///
  /// @code
  /// int range_index, component_index;
  /// AVOptionRanges *ranges;
  /// AVOptionRange *range[3]; //may require more than 3 in the future.
  /// av_opt_query_ranges(&ranges, obj, key, AV_OPT_MULTI_COMPONENT_RANGE);
  /// for (range_index = 0; range_index < ranges->nb_ranges; range_index++) {
  /// for (component_index = 0; component_index < ranges->nb_components; component_index++)
  /// range[component_index] = ranges->range[ranges->nb_ranges * component_index + range_index];
  /// //do something with range here.
  /// }
  /// av_opt_freep_ranges(&ranges);
  /// @endcode
  external ffi.Pointer<ffi.Pointer<AVOptionRange>> range;

  /// Number of ranges per component.
  @ffi.Int()
  external int nb_ranges;

  /// Number of componentes.
  @ffi.Int()
  external int nb_components;
}

/// A single allowed range of values, or a single allowed value.
final class AVOptionRange extends ffi.Struct {
  external ffi.Pointer<ffi.Char> str;

  /// Value range.
  /// For string ranges this represents the min/max length.
  /// For dimensions this represents the min/max pixel count or width/height in multi-component case.
  @ffi.Double()
  external double value_min;

  @ffi.Double()
  external double value_max;

  /// Value's component range.
  /// For string this represents the unicode range for chars, 0-127 limits to ASCII.
  @ffi.Double()
  external double component_min;

  @ffi.Double()
  external double component_max;

  /// Range flag.
  /// If set to 1 the struct encodes a range, if set to 0 a single value.
  @ffi.Int()
  external int is_range;
}

/// Different data types that can be returned via the AVIO
/// write_data_type callback.
enum AVIODataMarkerType {
  /// Header data; this needs to be present for the stream to be decodeable.
  AVIO_DATA_MARKER_HEADER(0),

  /// A point in the output bytestream where a decoder can start decoding
  /// (i.e. a keyframe). A demuxer/decoder given the data flagged with
  /// AVIO_DATA_MARKER_HEADER, followed by any AVIO_DATA_MARKER_SYNC_POINT,
  /// should give decodeable results.
  AVIO_DATA_MARKER_SYNC_POINT(1),

  /// A point in the output bytestream where a demuxer can start parsing
  /// (for non self synchronizing bytestream formats). That is, any
  /// non-keyframe packet start point.
  AVIO_DATA_MARKER_BOUNDARY_POINT(2),

  /// This is any, unlabelled data. It can either be a muxer not marking
  /// any positions at all, it can be an actual boundary/sync point
  /// that the muxer chooses not to mark, or a later part of a packet/fragment
  /// that is cut into multiple write callbacks due to limited IO buffer size.
  AVIO_DATA_MARKER_UNKNOWN(3),

  /// Trailer data, which doesn't contain actual content, but only for
  /// finalizing the output file.
  AVIO_DATA_MARKER_TRAILER(4),

  /// A point in the output bytestream where the underlying AVIOContext might
  /// flush the buffer depending on latency or buffering requirements. Typically
  /// means the end of a packet.
  AVIO_DATA_MARKER_FLUSH_POINT(5);

  final int value;
  const AVIODataMarkerType(this.value);

  static AVIODataMarkerType fromValue(int value) => switch (value) {
        0 => AVIO_DATA_MARKER_HEADER,
        1 => AVIO_DATA_MARKER_SYNC_POINT,
        2 => AVIO_DATA_MARKER_BOUNDARY_POINT,
        3 => AVIO_DATA_MARKER_UNKNOWN,
        4 => AVIO_DATA_MARKER_TRAILER,
        5 => AVIO_DATA_MARKER_FLUSH_POINT,
        _ =>
          throw ArgumentError("Unknown value for AVIODataMarkerType: $value"),
      };
}

/// Format I/O context.
/// New fields can be added to the end with minor version bumps.
/// Removal, reordering and changes to existing fields require a major
/// version bump.
/// sizeof(AVFormatContext) must not be used outside libav*, use
/// avformat_alloc_context() to create an AVFormatContext.
///
/// Fields can be accessed through AVOptions (av_opt*),
/// the name string used matches the associated command line parameter name and
/// can be found in libavformat/options_table.h.
/// The AVOption/command line parameter names differ in some cases from the C
/// structure field names for historic reasons or brevity.
final class AVFormatContext extends ffi.Struct {
  /// A class for logging and @ref avoptions. Set by avformat_alloc_context().
  /// Exports (de)muxer private options if they exist.
  external ffi.Pointer<AVClass> av_class;

  /// The input container format.
  ///
  /// Demuxing only, set by avformat_open_input().
  external ffi.Pointer<AVInputFormat> iformat;

  /// The output container format.
  ///
  /// Muxing only, must be set by the caller before avformat_write_header().
  external ffi.Pointer<AVOutputFormat> oformat;

  /// Format private data. This is an AVOptions-enabled struct
  /// if and only if iformat/oformat.priv_class is not NULL.
  ///
  /// - muxing: set by avformat_write_header()
  /// - demuxing: set by avformat_open_input()
  external ffi.Pointer<ffi.Void> priv_data;

  /// I/O context.
  ///
  /// - demuxing: either set by the user before avformat_open_input() (then
  /// the user must close it manually) or set by avformat_open_input().
  /// - muxing: set by the user before avformat_write_header(). The caller must
  /// take care of closing / freeing the IO context.
  ///
  /// Do NOT set this field if AVFMT_NOFILE flag is set in
  /// iformat/oformat.flags. In such a case, the (de)muxer will handle
  /// I/O in some other way and this field will be NULL.
  external ffi.Pointer<AVIOContext> pb;

  /// Flags signalling stream properties. A combination of AVFMTCTX_*.
  /// Set by libavformat.
  @ffi.Int()
  external int ctx_flags;

  /// Number of elements in AVFormatContext.streams.
  ///
  /// Set by avformat_new_stream(), must not be modified by any other code.
  @ffi.UnsignedInt()
  external int nb_streams;

  /// A list of all streams in the file. New streams are created with
  /// avformat_new_stream().
  ///
  /// - demuxing: streams are created by libavformat in avformat_open_input().
  /// If AVFMTCTX_NOHEADER is set in ctx_flags, then new streams may also
  /// appear in av_read_frame().
  /// - muxing: streams are created by the user before avformat_write_header().
  ///
  /// Freed by libavformat in avformat_free_context().
  external ffi.Pointer<ffi.Pointer<AVStream>> streams;

  /// Number of elements in AVFormatContext.stream_groups.
  ///
  /// Set by avformat_stream_group_create(), must not be modified by any other code.
  @ffi.UnsignedInt()
  external int nb_stream_groups;

  /// A list of all stream groups in the file. New groups are created with
  /// avformat_stream_group_create(), and filled with avformat_stream_group_add_stream().
  ///
  /// - demuxing: groups may be created by libavformat in avformat_open_input().
  /// If AVFMTCTX_NOHEADER is set in ctx_flags, then new groups may also
  /// appear in av_read_frame().
  /// - muxing: groups may be created by the user before avformat_write_header().
  ///
  /// Freed by libavformat in avformat_free_context().
  external ffi.Pointer<ffi.Pointer<AVStreamGroup>> stream_groups;

  /// Number of chapters in AVChapter array.
  /// When muxing, chapters are normally written in the file header,
  /// so nb_chapters should normally be initialized before write_header
  /// is called. Some muxers (e.g. mov and mkv) can also write chapters
  /// in the trailer.  To write chapters in the trailer, nb_chapters
  /// must be zero when write_header is called and non-zero when
  /// write_trailer is called.
  /// - muxing: set by user
  /// - demuxing: set by libavformat
  @ffi.UnsignedInt()
  external int nb_chapters;

  external ffi.Pointer<ffi.Pointer<AVChapter>> chapters;

  /// input or output URL. Unlike the old filename field, this field has no
  /// length restriction.
  ///
  /// - demuxing: set by avformat_open_input(), initialized to an empty
  /// string if url parameter was NULL in avformat_open_input().
  /// - muxing: may be set by the caller before calling avformat_write_header()
  /// (or avformat_init_output() if that is called first) to a string
  /// which is freeable by av_free(). Set to an empty string if it
  /// was NULL in avformat_init_output().
  ///
  /// Freed by libavformat in avformat_free_context().
  external ffi.Pointer<ffi.Char> url;

  /// Position of the first frame of the component, in
  /// AV_TIME_BASE fractional seconds. NEVER set this value directly:
  /// It is deduced from the AVStream values.
  ///
  /// Demuxing only, set by libavformat.
  @ffi.Int64()
  external int start_time;

  /// Duration of the stream, in AV_TIME_BASE fractional
  /// seconds. Only set this value if you know none of the individual stream
  /// durations and also do not set any of them. This is deduced from the
  /// AVStream values if not set.
  ///
  /// Demuxing only, set by libavformat.
  @ffi.Int64()
  external int duration;

  /// Total stream bitrate in bit/s, 0 if not
  /// available. Never set it directly if the file_size and the
  /// duration are known as FFmpeg can compute it automatically.
  @ffi.Int64()
  external int bit_rate;

  @ffi.UnsignedInt()
  external int packet_size;

  @ffi.Int()
  external int max_delay;

  /// Flags modifying the (de)muxer behaviour. A combination of AVFMT_FLAG_*.
  /// Set by the user before avformat_open_input() / avformat_write_header().
  @ffi.Int()
  external int flags;

  /// Maximum number of bytes read from input in order to determine stream
  /// properties. Used when reading the global header and in
  /// avformat_find_stream_info().
  ///
  /// Demuxing only, set by the caller before avformat_open_input().
  ///
  /// @note this is \e not  used for determining the \ref AVInputFormat
  /// "input format"
  /// @see format_probesize
  @ffi.Int64()
  external int probesize;

  /// Maximum duration (in AV_TIME_BASE units) of the data read
  /// from input in avformat_find_stream_info().
  /// Demuxing only, set by the caller before avformat_find_stream_info().
  /// Can be set to 0 to let avformat choose using a heuristic.
  @ffi.Int64()
  external int max_analyze_duration;

  external ffi.Pointer<ffi.Uint8> key;

  @ffi.Int()
  external int keylen;

  @ffi.UnsignedInt()
  external int nb_programs;

  external ffi.Pointer<ffi.Pointer<AVProgram>> programs;

  /// Forced video codec_id.
  /// Demuxing: Set by user.
  @ffi.UnsignedInt()
  external int video_codec_idAsInt;

  AVCodecID get video_codec_id => AVCodecID.fromValue(video_codec_idAsInt);

  /// Forced audio codec_id.
  /// Demuxing: Set by user.
  @ffi.UnsignedInt()
  external int audio_codec_idAsInt;

  AVCodecID get audio_codec_id => AVCodecID.fromValue(audio_codec_idAsInt);

  /// Forced subtitle codec_id.
  /// Demuxing: Set by user.
  @ffi.UnsignedInt()
  external int subtitle_codec_idAsInt;

  AVCodecID get subtitle_codec_id =>
      AVCodecID.fromValue(subtitle_codec_idAsInt);

  /// Forced Data codec_id.
  /// Demuxing: Set by user.
  @ffi.UnsignedInt()
  external int data_codec_idAsInt;

  AVCodecID get data_codec_id => AVCodecID.fromValue(data_codec_idAsInt);

  /// Metadata that applies to the whole file.
  ///
  /// - demuxing: set by libavformat in avformat_open_input()
  /// - muxing: may be set by the caller before avformat_write_header()
  ///
  /// Freed by libavformat in avformat_free_context().
  external ffi.Pointer<AVDictionary> metadata;

  /// Start time of the stream in real world time, in microseconds
  /// since the Unix epoch (00:00 1st January 1970). That is, pts=0 in the
  /// stream was captured at this real world time.
  /// - muxing: Set by the caller before avformat_write_header(). If set to
  /// either 0 or AV_NOPTS_VALUE, then the current wall-time will
  /// be used.
  /// - demuxing: Set by libavformat. AV_NOPTS_VALUE if unknown. Note that
  /// the value may become known after some number of frames
  /// have been received.
  @ffi.Int64()
  external int start_time_realtime;

  /// The number of frames used for determining the framerate in
  /// avformat_find_stream_info().
  /// Demuxing only, set by the caller before avformat_find_stream_info().
  @ffi.Int()
  external int fps_probe_size;

  /// Error recognition; higher values will detect more errors but may
  /// misdetect some more or less valid parts as errors.
  /// Demuxing only, set by the caller before avformat_open_input().
  @ffi.Int()
  external int error_recognition;

  /// Custom interrupt callbacks for the I/O layer.
  ///
  /// demuxing: set by the user before avformat_open_input().
  /// muxing: set by the user before avformat_write_header()
  /// (mainly useful for AVFMT_NOFILE formats). The callback
  /// should also be passed to avio_open2() if it's used to
  /// open the file.
  external AVIOInterruptCB interrupt_callback;

  /// Flags to enable debugging.
  @ffi.Int()
  external int debug;

  /// The maximum number of streams.
  /// - encoding: unused
  /// - decoding: set by user
  @ffi.Int()
  external int max_streams;

  /// Maximum amount of memory in bytes to use for the index of each stream.
  /// If the index exceeds this size, entries will be discarded as
  /// needed to maintain a smaller size. This can lead to slower or less
  /// accurate seeking (depends on demuxer).
  /// Demuxers for which a full in-memory index is mandatory will ignore
  /// this.
  /// - muxing: unused
  /// - demuxing: set by user
  @ffi.UnsignedInt()
  external int max_index_size;

  /// Maximum amount of memory in bytes to use for buffering frames
  /// obtained from realtime capture devices.
  @ffi.UnsignedInt()
  external int max_picture_buffer;

  /// Maximum buffering duration for interleaving.
  ///
  /// To ensure all the streams are interleaved correctly,
  /// av_interleaved_write_frame() will wait until it has at least one packet
  /// for each stream before actually writing any packets to the output file.
  /// When some streams are "sparse" (i.e. there are large gaps between
  /// successive packets), this can result in excessive buffering.
  ///
  /// This field specifies the maximum difference between the timestamps of the
  /// first and the last packet in the muxing queue, above which libavformat
  /// will output a packet regardless of whether it has queued a packet for all
  /// the streams.
  ///
  /// Muxing only, set by the caller before avformat_write_header().
  @ffi.Int64()
  external int max_interleave_delta;

  /// Maximum number of packets to read while waiting for the first timestamp.
  /// Decoding only.
  @ffi.Int()
  external int max_ts_probe;

  /// Max chunk time in microseconds.
  /// Note, not all formats support this and unpredictable things may happen if it is used when not supported.
  /// - encoding: Set by user
  /// - decoding: unused
  @ffi.Int()
  external int max_chunk_duration;

  /// Max chunk size in bytes
  /// Note, not all formats support this and unpredictable things may happen if it is used when not supported.
  /// - encoding: Set by user
  /// - decoding: unused
  @ffi.Int()
  external int max_chunk_size;

  /// Maximum number of packets that can be probed
  /// - encoding: unused
  /// - decoding: set by user
  @ffi.Int()
  external int max_probe_packets;

  /// Allow non-standard and experimental extension
  /// @see AVCodecContext.strict_std_compliance
  @ffi.Int()
  external int strict_std_compliance;

  /// Flags indicating events happening on the file, a combination of
  /// AVFMT_EVENT_FLAG_*.
  ///
  /// - demuxing: may be set by the demuxer in avformat_open_input(),
  /// avformat_find_stream_info() and av_read_frame(). Flags must be cleared
  /// by the user once the event has been handled.
  /// - muxing: may be set by the user after avformat_write_header() to
  /// indicate a user-triggered event.  The muxer will clear the flags for
  /// events it has handled in av_[interleaved]_write_frame().
  @ffi.Int()
  external int event_flags;

  /// Avoid negative timestamps during muxing.
  /// Any value of the AVFMT_AVOID_NEG_TS_* constants.
  /// Note, this works better when using av_interleaved_write_frame().
  /// - muxing: Set by user
  /// - demuxing: unused
  @ffi.Int()
  external int avoid_negative_ts;

  /// Audio preload in microseconds.
  /// Note, not all formats support this and unpredictable things may happen if it is used when not supported.
  /// - encoding: Set by user
  /// - decoding: unused
  @ffi.Int()
  external int audio_preload;

  /// forces the use of wallclock timestamps as pts/dts of packets
  /// This has undefined results in the presence of B frames.
  /// - encoding: unused
  /// - decoding: Set by user
  @ffi.Int()
  external int use_wallclock_as_timestamps;

  /// Skip duration calcuation in estimate_timings_from_pts.
  /// - encoding: unused
  /// - decoding: set by user
  ///
  /// @see duration_probesize
  @ffi.Int()
  external int skip_estimate_duration_from_pts;

  /// avio flags, used to force AVIO_FLAG_DIRECT.
  /// - encoding: unused
  /// - decoding: Set by user
  @ffi.Int()
  external int avio_flags;

  /// The duration field can be estimated through various ways, and this field can be used
  /// to know how the duration was estimated.
  /// - encoding: unused
  /// - decoding: Read by user
  @ffi.UnsignedInt()
  external int duration_estimation_methodAsInt;

  AVDurationEstimationMethod get duration_estimation_method =>
      AVDurationEstimationMethod.fromValue(duration_estimation_methodAsInt);

  /// Skip initial bytes when opening stream
  /// - encoding: unused
  /// - decoding: Set by user
  @ffi.Int64()
  external int skip_initial_bytes;

  /// Correct single timestamp overflows
  /// - encoding: unused
  /// - decoding: Set by user
  @ffi.UnsignedInt()
  external int correct_ts_overflow;

  /// Force seeking to any (also non key) frames.
  /// - encoding: unused
  /// - decoding: Set by user
  @ffi.Int()
  external int seek2any;

  /// Flush the I/O context after each packet.
  /// - encoding: Set by user
  /// - decoding: unused
  @ffi.Int()
  external int flush_packets;

  /// format probing score.
  /// The maximal score is AVPROBE_SCORE_MAX, its set when the demuxer probes
  /// the format.
  /// - encoding: unused
  /// - decoding: set by avformat, read by user
  @ffi.Int()
  external int probe_score;

  /// Maximum number of bytes read from input in order to identify the
  /// \ref AVInputFormat "input format". Only used when the format is not set
  /// explicitly by the caller.
  ///
  /// Demuxing only, set by the caller before avformat_open_input().
  ///
  /// @see probesize
  @ffi.Int()
  external int format_probesize;

  /// ',' separated list of allowed decoders.
  /// If NULL then all are allowed
  /// - encoding: unused
  /// - decoding: set by user
  external ffi.Pointer<ffi.Char> codec_whitelist;

  /// ',' separated list of allowed demuxers.
  /// If NULL then all are allowed
  /// - encoding: unused
  /// - decoding: set by user
  external ffi.Pointer<ffi.Char> format_whitelist;

  /// ',' separated list of allowed protocols.
  /// - encoding: unused
  /// - decoding: set by user
  external ffi.Pointer<ffi.Char> protocol_whitelist;

  /// ',' separated list of disallowed protocols.
  /// - encoding: unused
  /// - decoding: set by user
  external ffi.Pointer<ffi.Char> protocol_blacklist;

  /// IO repositioned flag.
  /// This is set by avformat when the underlaying IO context read pointer
  /// is repositioned, for example when doing byte based seeking.
  /// Demuxers can use the flag to detect such changes.
  @ffi.Int()
  external int io_repositioned;

  /// Forced video codec.
  /// This allows forcing a specific decoder, even when there are multiple with
  /// the same codec_id.
  /// Demuxing: Set by user
  external ffi.Pointer<AVCodec> video_codec;

  /// Forced audio codec.
  /// This allows forcing a specific decoder, even when there are multiple with
  /// the same codec_id.
  /// Demuxing: Set by user
  external ffi.Pointer<AVCodec> audio_codec;

  /// Forced subtitle codec.
  /// This allows forcing a specific decoder, even when there are multiple with
  /// the same codec_id.
  /// Demuxing: Set by user
  external ffi.Pointer<AVCodec> subtitle_codec;

  /// Forced data codec.
  /// This allows forcing a specific decoder, even when there are multiple with
  /// the same codec_id.
  /// Demuxing: Set by user
  external ffi.Pointer<AVCodec> data_codec;

  /// Number of bytes to be written as padding in a metadata header.
  /// Demuxing: Unused.
  /// Muxing: Set by user.
  @ffi.Int()
  external int metadata_header_padding;

  /// User data.
  /// This is a place for some private data of the user.
  external ffi.Pointer<ffi.Void> opaque;

  /// Callback used by devices to communicate with application.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<AVFormatContext>, ffi.Int,
              ffi.Pointer<ffi.Void>, ffi.Size)>> control_message_cb;

  /// Output timestamp offset, in microseconds.
  /// Muxing: set by user
  @ffi.Int64()
  external int output_ts_offset;

  /// dump format separator.
  /// can be ", " or "\n      " or anything else
  /// - muxing: Set by user.
  /// - demuxing: Set by user.
  external ffi.Pointer<ffi.Uint8> dump_separator;

  /// A callback for opening new IO streams.
  ///
  /// Whenever a muxer or a demuxer needs to open an IO stream (typically from
  /// avformat_open_input() for demuxers, but for certain formats can happen at
  /// other times as well), it will call this callback to obtain an IO context.
  ///
  /// @param s the format context
  /// @param pb on success, the newly opened IO context should be returned here
  /// @param url the url to open
  /// @param flags a combination of AVIO_FLAG_*
  /// @param options a dictionary of additional options, with the same
  /// semantics as in avio_open2()
  /// @return 0 on success, a negative AVERROR code on failure
  ///
  /// @note Certain muxers and demuxers do nesting, i.e. they open one or more
  /// additional internal format contexts. Thus the AVFormatContext pointer
  /// passed to this callback may be different from the one facing the caller.
  /// It will, however, have the same 'opaque' field.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<AVFormatContext> s,
              ffi.Pointer<ffi.Pointer<AVIOContext>> pb,
              ffi.Pointer<ffi.Char> url,
              ffi.Int flags,
              ffi.Pointer<ffi.Pointer<AVDictionary>> options)>> io_open;

  /// A callback for closing the streams opened with AVFormatContext.io_open().
  ///
  /// Using this is preferred over io_close, because this can return an error.
  /// Therefore this callback is used instead of io_close by the generic
  /// libavformat code if io_close is NULL or the default.
  ///
  /// @param s the format context
  /// @param pb IO context to be closed and freed
  /// @return 0 on success, a negative AVERROR code on failure
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Int Function(
                  ffi.Pointer<AVFormatContext> s, ffi.Pointer<AVIOContext> pb)>>
      io_close2;

  /// Maximum number of bytes read from input in order to determine stream durations
  /// when using estimate_timings_from_pts in avformat_find_stream_info().
  /// Demuxing only, set by the caller before avformat_find_stream_info().
  /// Can be set to 0 to let avformat choose using a heuristic.
  ///
  /// @see skip_estimate_duration_from_pts
  @ffi.Int64()
  external int duration_probesize;
}

/// @addtogroup lavf_decoding
/// @{
final class AVInputFormat extends ffi.Struct {
  /// A comma separated list of short names for the format. New names
  /// may be appended with a minor bump.
  external ffi.Pointer<ffi.Char> name;

  /// Descriptive name for the format, meant to be more human-readable
  /// than name. You should use the NULL_IF_CONFIG_SMALL() macro
  /// to define it.
  external ffi.Pointer<ffi.Char> long_name;

  /// Can use flags: AVFMT_NOFILE, AVFMT_NEEDNUMBER, AVFMT_SHOW_IDS,
  /// AVFMT_NOTIMESTAMPS, AVFMT_GENERIC_INDEX, AVFMT_TS_DISCONT, AVFMT_NOBINSEARCH,
  /// AVFMT_NOGENSEARCH, AVFMT_NO_BYTE_SEEK, AVFMT_SEEK_TO_PTS.
  @ffi.Int()
  external int flags;

  /// If extensions are defined, then no probe is done. You should
  /// usually not use extension format guessing because it is not
  /// reliable enough
  external ffi.Pointer<ffi.Char> extensions;

  external ffi.Pointer<ffi.Pointer<AVCodecTag>> codec_tag;

  /// < AVClass for the private context
  external ffi.Pointer<AVClass> priv_class;

  /// Comma-separated list of mime types.
  /// It is used check for matching mime types while probing.
  /// @see av_probe_input_format2
  external ffi.Pointer<ffi.Char> mime_type;
}

/// /
final class AVCodecTag extends ffi.Opaque {}

/// @addtogroup lavf_encoding
/// @{
final class AVOutputFormat extends ffi.Struct {
  external ffi.Pointer<ffi.Char> name;

  /// Descriptive name for the format, meant to be more human-readable
  /// than name. You should use the NULL_IF_CONFIG_SMALL() macro
  /// to define it.
  external ffi.Pointer<ffi.Char> long_name;

  external ffi.Pointer<ffi.Char> mime_type;

  /// < comma-separated filename extensions
  external ffi.Pointer<ffi.Char> extensions;

  /// < default audio codec
  @ffi.UnsignedInt()
  external int audio_codecAsInt;

  AVCodecID get audio_codec => AVCodecID.fromValue(audio_codecAsInt);

  /// < default video codec
  @ffi.UnsignedInt()
  external int video_codecAsInt;

  AVCodecID get video_codec => AVCodecID.fromValue(video_codecAsInt);

  /// < default subtitle codec
  @ffi.UnsignedInt()
  external int subtitle_codecAsInt;

  AVCodecID get subtitle_codec => AVCodecID.fromValue(subtitle_codecAsInt);

  /// can use flags: AVFMT_NOFILE, AVFMT_NEEDNUMBER,
  /// AVFMT_GLOBALHEADER, AVFMT_NOTIMESTAMPS, AVFMT_VARIABLE_FPS,
  /// AVFMT_NODIMENSIONS, AVFMT_NOSTREAMS,
  /// AVFMT_TS_NONSTRICT, AVFMT_TS_NEGATIVE
  @ffi.Int()
  external int flags;

  /// List of supported codec_id-codec_tag pairs, ordered by "better
  /// choice first". The arrays are all terminated by AV_CODEC_ID_NONE.
  external ffi.Pointer<ffi.Pointer<AVCodecTag>> codec_tag;

  /// < AVClass for the private context
  external ffi.Pointer<AVClass> priv_class;
}

/// Stream structure.
/// New fields can be added to the end with minor version bumps.
/// Removal, reordering and changes to existing fields require a major
/// version bump.
/// sizeof(AVStream) must not be used outside libav*.
final class AVStream extends ffi.Struct {
  /// A class for @ref avoptions. Set on stream creation.
  external ffi.Pointer<AVClass> av_class;

  /// < stream index in AVFormatContext
  @ffi.Int()
  external int index;

  /// Format-specific stream ID.
  /// decoding: set by libavformat
  /// encoding: set by the user, replaced by libavformat if left unset
  @ffi.Int()
  external int id;

  /// Codec parameters associated with this stream. Allocated and freed by
  /// libavformat in avformat_new_stream() and avformat_free_context()
  /// respectively.
  ///
  /// - demuxing: filled by libavformat on stream creation or in
  /// avformat_find_stream_info()
  /// - muxing: filled by the caller before avformat_write_header()
  external ffi.Pointer<AVCodecParameters> codecpar;

  external ffi.Pointer<ffi.Void> priv_data;

  /// This is the fundamental unit of time (in seconds) in terms
  /// of which frame timestamps are represented.
  ///
  /// decoding: set by libavformat
  /// encoding: May be set by the caller before avformat_write_header() to
  /// provide a hint to the muxer about the desired timebase. In
  /// avformat_write_header(), the muxer will overwrite this field
  /// with the timebase that will actually be used for the timestamps
  /// written into the file (which may or may not be related to the
  /// user-provided one, depending on the format).
  external AVRational time_base;

  /// Decoding: pts of the first frame of the stream in presentation order, in stream time base.
  /// Only set this if you are absolutely 100% sure that the value you set
  /// it to really is the pts of the first frame.
  /// This may be undefined (AV_NOPTS_VALUE).
  /// @note The ASF header does NOT contain a correct start_time the ASF
  /// demuxer must NOT set this.
  @ffi.Int64()
  external int start_time;

  /// Decoding: duration of the stream, in stream time base.
  /// If a source file does not specify a duration, but does specify
  /// a bitrate, this value will be estimated from bitrate and file size.
  ///
  /// Encoding: May be set by the caller before avformat_write_header() to
  /// provide a hint to the muxer about the estimated duration.
  @ffi.Int64()
  external int duration;

  /// < number of frames in this stream if known or 0
  @ffi.Int64()
  external int nb_frames;

  /// Stream disposition - a combination of AV_DISPOSITION_* flags.
  /// - demuxing: set by libavformat when creating the stream or in
  /// avformat_find_stream_info().
  /// - muxing: may be set by the caller before avformat_write_header().
  @ffi.Int()
  external int disposition;

  /// < Selects which packets can be discarded at will and do not need to be demuxed.
  @ffi.Int()
  external int discardAsInt;

  AVDiscard get discard => AVDiscard.fromValue(discardAsInt);

  /// sample aspect ratio (0 if unknown)
  /// - encoding: Set by user.
  /// - decoding: Set by libavformat.
  external AVRational sample_aspect_ratio;

  external ffi.Pointer<AVDictionary> metadata;

  /// Average framerate
  ///
  /// - demuxing: May be set by libavformat when creating the stream or in
  /// avformat_find_stream_info().
  /// - muxing: May be set by the caller before avformat_write_header().
  external AVRational avg_frame_rate;

  /// For streams with AV_DISPOSITION_ATTACHED_PIC disposition, this packet
  /// will contain the attached picture.
  ///
  /// decoding: set by libavformat, must not be modified by the caller.
  /// encoding: unused
  external AVPacket attached_pic;

  /// An array of side data that applies to the whole stream (i.e. the
  /// container does not allow it to change between packets).
  ///
  /// There may be no overlap between the side data in this array and side data
  /// in the packets. I.e. a given side data is either exported by the muxer
  /// (demuxing) / set by the caller (muxing) in this array, then it never
  /// appears in the packets, or the side data is exported / sent through
  /// the packets (always in the first packet where the value becomes known or
  /// changes), then it does not appear in this array.
  ///
  /// - demuxing: Set by libavformat when the stream is created.
  /// - muxing: May be set by the caller before avformat_write_header().
  ///
  /// Freed by libavformat in avformat_free_context().
  ///
  /// @deprecated use AVStream's @ref AVCodecParameters.coded_side_data
  /// "codecpar side data".
  external ffi.Pointer<AVPacketSideData> side_data;

  /// The number of elements in the AVStream.side_data array.
  ///
  /// @deprecated use AVStream's @ref AVCodecParameters.nb_coded_side_data
  /// "codecpar side data".
  @ffi.Int()
  external int nb_side_data;

  /// Flags indicating events happening on the stream, a combination of
  /// AVSTREAM_EVENT_FLAG_*.
  ///
  /// - demuxing: may be set by the demuxer in avformat_open_input(),
  /// avformat_find_stream_info() and av_read_frame(). Flags must be cleared
  /// by the user once the event has been handled.
  /// - muxing: may be set by the user after avformat_write_header(). to
  /// indicate a user-triggered event.  The muxer will clear the flags for
  /// events it has handled in av_[interleaved]_write_frame().
  @ffi.Int()
  external int event_flags;

  /// Real base framerate of the stream.
  /// This is the lowest framerate with which all timestamps can be
  /// represented accurately (it is the least common multiple of all
  /// framerates in the stream). Note, this value is just a guess!
  /// For example, if the time base is 1/90000 and all frames have either
  /// approximately 3600 or 1800 timer ticks, then r_frame_rate will be 50/1.
  external AVRational r_frame_rate;

  /// Number of bits in timestamps. Used for wrapping control.
  ///
  /// - demuxing: set by libavformat
  /// - muxing: set by libavformat
  @ffi.Int()
  external int pts_wrap_bits;
}

/// @ingroup lavc_decoding
enum AVDiscard {
  /// < discard nothing
  AVDISCARD_NONE(-16),

  /// < discard useless packets like 0 size packets in avi
  AVDISCARD_DEFAULT(0),

  /// < discard all non reference
  AVDISCARD_NONREF(8),

  /// < discard all bidirectional frames
  AVDISCARD_BIDIR(16),

  /// < discard all non intra frames
  AVDISCARD_NONINTRA(24),

  /// < discard all frames except keyframes
  AVDISCARD_NONKEY(32),

  /// < discard all
  AVDISCARD_ALL(48);

  final int value;
  const AVDiscard(this.value);

  static AVDiscard fromValue(int value) => switch (value) {
        -16 => AVDISCARD_NONE,
        0 => AVDISCARD_DEFAULT,
        8 => AVDISCARD_NONREF,
        16 => AVDISCARD_BIDIR,
        24 => AVDISCARD_NONINTRA,
        32 => AVDISCARD_NONKEY,
        48 => AVDISCARD_ALL,
        _ => throw ArgumentError("Unknown value for AVDiscard: $value"),
      };
}

final class AVDictionary extends ffi.Opaque {}

final class AVStreamGroup extends ffi.Struct {
  /// A class for @ref avoptions. Set by avformat_stream_group_create().
  external ffi.Pointer<AVClass> av_class;

  external ffi.Pointer<ffi.Void> priv_data;

  /// Group index in AVFormatContext.
  @ffi.UnsignedInt()
  external int index;

  /// Group type-specific group ID.
  ///
  /// decoding: set by libavformat
  /// encoding: may set by the user
  @ffi.Int64()
  external int id;

  /// Group type
  ///
  /// decoding: set by libavformat on group creation
  /// encoding: set by avformat_stream_group_create()
  @ffi.UnsignedInt()
  external int typeAsInt;

  AVStreamGroupParamsType get type =>
      AVStreamGroupParamsType.fromValue(typeAsInt);

  external UnnamedUnion3 params;

  /// Metadata that applies to the whole group.
  ///
  /// - demuxing: set by libavformat on group creation
  /// - muxing: may be set by the caller before avformat_write_header()
  ///
  /// Freed by libavformat in avformat_free_context().
  external ffi.Pointer<AVDictionary> metadata;

  /// Number of elements in AVStreamGroup.streams.
  ///
  /// Set by avformat_stream_group_add_stream() must not be modified by any other code.
  @ffi.UnsignedInt()
  external int nb_streams;

  /// A list of streams in the group. New entries are created with
  /// avformat_stream_group_add_stream().
  ///
  /// - demuxing: entries are created by libavformat on group creation.
  /// If AVFMTCTX_NOHEADER is set in ctx_flags, then new entries may also
  /// appear in av_read_frame().
  /// - muxing: entries are created by the user before avformat_write_header().
  ///
  /// Freed by libavformat in avformat_free_context().
  external ffi.Pointer<ffi.Pointer<AVStream>> streams;

  /// Stream group disposition - a combination of AV_DISPOSITION_* flags.
  /// This field currently applies to all defined AVStreamGroupParamsType.
  ///
  /// - demuxing: set by libavformat when creating the group or in
  /// avformat_find_stream_info().
  /// - muxing: may be set by the caller before avformat_write_header().
  @ffi.Int()
  external int disposition;
}

enum AVStreamGroupParamsType {
  AV_STREAM_GROUP_PARAMS_NONE(0),
  AV_STREAM_GROUP_PARAMS_IAMF_AUDIO_ELEMENT(1),
  AV_STREAM_GROUP_PARAMS_IAMF_MIX_PRESENTATION(2),
  AV_STREAM_GROUP_PARAMS_TILE_GRID(3),
  AV_STREAM_GROUP_PARAMS_LCEVC(4);

  final int value;
  const AVStreamGroupParamsType(this.value);

  static AVStreamGroupParamsType fromValue(int value) => switch (value) {
        0 => AV_STREAM_GROUP_PARAMS_NONE,
        1 => AV_STREAM_GROUP_PARAMS_IAMF_AUDIO_ELEMENT,
        2 => AV_STREAM_GROUP_PARAMS_IAMF_MIX_PRESENTATION,
        3 => AV_STREAM_GROUP_PARAMS_TILE_GRID,
        4 => AV_STREAM_GROUP_PARAMS_LCEVC,
        _ => throw ArgumentError(
            "Unknown value for AVStreamGroupParamsType: $value"),
      };
}

/// Group type-specific parameters
final class UnnamedUnion3 extends ffi.Union {
  external ffi.Pointer<AVIAMFAudioElement> iamf_audio_element;

  external ffi.Pointer<AVIAMFMixPresentation> iamf_mix_presentation;

  external ffi.Pointer<AVStreamGroupTileGrid> tile_grid;

  external ffi.Pointer<AVStreamGroupLCEVC> lcevc;
}

/// Information on how to combine one or more audio streams, as defined in
/// section 3.6 of IAMF.
///
/// @note The struct should be allocated with av_iamf_audio_element_alloc()
/// and its size is not a part of the public ABI.
final class AVIAMFAudioElement extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  external ffi.Pointer<ffi.Pointer<AVIAMFLayer>> layers;

  /// Number of layers, or channel groups, in the Audio Element.
  /// There may be 6 layers at most, and for @ref audio_element_type
  /// AV_IAMF_AUDIO_ELEMENT_TYPE_SCENE, there may be exactly 1.
  ///
  /// Set by av_iamf_audio_element_add_layer(), must not be
  /// modified by any other code.
  @ffi.UnsignedInt()
  external int nb_layers;

  /// Demixing information used to reconstruct a scalable channel audio
  /// representation.
  /// The @ref AVIAMFParamDefinition.type "type" must be
  /// AV_IAMF_PARAMETER_DEFINITION_DEMIXING.
  external ffi.Pointer<AVIAMFParamDefinition> demixing_info;

  /// Recon gain information used to reconstruct a scalable channel audio
  /// representation.
  /// The @ref AVIAMFParamDefinition.type "type" must be
  /// AV_IAMF_PARAMETER_DEFINITION_RECON_GAIN.
  external ffi.Pointer<AVIAMFParamDefinition> recon_gain_info;

  /// Audio element type as defined in section 3.6 of IAMF.
  @ffi.UnsignedInt()
  external int audio_element_typeAsInt;

  AVIAMFAudioElementType get audio_element_type =>
      AVIAMFAudioElementType.fromValue(audio_element_typeAsInt);

  /// Default weight value as defined in section 3.6 of IAMF.
  @ffi.UnsignedInt()
  external int default_w;
}

/// A layer defining a Channel Layout in the Audio Element.
///
/// When @ref AVIAMFAudioElement.audio_element_type "the parent's Audio Element type"
/// is AV_IAMF_AUDIO_ELEMENT_TYPE_CHANNEL, this corresponds to an Scalable Channel
/// Layout layer as defined in section 3.6.2 of IAMF.
/// For AV_IAMF_AUDIO_ELEMENT_TYPE_SCENE, it is an Ambisonics channel
/// layout as defined in section 3.6.3 of IAMF.
///
/// @note The struct should be allocated with av_iamf_audio_element_add_layer()
/// and its size is not a part of the public ABI.
final class AVIAMFLayer extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  external AVChannelLayout ch_layout;

  /// A bitmask which may contain a combination of AV_IAMF_LAYER_FLAG_* flags.
  @ffi.UnsignedInt()
  external int flags;

  /// Output gain channel flags as defined in section 3.6.2 of IAMF.
  ///
  /// This field is defined only if @ref AVIAMFAudioElement.audio_element_type
  /// "the parent's Audio Element type" is AV_IAMF_AUDIO_ELEMENT_TYPE_CHANNEL,
  /// must be 0 otherwise.
  @ffi.UnsignedInt()
  external int output_gain_flags;

  /// Output gain as defined in section 3.6.2 of IAMF.
  ///
  /// Must be 0 if @ref output_gain_flags is 0.
  external AVRational output_gain;

  /// Ambisonics mode as defined in section 3.6.3 of IAMF.
  ///
  /// This field is defined only if @ref AVIAMFAudioElement.audio_element_type
  /// "the parent's Audio Element type" is AV_IAMF_AUDIO_ELEMENT_TYPE_SCENE.
  ///
  /// If AV_IAMF_AMBISONICS_MODE_MONO, channel_mapping is defined implicitly
  /// (Ambisonic Order) or explicitly (Custom Order with ambi channels) in
  /// @ref ch_layout.
  /// If AV_IAMF_AMBISONICS_MODE_PROJECTION, @ref demixing_matrix must be set.
  @ffi.UnsignedInt()
  external int ambisonics_modeAsInt;

  AVIAMFAmbisonicsMode get ambisonics_mode =>
      AVIAMFAmbisonicsMode.fromValue(ambisonics_modeAsInt);

  /// Demixing matrix as defined in section 3.6.3 of IAMF.
  ///
  /// The length of the array is ch_layout.nb_channels multiplied by the sum of
  /// the amount of streams in the group plus the amount of streams in the group
  /// that are stereo.
  ///
  /// May be set only if @ref ambisonics_mode == AV_IAMF_AMBISONICS_MODE_PROJECTION,
  /// must be NULL otherwise.
  external ffi.Pointer<AVRational> demixing_matrix;
}

/// @}
/// @addtogroup lavu_iamf_audio
/// @{
enum AVIAMFAmbisonicsMode {
  AV_IAMF_AMBISONICS_MODE_MONO(0),
  AV_IAMF_AMBISONICS_MODE_PROJECTION(1);

  final int value;
  const AVIAMFAmbisonicsMode(this.value);

  static AVIAMFAmbisonicsMode fromValue(int value) => switch (value) {
        0 => AV_IAMF_AMBISONICS_MODE_MONO,
        1 => AV_IAMF_AMBISONICS_MODE_PROJECTION,
        _ =>
          throw ArgumentError("Unknown value for AVIAMFAmbisonicsMode: $value"),
      };
}

/// Parameters as defined in section 3.6.1 of IAMF.
///
/// The struct is allocated by av_iamf_param_definition_alloc() along with an
/// array of subblocks, its type depending on the value of type.
/// This array is placed subblocks_offset bytes after the start of this struct.
///
/// @note This struct's size is not a part of the public ABI.
final class AVIAMFParamDefinition extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  /// Offset in bytes from the start of this struct, at which the subblocks
  /// array is located.
  @ffi.Size()
  external int subblocks_offset;

  /// Size in bytes of each element in the subblocks array.
  @ffi.Size()
  external int subblock_size;

  /// Number of subblocks in the array.
  @ffi.UnsignedInt()
  external int nb_subblocks;

  /// Parameters type. Determines the type of the subblock elements.
  @ffi.UnsignedInt()
  external int typeAsInt;

  AVIAMFParamDefinitionType get type =>
      AVIAMFParamDefinitionType.fromValue(typeAsInt);

  /// Identifier for the paremeter substream.
  @ffi.UnsignedInt()
  external int parameter_id;

  /// Sample rate for the paremeter substream. It must not be 0.
  @ffi.UnsignedInt()
  external int parameter_rate;

  /// The accumulated duration of all blocks in this parameter definition,
  /// in units of 1 / @ref parameter_rate.
  ///
  /// May be 0, in which case all duration values should be specified in
  /// another parameter definition referencing the same parameter_id.
  @ffi.UnsignedInt()
  external int duration;

  /// The duration of every subblock in the case where all subblocks, with
  /// the optional exception of the last subblock, have equal durations.
  ///
  /// Must be 0 if subblocks have different durations.
  @ffi.UnsignedInt()
  external int constant_subblock_duration;
}

enum AVIAMFParamDefinitionType {
  /// Subblocks are of struct type AVIAMFMixGain
  AV_IAMF_PARAMETER_DEFINITION_MIX_GAIN(0),

  /// Subblocks are of struct type AVIAMFDemixingInfo
  AV_IAMF_PARAMETER_DEFINITION_DEMIXING(1),

  /// Subblocks are of struct type AVIAMFReconGain
  AV_IAMF_PARAMETER_DEFINITION_RECON_GAIN(2);

  final int value;
  const AVIAMFParamDefinitionType(this.value);

  static AVIAMFParamDefinitionType fromValue(int value) => switch (value) {
        0 => AV_IAMF_PARAMETER_DEFINITION_MIX_GAIN,
        1 => AV_IAMF_PARAMETER_DEFINITION_DEMIXING,
        2 => AV_IAMF_PARAMETER_DEFINITION_RECON_GAIN,
        _ => throw ArgumentError(
            "Unknown value for AVIAMFParamDefinitionType: $value"),
      };
}

enum AVIAMFAudioElementType {
  AV_IAMF_AUDIO_ELEMENT_TYPE_CHANNEL(0),
  AV_IAMF_AUDIO_ELEMENT_TYPE_SCENE(1);

  final int value;
  const AVIAMFAudioElementType(this.value);

  static AVIAMFAudioElementType fromValue(int value) => switch (value) {
        0 => AV_IAMF_AUDIO_ELEMENT_TYPE_CHANNEL,
        1 => AV_IAMF_AUDIO_ELEMENT_TYPE_SCENE,
        _ => throw ArgumentError(
            "Unknown value for AVIAMFAudioElementType: $value"),
      };
}

/// Information on how to render and mix one or more AVIAMFAudioElement to generate
/// the final audio output, as defined in section 3.7 of IAMF.
///
/// @note The struct should be allocated with av_iamf_mix_presentation_alloc()
/// and its size is not a part of the public ABI.
final class AVIAMFMixPresentation extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  /// Array of submixes.
  ///
  /// Set by av_iamf_mix_presentation_add_submix(), must not be modified
  /// by any other code.
  external ffi.Pointer<ffi.Pointer<AVIAMFSubmix>> submixes;

  /// Number of submixes in the presentation.
  ///
  /// Set by av_iamf_mix_presentation_add_submix(), must not be modified
  /// by any other code.
  @ffi.UnsignedInt()
  external int nb_submixes;

  /// A dictionary of strings describing the mix in different languages.
  /// Must have the same amount of entries as every
  /// @ref AVIAMFSubmixElement.annotations "Submix element annotations",
  /// stored in the same order, and with the same key strings.
  ///
  /// @ref AVDictionaryEntry.key "key" is a string conforming to BCP-47
  /// that specifies the language for the string stored in
  /// @ref AVDictionaryEntry.value "value".
  external ffi.Pointer<AVDictionary> annotations;
}

/// Submix layout as defined in section 3.7 of IAMF.
///
/// @note The struct should be allocated with av_iamf_mix_presentation_add_submix()
/// and its size is not a part of the public ABI.
final class AVIAMFSubmix extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  /// Array of submix elements.
  ///
  /// Set by av_iamf_submix_add_element(), must not be modified by any
  /// other code.
  external ffi.Pointer<ffi.Pointer<AVIAMFSubmixElement>> elements;

  /// Number of elements in the submix.
  ///
  /// Set by av_iamf_submix_add_element(), must not be modified by any
  /// other code.
  @ffi.UnsignedInt()
  external int nb_elements;

  /// Array of submix layouts.
  ///
  /// Set by av_iamf_submix_add_layout(), must not be modified by any
  /// other code.
  external ffi.Pointer<ffi.Pointer<AVIAMFSubmixLayout>> layouts;

  /// Number of layouts in the submix.
  ///
  /// Set by av_iamf_submix_add_layout(), must not be modified by any
  /// other code.
  @ffi.UnsignedInt()
  external int nb_layouts;

  /// Information required for post-processing the mixed audio signal to
  /// generate the audio signal for playback.
  /// The @ref AVIAMFParamDefinition.type "type" must be
  /// AV_IAMF_PARAMETER_DEFINITION_MIX_GAIN.
  external ffi.Pointer<AVIAMFParamDefinition> output_mix_config;

  /// Default mix gain value to apply when there are no AVIAMFParamDefinition
  /// with @ref output_mix_config "output_mix_config's"
  /// @ref AVIAMFParamDefinition.parameter_id "parameter_id" available for a
  /// given audio frame.
  external AVRational default_mix_gain;
}

/// Submix element as defined in section 3.7 of IAMF.
///
/// @note The struct should be allocated with av_iamf_submix_add_element()
/// and its size is not a part of the public ABI.
final class AVIAMFSubmixElement extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  /// The id of the Audio Element this submix element references.
  @ffi.UnsignedInt()
  external int audio_element_id;

  /// Information required required for applying any processing to the
  /// referenced and rendered Audio Element before being summed with other
  /// processed Audio Elements.
  /// The @ref AVIAMFParamDefinition.type "type" must be
  /// AV_IAMF_PARAMETER_DEFINITION_MIX_GAIN.
  external ffi.Pointer<AVIAMFParamDefinition> element_mix_config;

  /// Default mix gain value to apply when there are no AVIAMFParamDefinition
  /// with @ref element_mix_config "element_mix_config's"
  /// @ref AVIAMFParamDefinition.parameter_id "parameter_id" available for a
  /// given audio frame.
  external AVRational default_mix_gain;

  /// A value that indicates whether the referenced channel-based Audio Element
  /// shall be rendered to stereo loudspeakers or spatialized with a binaural
  /// renderer when played back on headphones.
  /// If the Audio Element is not of @ref AVIAMFAudioElement.audio_element_type
  /// "type" AV_IAMF_AUDIO_ELEMENT_TYPE_CHANNEL, then this field is undefined.
  @ffi.UnsignedInt()
  external int headphones_rendering_modeAsInt;

  AVIAMFHeadphonesMode get headphones_rendering_mode =>
      AVIAMFHeadphonesMode.fromValue(headphones_rendering_modeAsInt);

  /// A dictionary of strings describing the submix in different languages.
  /// Must have the same amount of entries as
  /// @ref AVIAMFMixPresentation.annotations "the mix's annotations", stored
  /// in the same order, and with the same key strings.
  ///
  /// @ref AVDictionaryEntry.key "key" is a string conforming to BCP-47 that
  /// specifies the language for the string stored in
  /// @ref AVDictionaryEntry.value "value".
  external ffi.Pointer<AVDictionary> annotations;
}

/// @}
/// @addtogroup lavu_iamf_mix
/// @{
enum AVIAMFHeadphonesMode {
  /// The referenced Audio Element shall be rendered to stereo loudspeakers.
  AV_IAMF_HEADPHONES_MODE_STEREO(0),

  /// The referenced Audio Element shall be rendered with a binaural renderer.
  AV_IAMF_HEADPHONES_MODE_BINAURAL(1);

  final int value;
  const AVIAMFHeadphonesMode(this.value);

  static AVIAMFHeadphonesMode fromValue(int value) => switch (value) {
        0 => AV_IAMF_HEADPHONES_MODE_STEREO,
        1 => AV_IAMF_HEADPHONES_MODE_BINAURAL,
        _ =>
          throw ArgumentError("Unknown value for AVIAMFHeadphonesMode: $value"),
      };
}

/// Submix layout as defined in section 3.7.6 of IAMF.
///
/// @note The struct should be allocated with av_iamf_submix_add_layout()
/// and its size is not a part of the public ABI.
final class AVIAMFSubmixLayout extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  @ffi.UnsignedInt()
  external int layout_typeAsInt;

  AVIAMFSubmixLayoutType get layout_type =>
      AVIAMFSubmixLayoutType.fromValue(layout_typeAsInt);

  /// Channel layout matching one of Sound Systems A to J of ITU-2051-3, plus
  /// 7.1.2ch and 3.1.2ch
  /// If layout_type is not AV_IAMF_SUBMIX_LAYOUT_TYPE_LOUDSPEAKERS, this field
  /// is undefined.
  external AVChannelLayout sound_system;

  /// The program integrated loudness information, as defined in
  /// ITU-1770-4.
  external AVRational integrated_loudness;

  /// The digital (sampled) peak value of the audio signal, as defined
  /// in ITU-1770-4.
  external AVRational digital_peak;

  /// The true peak of the audio signal, as defined in ITU-1770-4.
  external AVRational true_peak;

  /// The Dialogue loudness information, as defined in ITU-1770-4.
  external AVRational dialogue_anchored_loudness;

  /// The Album loudness information, as defined in ITU-1770-4.
  external AVRational album_anchored_loudness;
}

enum AVIAMFSubmixLayoutType {
  /// The layout follows the loudspeaker sound system convention of ITU-2051-3.
  AV_IAMF_SUBMIX_LAYOUT_TYPE_LOUDSPEAKERS(2),

  /// The layout is binaural.
  AV_IAMF_SUBMIX_LAYOUT_TYPE_BINAURAL(3);

  final int value;
  const AVIAMFSubmixLayoutType(this.value);

  static AVIAMFSubmixLayoutType fromValue(int value) => switch (value) {
        2 => AV_IAMF_SUBMIX_LAYOUT_TYPE_LOUDSPEAKERS,
        3 => AV_IAMF_SUBMIX_LAYOUT_TYPE_BINAURAL,
        _ => throw ArgumentError(
            "Unknown value for AVIAMFSubmixLayoutType: $value"),
      };
}

/// AVStreamGroupTileGrid holds information on how to combine several
/// independent images on a single canvas for presentation.
///
/// The output should be a @ref AVStreamGroupTileGrid.background "background"
/// colored @ref AVStreamGroupTileGrid.coded_width "coded_width" x
/// @ref AVStreamGroupTileGrid.coded_height "coded_height" canvas where a
/// @ref AVStreamGroupTileGrid.nb_tiles "nb_tiles" amount of tiles are placed in
/// the order they appear in the @ref AVStreamGroupTileGrid.offsets "offsets"
/// array, at the exact offset described for them. In particular, if two or more
/// tiles overlap, the image with higher index in the
/// @ref AVStreamGroupTileGrid.offsets "offsets" array takes priority.
/// Note that a single image may be used multiple times, i.e. multiple entries
/// in @ref AVStreamGroupTileGrid.offsets "offsets" may have the same value of
/// idx.
///
/// The following is an example of a simple grid with 3 rows and 4 columns:
///
/// +---+---+---+---+
/// | 0 | 1 | 2 | 3 |
/// +---+---+---+---+
/// | 4 | 5 | 6 | 7 |
/// +---+---+---+---+
/// | 8 | 9 |10 |11 |
/// +---+---+---+---+
///
/// Assuming all tiles have a dimension of 512x512, the
/// @ref AVStreamGroupTileGrid.offsets "offset" of the topleft pixel of
/// the first @ref AVStreamGroup.streams "stream" in the group is "0,0", the
/// @ref AVStreamGroupTileGrid.offsets "offset" of the topleft pixel of
/// the second @ref AVStreamGroup.streams "stream" in the group is "512,0", the
/// @ref AVStreamGroupTileGrid.offsets "offset" of the topleft pixel of
/// the fifth @ref AVStreamGroup.streams "stream" in the group is "0,512", the
/// @ref AVStreamGroupTileGrid.offsets "offset", of the topleft pixel of
/// the sixth @ref AVStreamGroup.streams "stream" in the group is "512,512",
/// etc.
///
/// The following is an example of a canvas with overlaping tiles:
///
/// +-----------+
/// |   %%%%%   |
/// |***%%3%%@@@|
/// |**0%%%%%2@@|
/// |***##1@@@@@|
/// |   #####   |
/// +-----------+
///
/// Assuming a canvas with size 1024x1024 and all tiles with a dimension of
/// 512x512, a possible @ref AVStreamGroupTileGrid.offsets "offset" for the
/// topleft pixel of the first @ref AVStreamGroup.streams "stream" in the group
/// would be 0x256, the @ref AVStreamGroupTileGrid.offsets "offset" for the
/// topleft pixel of the second @ref AVStreamGroup.streams "stream" in the group
/// would be 256x512, the @ref AVStreamGroupTileGrid.offsets "offset" for the
/// topleft pixel of the third @ref AVStreamGroup.streams "stream" in the group
/// would be 512x256, and the @ref AVStreamGroupTileGrid.offsets "offset" for
/// the topleft pixel of the fourth @ref AVStreamGroup.streams "stream" in the
/// group would be 256x0.
///
/// sizeof(AVStreamGroupTileGrid) is not a part of the ABI and may only be
/// allocated by avformat_stream_group_create().
final class AVStreamGroupTileGrid extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  /// Amount of tiles in the grid.
  ///
  /// Must be > 0.
  @ffi.UnsignedInt()
  external int nb_tiles;

  /// Width of the canvas.
  ///
  /// Must be > 0.
  @ffi.Int()
  external int coded_width;

  /// Width of the canvas.
  ///
  /// Must be > 0.
  @ffi.Int()
  external int coded_height;

  external ffi.Pointer<UnnamedStruct1> offsets;

  /// The pixel value per channel in RGBA format used if no pixel of any tile
  /// is located at a particular pixel location.
  ///
  /// @see av_image_fill_color().
  /// @see av_parse_color().
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint8> background;

  /// Offset in pixels from the left edge of the canvas where the actual image
  /// meant for presentation starts.
  ///
  /// This field must be >= 0 and < @ref coded_width.
  @ffi.Int()
  external int horizontal_offset;

  /// Offset in pixels from the top edge of the canvas where the actual image
  /// meant for presentation starts.
  ///
  /// This field must be >= 0 and < @ref coded_height.
  @ffi.Int()
  external int vertical_offset;

  /// Width of the final image for presentation.
  ///
  /// Must be > 0 and <= (@ref coded_width - @ref horizontal_offset).
  /// When it's not equal to (@ref coded_width - @ref horizontal_offset), the
  /// result of (@ref coded_width - width - @ref horizontal_offset) is the
  /// amount amount of pixels to be cropped from the right edge of the
  /// final image before presentation.
  @ffi.Int()
  external int width;

  /// Height of the final image for presentation.
  ///
  /// Must be > 0 and <= (@ref coded_height - @ref vertical_offset).
  /// When it's not equal to (@ref coded_height - @ref vertical_offset), the
  /// result of (@ref coded_height - height - @ref vertical_offset) is the
  /// amount amount of pixels to be cropped from the bottom edge of the
  /// final image before presentation.
  @ffi.Int()
  external int height;
}

/// An @ref nb_tiles sized array of offsets in pixels from the topleft edge
/// of the canvas, indicating where each stream should be placed.
/// It must be allocated with the av_malloc() family of functions.
///
/// - demuxing: set by libavformat, must not be modified by the caller.
/// - muxing: set by the caller before avformat_write_header().
///
/// Freed by libavformat in avformat_free_context().
final class UnnamedStruct1 extends ffi.Struct {
  /// Index of the stream in the group this tile references.
  ///
  /// Must be < @ref AVStreamGroup.nb_streams "nb_streams".
  @ffi.UnsignedInt()
  external int idx;

  /// Offset in pixels from the left edge of the canvas where the tile
  /// should be placed.
  @ffi.Int()
  external int horizontal;

  /// Offset in pixels from the top edge of the canvas where the tile
  /// should be placed.
  @ffi.Int()
  external int vertical;
}

/// AVStreamGroupLCEVC is meant to define the relation between video streams
/// and a data stream containing LCEVC enhancement layer NALUs.
///
/// No more than one stream of @ref AVCodecParameters.codec_type "codec_type"
/// AVMEDIA_TYPE_DATA shall be present, and it must be of
/// @ref AVCodecParameters.codec_id "codec_id" AV_CODEC_ID_LCEVC.
final class AVStreamGroupLCEVC extends ffi.Struct {
  external ffi.Pointer<AVClass> av_class;

  /// Index of the LCEVC data stream in AVStreamGroup.
  @ffi.UnsignedInt()
  external int lcevc_index;

  /// Width of the final stream for presentation.
  @ffi.Int()
  external int width;

  /// Height of the final image for presentation.
  @ffi.Int()
  external int height;
}

final class AVChapter extends ffi.Struct {
  /// < unique ID to identify the chapter
  @ffi.Int64()
  external int id;

  /// < time base in which the start/end timestamps are specified
  external AVRational time_base;

  /// < chapter start/end time in time_base units
  @ffi.Int64()
  external int start;

  @ffi.Int64()
  external int end;

  external ffi.Pointer<AVDictionary> metadata;
}

/// New fields can be added to the end with minor version bumps.
/// Removal, reordering and changes to existing fields require a major
/// version bump.
/// sizeof(AVProgram) must not be used outside libav*.
final class AVProgram extends ffi.Struct {
  @ffi.Int()
  external int id;

  @ffi.Int()
  external int flags;

  /// < selects which program to discard and which to feed to the caller
  @ffi.Int()
  external int discardAsInt;

  AVDiscard get discard => AVDiscard.fromValue(discardAsInt);

  external ffi.Pointer<ffi.UnsignedInt> stream_index;

  @ffi.UnsignedInt()
  external int nb_stream_indexes;

  external ffi.Pointer<AVDictionary> metadata;

  @ffi.Int()
  external int program_num;

  @ffi.Int()
  external int pmt_pid;

  @ffi.Int()
  external int pcr_pid;

  @ffi.Int()
  external int pmt_version;

  /// All fields below this line are not part of the public API. They
  /// may not be used outside of libavformat and can be changed and
  /// removed at will.
  /// New public fields should be added right above.
  @ffi.Int64()
  external int start_time;

  @ffi.Int64()
  external int end_time;

  /// < reference dts for wrap detection
  @ffi.Int64()
  external int pts_wrap_reference;

  /// < behavior on wrap detection
  @ffi.Int()
  external int pts_wrap_behavior;
}

/// Callback for checking whether to abort blocking functions.
/// AVERROR_EXIT is returned in this case by the interrupted
/// function. During blocking operations, callback is called with
/// opaque as parameter. If the callback returns 1, the
/// blocking operation will be aborted.
///
/// No members can be added to this struct without a major bump, if
/// new elements have been added after this struct in AVFormatContext
/// or AVIOContext.
final class AVIOInterruptCB extends ffi.Struct {
  external ffi
      .Pointer<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>
      callback;

  external ffi.Pointer<ffi.Void> opaque;
}

/// The duration of a video can be estimated through various ways, and this enum can be used
/// to know how the duration was estimated.
enum AVDurationEstimationMethod {
  /// < Duration accurately estimated from PTSes
  AVFMT_DURATION_FROM_PTS(0),

  /// < Duration estimated from a stream with a known duration
  AVFMT_DURATION_FROM_STREAM(1),

  /// < Duration estimated from bitrate (less accurate)
  AVFMT_DURATION_FROM_BITRATE(2);

  final int value;
  const AVDurationEstimationMethod(this.value);

  static AVDurationEstimationMethod fromValue(int value) => switch (value) {
        0 => AVFMT_DURATION_FROM_PTS,
        1 => AVFMT_DURATION_FROM_STREAM,
        2 => AVFMT_DURATION_FROM_BITRATE,
        _ => throw ArgumentError(
            "Unknown value for AVDurationEstimationMethod: $value"),
      };
}

/// AVCodec.
final class AVCodec extends ffi.Struct {
  /// Name of the codec implementation.
  /// The name is globally unique among encoders and among decoders (but an
  /// encoder and a decoder can share the same name).
  /// This is the primary way to find a codec from the user perspective.
  external ffi.Pointer<ffi.Char> name;

  /// Descriptive name for the codec, meant to be more human readable than name.
  /// You should use the NULL_IF_CONFIG_SMALL() macro to define it.
  external ffi.Pointer<ffi.Char> long_name;

  @ffi.Int()
  external int typeAsInt;

  AVMediaType get type => AVMediaType.fromValue(typeAsInt);

  @ffi.UnsignedInt()
  external int idAsInt;

  AVCodecID get id => AVCodecID.fromValue(idAsInt);

  /// Codec capabilities.
  /// see AV_CODEC_CAP_*
  @ffi.Int()
  external int capabilities;

  /// < maximum value for lowres supported by the decoder
  @ffi.Uint8()
  external int max_lowres;

  /// < @deprecated use avcodec_get_supported_config()
  external ffi.Pointer<AVRational> supported_framerates;

  /// < @deprecated use avcodec_get_supported_config()
  external ffi.Pointer<ffi.Int> pix_fmts;

  /// < @deprecated use avcodec_get_supported_config()
  external ffi.Pointer<ffi.Int> supported_samplerates;

  /// < @deprecated use avcodec_get_supported_config()
  external ffi.Pointer<ffi.Int> sample_fmts;

  /// < AVClass for the private context
  external ffi.Pointer<AVClass> priv_class;

  /// < array of recognized profiles, or NULL if unknown, array is terminated by {AV_PROFILE_UNKNOWN}
  external ffi.Pointer<AVProfile> profiles;

  /// Group name of the codec implementation.
  /// This is a short symbolic name of the wrapper backing this codec. A
  /// wrapper uses some kind of external implementation for the codec, such
  /// as an external library, or a codec implementation provided by the OS or
  /// the hardware.
  /// If this field is NULL, this is a builtin, libavcodec native codec.
  /// If non-NULL, this will be the suffix in AVCodec.name in most cases
  /// (usually AVCodec.name will be of the form "<codec_name>_<wrapper_name>").
  external ffi.Pointer<ffi.Char> wrapper_name;

  /// Array of supported channel layouts, terminated with a zeroed layout.
  /// @deprecated use avcodec_get_supported_config()
  external ffi.Pointer<AVChannelLayout> ch_layouts;
}

/// Pixel format.
///
/// @note
/// AV_PIX_FMT_RGB32 is handled in an endian-specific manner. An RGBA
/// color is put together as:
/// (A << 24) | (R << 16) | (G << 8) | B
/// This is stored as BGRA on little-endian CPU architectures and ARGB on
/// big-endian CPUs.
///
/// @note
/// If the resolution is not a multiple of the chroma subsampling factor
/// then the chroma plane resolution must be rounded up.
///
/// @par
/// When the pixel format is palettized RGB32 (AV_PIX_FMT_PAL8), the palettized
/// image data is stored in AVFrame.data[0]. The palette is transported in
/// AVFrame.data[1], is 1024 bytes long (256 4-byte entries) and is
/// formatted the same as in AV_PIX_FMT_RGB32 described above (i.e., it is
/// also endian-specific). Note also that the individual RGB32 palette
/// components stored in AVFrame.data[1] should be in the range 0..255.
/// This is important as many custom PAL8 video codecs that were designed
/// to run on the IBM VGA graphics adapter use 6-bit palette components.
///
/// @par
/// For all the 8 bits per pixel formats, an RGB32 palette is in data[1] like
/// for pal8. This palette is filled in automatically by the function
/// allocating the picture.
enum AVPixelFormat {
  AV_PIX_FMT_NONE(-1),

  /// < planar YUV 4:2:0, 12bpp, (1 Cr & Cb sample per 2x2 Y samples)
  AV_PIX_FMT_YUV420P(0),

  /// < packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr
  AV_PIX_FMT_YUYV422(1),

  /// < packed RGB 8:8:8, 24bpp, RGBRGB...
  AV_PIX_FMT_RGB24(2),

  /// < packed RGB 8:8:8, 24bpp, BGRBGR...
  AV_PIX_FMT_BGR24(3),

  /// < planar YUV 4:2:2, 16bpp, (1 Cr & Cb sample per 2x1 Y samples)
  AV_PIX_FMT_YUV422P(4),

  /// < planar YUV 4:4:4, 24bpp, (1 Cr & Cb sample per 1x1 Y samples)
  AV_PIX_FMT_YUV444P(5),

  /// < planar YUV 4:1:0,  9bpp, (1 Cr & Cb sample per 4x4 Y samples)
  AV_PIX_FMT_YUV410P(6),

  /// < planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples)
  AV_PIX_FMT_YUV411P(7),

  /// <        Y        ,  8bpp
  AV_PIX_FMT_GRAY8(8),

  /// <        Y        ,  1bpp, 0 is white, 1 is black, in each byte pixels are ordered from the msb to the lsb
  AV_PIX_FMT_MONOWHITE(9),

  /// <        Y        ,  1bpp, 0 is black, 1 is white, in each byte pixels are ordered from the msb to the lsb
  AV_PIX_FMT_MONOBLACK(10),

  /// < 8 bits with AV_PIX_FMT_RGB32 palette
  AV_PIX_FMT_PAL8(11),

  /// < planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV420P and setting color_range
  AV_PIX_FMT_YUVJ420P(12),

  /// < planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV422P and setting color_range
  AV_PIX_FMT_YUVJ422P(13),

  /// < planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV444P and setting color_range
  AV_PIX_FMT_YUVJ444P(14),

  /// < packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1
  AV_PIX_FMT_UYVY422(15),

  /// < packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3
  AV_PIX_FMT_UYYVYY411(16),

  /// < packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb)
  AV_PIX_FMT_BGR8(17),

  /// < packed RGB 1:2:1 bitstream,  4bpp, (msb)1B 2G 1R(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits
  AV_PIX_FMT_BGR4(18),

  /// < packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb)
  AV_PIX_FMT_BGR4_BYTE(19),

  /// < packed RGB 3:3:2,  8bpp, (msb)3R 3G 2B(lsb)
  AV_PIX_FMT_RGB8(20),

  /// < packed RGB 1:2:1 bitstream,  4bpp, (msb)1R 2G 1B(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits
  AV_PIX_FMT_RGB4(21),

  /// < packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)
  AV_PIX_FMT_RGB4_BYTE(22),

  /// < planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)
  AV_PIX_FMT_NV12(23),

  /// < as above, but U and V bytes are swapped
  AV_PIX_FMT_NV21(24),

  /// < packed ARGB 8:8:8:8, 32bpp, ARGBARGB...
  AV_PIX_FMT_ARGB(25),

  /// < packed RGBA 8:8:8:8, 32bpp, RGBARGBA...
  AV_PIX_FMT_RGBA(26),

  /// < packed ABGR 8:8:8:8, 32bpp, ABGRABGR...
  AV_PIX_FMT_ABGR(27),

  /// < packed BGRA 8:8:8:8, 32bpp, BGRABGRA...
  AV_PIX_FMT_BGRA(28),

  /// <        Y        , 16bpp, big-endian
  AV_PIX_FMT_GRAY16BE(29),

  /// <        Y        , 16bpp, little-endian
  AV_PIX_FMT_GRAY16LE(30),

  /// < planar YUV 4:4:0 (1 Cr & Cb sample per 1x2 Y samples)
  AV_PIX_FMT_YUV440P(31),

  /// < planar YUV 4:4:0 full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV440P and setting color_range
  AV_PIX_FMT_YUVJ440P(32),

  /// < planar YUV 4:2:0, 20bpp, (1 Cr & Cb sample per 2x2 Y & A samples)
  AV_PIX_FMT_YUVA420P(33),

  /// < packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as big-endian
  AV_PIX_FMT_RGB48BE(34),

  /// < packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as little-endian
  AV_PIX_FMT_RGB48LE(35),

  /// < packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), big-endian
  AV_PIX_FMT_RGB565BE(36),

  /// < packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), little-endian
  AV_PIX_FMT_RGB565LE(37),

  /// < packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), big-endian   , X=unused/undefined
  AV_PIX_FMT_RGB555BE(38),

  /// < packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), little-endian, X=unused/undefined
  AV_PIX_FMT_RGB555LE(39),

  /// < packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), big-endian
  AV_PIX_FMT_BGR565BE(40),

  /// < packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), little-endian
  AV_PIX_FMT_BGR565LE(41),

  /// < packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), big-endian   , X=unused/undefined
  AV_PIX_FMT_BGR555BE(42),

  /// < packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), little-endian, X=unused/undefined
  AV_PIX_FMT_BGR555LE(43),

  /// Hardware acceleration through VA-API, data[3] contains a
  /// VASurfaceID.
  AV_PIX_FMT_VAAPI(44),

  /// < planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian
  AV_PIX_FMT_YUV420P16LE(45),

  /// < planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
  AV_PIX_FMT_YUV420P16BE(46),

  /// < planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian
  AV_PIX_FMT_YUV422P16LE(47),

  /// < planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian
  AV_PIX_FMT_YUV422P16BE(48),

  /// < planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian
  AV_PIX_FMT_YUV444P16LE(49),

  /// < planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian
  AV_PIX_FMT_YUV444P16BE(50),

  /// < HW decoding through DXVA2, Picture.data[3] contains a LPDIRECT3DSURFACE9 pointer
  AV_PIX_FMT_DXVA2_VLD(51),

  /// < packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), little-endian, X=unused/undefined
  AV_PIX_FMT_RGB444LE(52),

  /// < packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), big-endian,    X=unused/undefined
  AV_PIX_FMT_RGB444BE(53),

  /// < packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), little-endian, X=unused/undefined
  AV_PIX_FMT_BGR444LE(54),

  /// < packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), big-endian,    X=unused/undefined
  AV_PIX_FMT_BGR444BE(55),

  /// < 8 bits gray, 8 bits alpha
  AV_PIX_FMT_YA8(56),

  /// < packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as big-endian
  AV_PIX_FMT_BGR48BE(57),

  /// < packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as little-endian
  AV_PIX_FMT_BGR48LE(58),

  /// < planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
  AV_PIX_FMT_YUV420P9BE(59),

  /// < planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian
  AV_PIX_FMT_YUV420P9LE(60),

  /// < planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
  AV_PIX_FMT_YUV420P10BE(61),

  /// < planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian
  AV_PIX_FMT_YUV420P10LE(62),

  /// < planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian
  AV_PIX_FMT_YUV422P10BE(63),

  /// < planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian
  AV_PIX_FMT_YUV422P10LE(64),

  /// < planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian
  AV_PIX_FMT_YUV444P9BE(65),

  /// < planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian
  AV_PIX_FMT_YUV444P9LE(66),

  /// < planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian
  AV_PIX_FMT_YUV444P10BE(67),

  /// < planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian
  AV_PIX_FMT_YUV444P10LE(68),

  /// < planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian
  AV_PIX_FMT_YUV422P9BE(69),

  /// < planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian
  AV_PIX_FMT_YUV422P9LE(70),

  /// < planar GBR 4:4:4 24bpp
  AV_PIX_FMT_GBRP(71),

  /// < planar GBR 4:4:4 27bpp, big-endian
  AV_PIX_FMT_GBRP9BE(72),

  /// < planar GBR 4:4:4 27bpp, little-endian
  AV_PIX_FMT_GBRP9LE(73),

  /// < planar GBR 4:4:4 30bpp, big-endian
  AV_PIX_FMT_GBRP10BE(74),

  /// < planar GBR 4:4:4 30bpp, little-endian
  AV_PIX_FMT_GBRP10LE(75),

  /// < planar GBR 4:4:4 48bpp, big-endian
  AV_PIX_FMT_GBRP16BE(76),

  /// < planar GBR 4:4:4 48bpp, little-endian
  AV_PIX_FMT_GBRP16LE(77),

  /// < planar YUV 4:2:2 24bpp, (1 Cr & Cb sample per 2x1 Y & A samples)
  AV_PIX_FMT_YUVA422P(78),

  /// < planar YUV 4:4:4 32bpp, (1 Cr & Cb sample per 1x1 Y & A samples)
  AV_PIX_FMT_YUVA444P(79),

  /// < planar YUV 4:2:0 22.5bpp, (1 Cr & Cb sample per 2x2 Y & A samples), big-endian
  AV_PIX_FMT_YUVA420P9BE(80),

  /// < planar YUV 4:2:0 22.5bpp, (1 Cr & Cb sample per 2x2 Y & A samples), little-endian
  AV_PIX_FMT_YUVA420P9LE(81),

  /// < planar YUV 4:2:2 27bpp, (1 Cr & Cb sample per 2x1 Y & A samples), big-endian
  AV_PIX_FMT_YUVA422P9BE(82),

  /// < planar YUV 4:2:2 27bpp, (1 Cr & Cb sample per 2x1 Y & A samples), little-endian
  AV_PIX_FMT_YUVA422P9LE(83),

  /// < planar YUV 4:4:4 36bpp, (1 Cr & Cb sample per 1x1 Y & A samples), big-endian
  AV_PIX_FMT_YUVA444P9BE(84),

  /// < planar YUV 4:4:4 36bpp, (1 Cr & Cb sample per 1x1 Y & A samples), little-endian
  AV_PIX_FMT_YUVA444P9LE(85),

  /// < planar YUV 4:2:0 25bpp, (1 Cr & Cb sample per 2x2 Y & A samples, big-endian)
  AV_PIX_FMT_YUVA420P10BE(86),

  /// < planar YUV 4:2:0 25bpp, (1 Cr & Cb sample per 2x2 Y & A samples, little-endian)
  AV_PIX_FMT_YUVA420P10LE(87),

  /// < planar YUV 4:2:2 30bpp, (1 Cr & Cb sample per 2x1 Y & A samples, big-endian)
  AV_PIX_FMT_YUVA422P10BE(88),

  /// < planar YUV 4:2:2 30bpp, (1 Cr & Cb sample per 2x1 Y & A samples, little-endian)
  AV_PIX_FMT_YUVA422P10LE(89),

  /// < planar YUV 4:4:4 40bpp, (1 Cr & Cb sample per 1x1 Y & A samples, big-endian)
  AV_PIX_FMT_YUVA444P10BE(90),

  /// < planar YUV 4:4:4 40bpp, (1 Cr & Cb sample per 1x1 Y & A samples, little-endian)
  AV_PIX_FMT_YUVA444P10LE(91),

  /// < planar YUV 4:2:0 40bpp, (1 Cr & Cb sample per 2x2 Y & A samples, big-endian)
  AV_PIX_FMT_YUVA420P16BE(92),

  /// < planar YUV 4:2:0 40bpp, (1 Cr & Cb sample per 2x2 Y & A samples, little-endian)
  AV_PIX_FMT_YUVA420P16LE(93),

  /// < planar YUV 4:2:2 48bpp, (1 Cr & Cb sample per 2x1 Y & A samples, big-endian)
  AV_PIX_FMT_YUVA422P16BE(94),

  /// < planar YUV 4:2:2 48bpp, (1 Cr & Cb sample per 2x1 Y & A samples, little-endian)
  AV_PIX_FMT_YUVA422P16LE(95),

  /// < planar YUV 4:4:4 64bpp, (1 Cr & Cb sample per 1x1 Y & A samples, big-endian)
  AV_PIX_FMT_YUVA444P16BE(96),

  /// < planar YUV 4:4:4 64bpp, (1 Cr & Cb sample per 1x1 Y & A samples, little-endian)
  AV_PIX_FMT_YUVA444P16LE(97),

  /// < HW acceleration through VDPAU, Picture.data[3] contains a VdpVideoSurface
  AV_PIX_FMT_VDPAU(98),

  /// < packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as little-endian, the 4 lower bits are set to 0
  AV_PIX_FMT_XYZ12LE(99),

  /// < packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as big-endian, the 4 lower bits are set to 0
  AV_PIX_FMT_XYZ12BE(100),

  /// < interleaved chroma YUV 4:2:2, 16bpp, (1 Cr & Cb sample per 2x1 Y samples)
  AV_PIX_FMT_NV16(101),

  /// < interleaved chroma YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian
  AV_PIX_FMT_NV20LE(102),

  /// < interleaved chroma YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian
  AV_PIX_FMT_NV20BE(103),

  /// < packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
  AV_PIX_FMT_RGBA64BE(104),

  /// < packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
  AV_PIX_FMT_RGBA64LE(105),

  /// < packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
  AV_PIX_FMT_BGRA64BE(106),

  /// < packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
  AV_PIX_FMT_BGRA64LE(107),

  /// < packed YUV 4:2:2, 16bpp, Y0 Cr Y1 Cb
  AV_PIX_FMT_YVYU422(108),

  /// < 16 bits gray, 16 bits alpha (big-endian)
  AV_PIX_FMT_YA16BE(109),

  /// < 16 bits gray, 16 bits alpha (little-endian)
  AV_PIX_FMT_YA16LE(110),

  /// < planar GBRA 4:4:4:4 32bpp
  AV_PIX_FMT_GBRAP(111),

  /// < planar GBRA 4:4:4:4 64bpp, big-endian
  AV_PIX_FMT_GBRAP16BE(112),

  /// < planar GBRA 4:4:4:4 64bpp, little-endian
  AV_PIX_FMT_GBRAP16LE(113),

  /// HW acceleration through QSV, data[3] contains a pointer to the
  /// mfxFrameSurface1 structure.
  ///
  /// Before FFmpeg 5.0:
  /// mfxFrameSurface1.Data.MemId contains a pointer when importing
  /// the following frames as QSV frames:
  ///
  /// VAAPI:
  /// mfxFrameSurface1.Data.MemId contains a pointer to VASurfaceID
  ///
  /// DXVA2:
  /// mfxFrameSurface1.Data.MemId contains a pointer to IDirect3DSurface9
  ///
  /// FFmpeg 5.0 and above:
  /// mfxFrameSurface1.Data.MemId contains a pointer to the mfxHDLPair
  /// structure when importing the following frames as QSV frames:
  ///
  /// VAAPI:
  /// mfxHDLPair.first contains a VASurfaceID pointer.
  /// mfxHDLPair.second is always MFX_INFINITE.
  ///
  /// DXVA2:
  /// mfxHDLPair.first contains IDirect3DSurface9 pointer.
  /// mfxHDLPair.second is always MFX_INFINITE.
  ///
  /// D3D11:
  /// mfxHDLPair.first contains a ID3D11Texture2D pointer.
  /// mfxHDLPair.second contains the texture array index of the frame if the
  /// ID3D11Texture2D is an array texture, or always MFX_INFINITE if it is a
  /// normal texture.
  AV_PIX_FMT_QSV(114),

  /// HW acceleration though MMAL, data[3] contains a pointer to the
  /// MMAL_BUFFER_HEADER_T structure.
  AV_PIX_FMT_MMAL(115),

  /// < HW decoding through Direct3D11 via old API, Picture.data[3] contains a ID3D11VideoDecoderOutputView pointer
  AV_PIX_FMT_D3D11VA_VLD(116),

  /// HW acceleration through CUDA. data[i] contain CUdeviceptr pointers
  /// exactly as for system memory frames.
  AV_PIX_FMT_CUDA(117),

  /// < packed RGB 8:8:8, 32bpp, XRGBXRGB...   X=unused/undefined
  AV_PIX_FMT_0RGB(118),

  /// < packed RGB 8:8:8, 32bpp, RGBXRGBX...   X=unused/undefined
  AV_PIX_FMT_RGB0(119),

  /// < packed BGR 8:8:8, 32bpp, XBGRXBGR...   X=unused/undefined
  AV_PIX_FMT_0BGR(120),

  /// < packed BGR 8:8:8, 32bpp, BGRXBGRX...   X=unused/undefined
  AV_PIX_FMT_BGR0(121),

  /// < planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
  AV_PIX_FMT_YUV420P12BE(122),

  /// < planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian
  AV_PIX_FMT_YUV420P12LE(123),

  /// < planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
  AV_PIX_FMT_YUV420P14BE(124),

  /// < planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian
  AV_PIX_FMT_YUV420P14LE(125),

  /// < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian
  AV_PIX_FMT_YUV422P12BE(126),

  /// < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian
  AV_PIX_FMT_YUV422P12LE(127),

  /// < planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian
  AV_PIX_FMT_YUV422P14BE(128),

  /// < planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian
  AV_PIX_FMT_YUV422P14LE(129),

  /// < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian
  AV_PIX_FMT_YUV444P12BE(130),

  /// < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian
  AV_PIX_FMT_YUV444P12LE(131),

  /// < planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian
  AV_PIX_FMT_YUV444P14BE(132),

  /// < planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian
  AV_PIX_FMT_YUV444P14LE(133),

  /// < planar GBR 4:4:4 36bpp, big-endian
  AV_PIX_FMT_GBRP12BE(134),

  /// < planar GBR 4:4:4 36bpp, little-endian
  AV_PIX_FMT_GBRP12LE(135),

  /// < planar GBR 4:4:4 42bpp, big-endian
  AV_PIX_FMT_GBRP14BE(136),

  /// < planar GBR 4:4:4 42bpp, little-endian
  AV_PIX_FMT_GBRP14LE(137),

  /// < planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples) full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV411P and setting color_range
  AV_PIX_FMT_YUVJ411P(138),

  /// < bayer, BGBG..(odd line), GRGR..(even line), 8-bit samples
  AV_PIX_FMT_BAYER_BGGR8(139),

  /// < bayer, RGRG..(odd line), GBGB..(even line), 8-bit samples
  AV_PIX_FMT_BAYER_RGGB8(140),

  /// < bayer, GBGB..(odd line), RGRG..(even line), 8-bit samples
  AV_PIX_FMT_BAYER_GBRG8(141),

  /// < bayer, GRGR..(odd line), BGBG..(even line), 8-bit samples
  AV_PIX_FMT_BAYER_GRBG8(142),

  /// < bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, little-endian
  AV_PIX_FMT_BAYER_BGGR16LE(143),

  /// < bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, big-endian
  AV_PIX_FMT_BAYER_BGGR16BE(144),

  /// < bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, little-endian
  AV_PIX_FMT_BAYER_RGGB16LE(145),

  /// < bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, big-endian
  AV_PIX_FMT_BAYER_RGGB16BE(146),

  /// < bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, little-endian
  AV_PIX_FMT_BAYER_GBRG16LE(147),

  /// < bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, big-endian
  AV_PIX_FMT_BAYER_GBRG16BE(148),

  /// < bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, little-endian
  AV_PIX_FMT_BAYER_GRBG16LE(149),

  /// < bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, big-endian
  AV_PIX_FMT_BAYER_GRBG16BE(150),

  /// < planar YUV 4:4:0,20bpp, (1 Cr & Cb sample per 1x2 Y samples), little-endian
  AV_PIX_FMT_YUV440P10LE(151),

  /// < planar YUV 4:4:0,20bpp, (1 Cr & Cb sample per 1x2 Y samples), big-endian
  AV_PIX_FMT_YUV440P10BE(152),

  /// < planar YUV 4:4:0,24bpp, (1 Cr & Cb sample per 1x2 Y samples), little-endian
  AV_PIX_FMT_YUV440P12LE(153),

  /// < planar YUV 4:4:0,24bpp, (1 Cr & Cb sample per 1x2 Y samples), big-endian
  AV_PIX_FMT_YUV440P12BE(154),

  /// < packed AYUV 4:4:4,64bpp (1 Cr & Cb sample per 1x1 Y & A samples), little-endian
  AV_PIX_FMT_AYUV64LE(155),

  /// < packed AYUV 4:4:4,64bpp (1 Cr & Cb sample per 1x1 Y & A samples), big-endian
  AV_PIX_FMT_AYUV64BE(156),

  /// < hardware decoding through Videotoolbox
  AV_PIX_FMT_VIDEOTOOLBOX(157),

  /// < like NV12, with 10bpp per component, data in the high bits, zeros in the low bits, little-endian
  AV_PIX_FMT_P010LE(158),

  /// < like NV12, with 10bpp per component, data in the high bits, zeros in the low bits, big-endian
  AV_PIX_FMT_P010BE(159),

  /// < planar GBR 4:4:4:4 48bpp, big-endian
  AV_PIX_FMT_GBRAP12BE(160),

  /// < planar GBR 4:4:4:4 48bpp, little-endian
  AV_PIX_FMT_GBRAP12LE(161),

  /// < planar GBR 4:4:4:4 40bpp, big-endian
  AV_PIX_FMT_GBRAP10BE(162),

  /// < planar GBR 4:4:4:4 40bpp, little-endian
  AV_PIX_FMT_GBRAP10LE(163),

  /// < hardware decoding through MediaCodec
  AV_PIX_FMT_MEDIACODEC(164),

  /// <        Y        , 12bpp, big-endian
  AV_PIX_FMT_GRAY12BE(165),

  /// <        Y        , 12bpp, little-endian
  AV_PIX_FMT_GRAY12LE(166),

  /// <        Y        , 10bpp, big-endian
  AV_PIX_FMT_GRAY10BE(167),

  /// <        Y        , 10bpp, little-endian
  AV_PIX_FMT_GRAY10LE(168),

  /// < like NV12, with 16bpp per component, little-endian
  AV_PIX_FMT_P016LE(169),

  /// < like NV12, with 16bpp per component, big-endian
  AV_PIX_FMT_P016BE(170),

  /// Hardware surfaces for Direct3D11.
  ///
  /// This is preferred over the legacy AV_PIX_FMT_D3D11VA_VLD. The new D3D11
  /// hwaccel API and filtering support AV_PIX_FMT_D3D11 only.
  ///
  /// data[0] contains a ID3D11Texture2D pointer, and data[1] contains the
  /// texture array index of the frame as intptr_t if the ID3D11Texture2D is
  /// an array texture (or always 0 if it's a normal texture).
  AV_PIX_FMT_D3D11(171),

  /// <        Y        , 9bpp, big-endian
  AV_PIX_FMT_GRAY9BE(172),

  /// <        Y        , 9bpp, little-endian
  AV_PIX_FMT_GRAY9LE(173),

  /// < IEEE-754 single precision planar GBR 4:4:4,     96bpp, big-endian
  AV_PIX_FMT_GBRPF32BE(174),

  /// < IEEE-754 single precision planar GBR 4:4:4,     96bpp, little-endian
  AV_PIX_FMT_GBRPF32LE(175),

  /// < IEEE-754 single precision planar GBRA 4:4:4:4, 128bpp, big-endian
  AV_PIX_FMT_GBRAPF32BE(176),

  /// < IEEE-754 single precision planar GBRA 4:4:4:4, 128bpp, little-endian
  AV_PIX_FMT_GBRAPF32LE(177),

  /// DRM-managed buffers exposed through PRIME buffer sharing.
  ///
  /// data[0] points to an AVDRMFrameDescriptor.
  AV_PIX_FMT_DRM_PRIME(178),

  /// Hardware surfaces for OpenCL.
  ///
  /// data[i] contain 2D image objects (typed in C as cl_mem, used
  /// in OpenCL as image2d_t) for each plane of the surface.
  AV_PIX_FMT_OPENCL(179),

  /// <        Y        , 14bpp, big-endian
  AV_PIX_FMT_GRAY14BE(180),

  /// <        Y        , 14bpp, little-endian
  AV_PIX_FMT_GRAY14LE(181),

  /// < IEEE-754 single precision Y, 32bpp, big-endian
  AV_PIX_FMT_GRAYF32BE(182),

  /// < IEEE-754 single precision Y, 32bpp, little-endian
  AV_PIX_FMT_GRAYF32LE(183),

  /// < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), 12b alpha, big-endian
  AV_PIX_FMT_YUVA422P12BE(184),

  /// < planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), 12b alpha, little-endian
  AV_PIX_FMT_YUVA422P12LE(185),

  /// < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), 12b alpha, big-endian
  AV_PIX_FMT_YUVA444P12BE(186),

  /// < planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), 12b alpha, little-endian
  AV_PIX_FMT_YUVA444P12LE(187),

  /// < planar YUV 4:4:4, 24bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)
  AV_PIX_FMT_NV24(188),

  /// < as above, but U and V bytes are swapped
  AV_PIX_FMT_NV42(189),

  /// Vulkan hardware images.
  ///
  /// data[0] points to an AVVkFrame
  AV_PIX_FMT_VULKAN(190),

  /// < packed YUV 4:2:2 like YUYV422, 20bpp, data in the high bits, big-endian
  AV_PIX_FMT_Y210BE(191),

  /// < packed YUV 4:2:2 like YUYV422, 20bpp, data in the high bits, little-endian
  AV_PIX_FMT_Y210LE(192),

  /// < packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), little-endian, X=unused/undefined
  AV_PIX_FMT_X2RGB10LE(193),

  /// < packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), big-endian, X=unused/undefined
  AV_PIX_FMT_X2RGB10BE(194),

  /// < packed BGR 10:10:10, 30bpp, (msb)2X 10B 10G 10R(lsb), little-endian, X=unused/undefined
  AV_PIX_FMT_X2BGR10LE(195),

  /// < packed BGR 10:10:10, 30bpp, (msb)2X 10B 10G 10R(lsb), big-endian, X=unused/undefined
  AV_PIX_FMT_X2BGR10BE(196),

  /// < interleaved chroma YUV 4:2:2, 20bpp, data in the high bits, big-endian
  AV_PIX_FMT_P210BE(197),

  /// < interleaved chroma YUV 4:2:2, 20bpp, data in the high bits, little-endian
  AV_PIX_FMT_P210LE(198),

  /// < interleaved chroma YUV 4:4:4, 30bpp, data in the high bits, big-endian
  AV_PIX_FMT_P410BE(199),

  /// < interleaved chroma YUV 4:4:4, 30bpp, data in the high bits, little-endian
  AV_PIX_FMT_P410LE(200),

  /// < interleaved chroma YUV 4:2:2, 32bpp, big-endian
  AV_PIX_FMT_P216BE(201),

  /// < interleaved chroma YUV 4:2:2, 32bpp, little-endian
  AV_PIX_FMT_P216LE(202),

  /// < interleaved chroma YUV 4:4:4, 48bpp, big-endian
  AV_PIX_FMT_P416BE(203),

  /// < interleaved chroma YUV 4:4:4, 48bpp, little-endian
  AV_PIX_FMT_P416LE(204),

  /// < packed VUYA 4:4:4, 32bpp, VUYAVUYA...
  AV_PIX_FMT_VUYA(205),

  /// < IEEE-754 half precision packed RGBA 16:16:16:16, 64bpp, RGBARGBA..., big-endian
  AV_PIX_FMT_RGBAF16BE(206),

  /// < IEEE-754 half precision packed RGBA 16:16:16:16, 64bpp, RGBARGBA..., little-endian
  AV_PIX_FMT_RGBAF16LE(207),

  /// < packed VUYX 4:4:4, 32bpp, Variant of VUYA where alpha channel is left undefined
  AV_PIX_FMT_VUYX(208),

  /// < like NV12, with 12bpp per component, data in the high bits, zeros in the low bits, little-endian
  AV_PIX_FMT_P012LE(209),

  /// < like NV12, with 12bpp per component, data in the high bits, zeros in the low bits, big-endian
  AV_PIX_FMT_P012BE(210),

  /// < packed YUV 4:2:2 like YUYV422, 24bpp, data in the high bits, zeros in the low bits, big-endian
  AV_PIX_FMT_Y212BE(211),

  /// < packed YUV 4:2:2 like YUYV422, 24bpp, data in the high bits, zeros in the low bits, little-endian
  AV_PIX_FMT_Y212LE(212),

  /// < packed XVYU 4:4:4, 32bpp, (msb)2X 10V 10Y 10U(lsb), big-endian, variant of Y410 where alpha channel is left undefined
  AV_PIX_FMT_XV30BE(213),

  /// < packed XVYU 4:4:4, 32bpp, (msb)2X 10V 10Y 10U(lsb), little-endian, variant of Y410 where alpha channel is left undefined
  AV_PIX_FMT_XV30LE(214),

  /// < packed XVYU 4:4:4, 48bpp, data in the high bits, zeros in the low bits, big-endian, variant of Y412 where alpha channel is left undefined
  AV_PIX_FMT_XV36BE(215),

  /// < packed XVYU 4:4:4, 48bpp, data in the high bits, zeros in the low bits, little-endian, variant of Y412 where alpha channel is left undefined
  AV_PIX_FMT_XV36LE(216),

  /// < IEEE-754 single precision packed RGB 32:32:32, 96bpp, RGBRGB..., big-endian
  AV_PIX_FMT_RGBF32BE(217),

  /// < IEEE-754 single precision packed RGB 32:32:32, 96bpp, RGBRGB..., little-endian
  AV_PIX_FMT_RGBF32LE(218),

  /// < IEEE-754 single precision packed RGBA 32:32:32:32, 128bpp, RGBARGBA..., big-endian
  AV_PIX_FMT_RGBAF32BE(219),

  /// < IEEE-754 single precision packed RGBA 32:32:32:32, 128bpp, RGBARGBA..., little-endian
  AV_PIX_FMT_RGBAF32LE(220),

  /// < interleaved chroma YUV 4:2:2, 24bpp, data in the high bits, big-endian
  AV_PIX_FMT_P212BE(221),

  /// < interleaved chroma YUV 4:2:2, 24bpp, data in the high bits, little-endian
  AV_PIX_FMT_P212LE(222),

  /// < interleaved chroma YUV 4:4:4, 36bpp, data in the high bits, big-endian
  AV_PIX_FMT_P412BE(223),

  /// < interleaved chroma YUV 4:4:4, 36bpp, data in the high bits, little-endian
  AV_PIX_FMT_P412LE(224),

  /// < planar GBR 4:4:4:4 56bpp, big-endian
  AV_PIX_FMT_GBRAP14BE(225),

  /// < planar GBR 4:4:4:4 56bpp, little-endian
  AV_PIX_FMT_GBRAP14LE(226),

  /// Hardware surfaces for Direct3D 12.
  ///
  /// data[0] points to an AVD3D12VAFrame
  AV_PIX_FMT_D3D12(227),

  /// < number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions
  AV_PIX_FMT_NB(228);

  /// < alias for AV_PIX_FMT_YA8
  static const AV_PIX_FMT_Y400A = AV_PIX_FMT_YA8;

  /// < alias for AV_PIX_FMT_YA8
  static const AV_PIX_FMT_GRAY8A = AV_PIX_FMT_YA8;
  static const AV_PIX_FMT_GBR24P = AV_PIX_FMT_GBRP;

  final int value;
  const AVPixelFormat(this.value);

  static AVPixelFormat fromValue(int value) => switch (value) {
        -1 => AV_PIX_FMT_NONE,
        0 => AV_PIX_FMT_YUV420P,
        1 => AV_PIX_FMT_YUYV422,
        2 => AV_PIX_FMT_RGB24,
        3 => AV_PIX_FMT_BGR24,
        4 => AV_PIX_FMT_YUV422P,
        5 => AV_PIX_FMT_YUV444P,
        6 => AV_PIX_FMT_YUV410P,
        7 => AV_PIX_FMT_YUV411P,
        8 => AV_PIX_FMT_GRAY8,
        9 => AV_PIX_FMT_MONOWHITE,
        10 => AV_PIX_FMT_MONOBLACK,
        11 => AV_PIX_FMT_PAL8,
        12 => AV_PIX_FMT_YUVJ420P,
        13 => AV_PIX_FMT_YUVJ422P,
        14 => AV_PIX_FMT_YUVJ444P,
        15 => AV_PIX_FMT_UYVY422,
        16 => AV_PIX_FMT_UYYVYY411,
        17 => AV_PIX_FMT_BGR8,
        18 => AV_PIX_FMT_BGR4,
        19 => AV_PIX_FMT_BGR4_BYTE,
        20 => AV_PIX_FMT_RGB8,
        21 => AV_PIX_FMT_RGB4,
        22 => AV_PIX_FMT_RGB4_BYTE,
        23 => AV_PIX_FMT_NV12,
        24 => AV_PIX_FMT_NV21,
        25 => AV_PIX_FMT_ARGB,
        26 => AV_PIX_FMT_RGBA,
        27 => AV_PIX_FMT_ABGR,
        28 => AV_PIX_FMT_BGRA,
        29 => AV_PIX_FMT_GRAY16BE,
        30 => AV_PIX_FMT_GRAY16LE,
        31 => AV_PIX_FMT_YUV440P,
        32 => AV_PIX_FMT_YUVJ440P,
        33 => AV_PIX_FMT_YUVA420P,
        34 => AV_PIX_FMT_RGB48BE,
        35 => AV_PIX_FMT_RGB48LE,
        36 => AV_PIX_FMT_RGB565BE,
        37 => AV_PIX_FMT_RGB565LE,
        38 => AV_PIX_FMT_RGB555BE,
        39 => AV_PIX_FMT_RGB555LE,
        40 => AV_PIX_FMT_BGR565BE,
        41 => AV_PIX_FMT_BGR565LE,
        42 => AV_PIX_FMT_BGR555BE,
        43 => AV_PIX_FMT_BGR555LE,
        44 => AV_PIX_FMT_VAAPI,
        45 => AV_PIX_FMT_YUV420P16LE,
        46 => AV_PIX_FMT_YUV420P16BE,
        47 => AV_PIX_FMT_YUV422P16LE,
        48 => AV_PIX_FMT_YUV422P16BE,
        49 => AV_PIX_FMT_YUV444P16LE,
        50 => AV_PIX_FMT_YUV444P16BE,
        51 => AV_PIX_FMT_DXVA2_VLD,
        52 => AV_PIX_FMT_RGB444LE,
        53 => AV_PIX_FMT_RGB444BE,
        54 => AV_PIX_FMT_BGR444LE,
        55 => AV_PIX_FMT_BGR444BE,
        56 => AV_PIX_FMT_YA8,
        57 => AV_PIX_FMT_BGR48BE,
        58 => AV_PIX_FMT_BGR48LE,
        59 => AV_PIX_FMT_YUV420P9BE,
        60 => AV_PIX_FMT_YUV420P9LE,
        61 => AV_PIX_FMT_YUV420P10BE,
        62 => AV_PIX_FMT_YUV420P10LE,
        63 => AV_PIX_FMT_YUV422P10BE,
        64 => AV_PIX_FMT_YUV422P10LE,
        65 => AV_PIX_FMT_YUV444P9BE,
        66 => AV_PIX_FMT_YUV444P9LE,
        67 => AV_PIX_FMT_YUV444P10BE,
        68 => AV_PIX_FMT_YUV444P10LE,
        69 => AV_PIX_FMT_YUV422P9BE,
        70 => AV_PIX_FMT_YUV422P9LE,
        71 => AV_PIX_FMT_GBRP,
        72 => AV_PIX_FMT_GBRP9BE,
        73 => AV_PIX_FMT_GBRP9LE,
        74 => AV_PIX_FMT_GBRP10BE,
        75 => AV_PIX_FMT_GBRP10LE,
        76 => AV_PIX_FMT_GBRP16BE,
        77 => AV_PIX_FMT_GBRP16LE,
        78 => AV_PIX_FMT_YUVA422P,
        79 => AV_PIX_FMT_YUVA444P,
        80 => AV_PIX_FMT_YUVA420P9BE,
        81 => AV_PIX_FMT_YUVA420P9LE,
        82 => AV_PIX_FMT_YUVA422P9BE,
        83 => AV_PIX_FMT_YUVA422P9LE,
        84 => AV_PIX_FMT_YUVA444P9BE,
        85 => AV_PIX_FMT_YUVA444P9LE,
        86 => AV_PIX_FMT_YUVA420P10BE,
        87 => AV_PIX_FMT_YUVA420P10LE,
        88 => AV_PIX_FMT_YUVA422P10BE,
        89 => AV_PIX_FMT_YUVA422P10LE,
        90 => AV_PIX_FMT_YUVA444P10BE,
        91 => AV_PIX_FMT_YUVA444P10LE,
        92 => AV_PIX_FMT_YUVA420P16BE,
        93 => AV_PIX_FMT_YUVA420P16LE,
        94 => AV_PIX_FMT_YUVA422P16BE,
        95 => AV_PIX_FMT_YUVA422P16LE,
        96 => AV_PIX_FMT_YUVA444P16BE,
        97 => AV_PIX_FMT_YUVA444P16LE,
        98 => AV_PIX_FMT_VDPAU,
        99 => AV_PIX_FMT_XYZ12LE,
        100 => AV_PIX_FMT_XYZ12BE,
        101 => AV_PIX_FMT_NV16,
        102 => AV_PIX_FMT_NV20LE,
        103 => AV_PIX_FMT_NV20BE,
        104 => AV_PIX_FMT_RGBA64BE,
        105 => AV_PIX_FMT_RGBA64LE,
        106 => AV_PIX_FMT_BGRA64BE,
        107 => AV_PIX_FMT_BGRA64LE,
        108 => AV_PIX_FMT_YVYU422,
        109 => AV_PIX_FMT_YA16BE,
        110 => AV_PIX_FMT_YA16LE,
        111 => AV_PIX_FMT_GBRAP,
        112 => AV_PIX_FMT_GBRAP16BE,
        113 => AV_PIX_FMT_GBRAP16LE,
        114 => AV_PIX_FMT_QSV,
        115 => AV_PIX_FMT_MMAL,
        116 => AV_PIX_FMT_D3D11VA_VLD,
        117 => AV_PIX_FMT_CUDA,
        118 => AV_PIX_FMT_0RGB,
        119 => AV_PIX_FMT_RGB0,
        120 => AV_PIX_FMT_0BGR,
        121 => AV_PIX_FMT_BGR0,
        122 => AV_PIX_FMT_YUV420P12BE,
        123 => AV_PIX_FMT_YUV420P12LE,
        124 => AV_PIX_FMT_YUV420P14BE,
        125 => AV_PIX_FMT_YUV420P14LE,
        126 => AV_PIX_FMT_YUV422P12BE,
        127 => AV_PIX_FMT_YUV422P12LE,
        128 => AV_PIX_FMT_YUV422P14BE,
        129 => AV_PIX_FMT_YUV422P14LE,
        130 => AV_PIX_FMT_YUV444P12BE,
        131 => AV_PIX_FMT_YUV444P12LE,
        132 => AV_PIX_FMT_YUV444P14BE,
        133 => AV_PIX_FMT_YUV444P14LE,
        134 => AV_PIX_FMT_GBRP12BE,
        135 => AV_PIX_FMT_GBRP12LE,
        136 => AV_PIX_FMT_GBRP14BE,
        137 => AV_PIX_FMT_GBRP14LE,
        138 => AV_PIX_FMT_YUVJ411P,
        139 => AV_PIX_FMT_BAYER_BGGR8,
        140 => AV_PIX_FMT_BAYER_RGGB8,
        141 => AV_PIX_FMT_BAYER_GBRG8,
        142 => AV_PIX_FMT_BAYER_GRBG8,
        143 => AV_PIX_FMT_BAYER_BGGR16LE,
        144 => AV_PIX_FMT_BAYER_BGGR16BE,
        145 => AV_PIX_FMT_BAYER_RGGB16LE,
        146 => AV_PIX_FMT_BAYER_RGGB16BE,
        147 => AV_PIX_FMT_BAYER_GBRG16LE,
        148 => AV_PIX_FMT_BAYER_GBRG16BE,
        149 => AV_PIX_FMT_BAYER_GRBG16LE,
        150 => AV_PIX_FMT_BAYER_GRBG16BE,
        151 => AV_PIX_FMT_YUV440P10LE,
        152 => AV_PIX_FMT_YUV440P10BE,
        153 => AV_PIX_FMT_YUV440P12LE,
        154 => AV_PIX_FMT_YUV440P12BE,
        155 => AV_PIX_FMT_AYUV64LE,
        156 => AV_PIX_FMT_AYUV64BE,
        157 => AV_PIX_FMT_VIDEOTOOLBOX,
        158 => AV_PIX_FMT_P010LE,
        159 => AV_PIX_FMT_P010BE,
        160 => AV_PIX_FMT_GBRAP12BE,
        161 => AV_PIX_FMT_GBRAP12LE,
        162 => AV_PIX_FMT_GBRAP10BE,
        163 => AV_PIX_FMT_GBRAP10LE,
        164 => AV_PIX_FMT_MEDIACODEC,
        165 => AV_PIX_FMT_GRAY12BE,
        166 => AV_PIX_FMT_GRAY12LE,
        167 => AV_PIX_FMT_GRAY10BE,
        168 => AV_PIX_FMT_GRAY10LE,
        169 => AV_PIX_FMT_P016LE,
        170 => AV_PIX_FMT_P016BE,
        171 => AV_PIX_FMT_D3D11,
        172 => AV_PIX_FMT_GRAY9BE,
        173 => AV_PIX_FMT_GRAY9LE,
        174 => AV_PIX_FMT_GBRPF32BE,
        175 => AV_PIX_FMT_GBRPF32LE,
        176 => AV_PIX_FMT_GBRAPF32BE,
        177 => AV_PIX_FMT_GBRAPF32LE,
        178 => AV_PIX_FMT_DRM_PRIME,
        179 => AV_PIX_FMT_OPENCL,
        180 => AV_PIX_FMT_GRAY14BE,
        181 => AV_PIX_FMT_GRAY14LE,
        182 => AV_PIX_FMT_GRAYF32BE,
        183 => AV_PIX_FMT_GRAYF32LE,
        184 => AV_PIX_FMT_YUVA422P12BE,
        185 => AV_PIX_FMT_YUVA422P12LE,
        186 => AV_PIX_FMT_YUVA444P12BE,
        187 => AV_PIX_FMT_YUVA444P12LE,
        188 => AV_PIX_FMT_NV24,
        189 => AV_PIX_FMT_NV42,
        190 => AV_PIX_FMT_VULKAN,
        191 => AV_PIX_FMT_Y210BE,
        192 => AV_PIX_FMT_Y210LE,
        193 => AV_PIX_FMT_X2RGB10LE,
        194 => AV_PIX_FMT_X2RGB10BE,
        195 => AV_PIX_FMT_X2BGR10LE,
        196 => AV_PIX_FMT_X2BGR10BE,
        197 => AV_PIX_FMT_P210BE,
        198 => AV_PIX_FMT_P210LE,
        199 => AV_PIX_FMT_P410BE,
        200 => AV_PIX_FMT_P410LE,
        201 => AV_PIX_FMT_P216BE,
        202 => AV_PIX_FMT_P216LE,
        203 => AV_PIX_FMT_P416BE,
        204 => AV_PIX_FMT_P416LE,
        205 => AV_PIX_FMT_VUYA,
        206 => AV_PIX_FMT_RGBAF16BE,
        207 => AV_PIX_FMT_RGBAF16LE,
        208 => AV_PIX_FMT_VUYX,
        209 => AV_PIX_FMT_P012LE,
        210 => AV_PIX_FMT_P012BE,
        211 => AV_PIX_FMT_Y212BE,
        212 => AV_PIX_FMT_Y212LE,
        213 => AV_PIX_FMT_XV30BE,
        214 => AV_PIX_FMT_XV30LE,
        215 => AV_PIX_FMT_XV36BE,
        216 => AV_PIX_FMT_XV36LE,
        217 => AV_PIX_FMT_RGBF32BE,
        218 => AV_PIX_FMT_RGBF32LE,
        219 => AV_PIX_FMT_RGBAF32BE,
        220 => AV_PIX_FMT_RGBAF32LE,
        221 => AV_PIX_FMT_P212BE,
        222 => AV_PIX_FMT_P212LE,
        223 => AV_PIX_FMT_P412BE,
        224 => AV_PIX_FMT_P412LE,
        225 => AV_PIX_FMT_GBRAP14BE,
        226 => AV_PIX_FMT_GBRAP14LE,
        227 => AV_PIX_FMT_D3D12,
        228 => AV_PIX_FMT_NB,
        _ => throw ArgumentError("Unknown value for AVPixelFormat: $value"),
      };

  @override
  String toString() {
    if (this == AV_PIX_FMT_YA8)
      return "AVPixelFormat.AV_PIX_FMT_YA8, AVPixelFormat.AV_PIX_FMT_Y400A, AVPixelFormat.AV_PIX_FMT_GRAY8A";
    if (this == AV_PIX_FMT_GBRP)
      return "AVPixelFormat.AV_PIX_FMT_GBRP, AVPixelFormat.AV_PIX_FMT_GBR24P";
    return super.toString();
  }
}

/// Audio sample formats
///
/// - The data described by the sample format is always in native-endian order.
/// Sample values can be expressed by native C types, hence the lack of a signed
/// 24-bit sample format even though it is a common raw audio data format.
///
/// - The floating-point formats are based on full volume being in the range
/// [-1.0, 1.0]. Any values outside this range are beyond full volume level.
///
/// - The data layout as used in av_samples_fill_arrays() and elsewhere in FFmpeg
/// (such as AVFrame in libavcodec) is as follows:
///
/// @par
/// For planar sample formats, each audio channel is in a separate data plane,
/// and linesize is the buffer size, in bytes, for a single plane. All data
/// planes must be the same size. For packed sample formats, only the first data
/// plane is used, and samples for each channel are interleaved. In this case,
/// linesize is the buffer size, in bytes, for the 1 plane.
enum AVSampleFormat {
  AV_SAMPLE_FMT_NONE(-1),

  /// < unsigned 8 bits
  AV_SAMPLE_FMT_U8(0),

  /// < signed 16 bits
  AV_SAMPLE_FMT_S16(1),

  /// < signed 32 bits
  AV_SAMPLE_FMT_S32(2),

  /// < float
  AV_SAMPLE_FMT_FLT(3),

  /// < double
  AV_SAMPLE_FMT_DBL(4),

  /// < unsigned 8 bits, planar
  AV_SAMPLE_FMT_U8P(5),

  /// < signed 16 bits, planar
  AV_SAMPLE_FMT_S16P(6),

  /// < signed 32 bits, planar
  AV_SAMPLE_FMT_S32P(7),

  /// < float, planar
  AV_SAMPLE_FMT_FLTP(8),

  /// < double, planar
  AV_SAMPLE_FMT_DBLP(9),

  /// < signed 64 bits
  AV_SAMPLE_FMT_S64(10),

  /// < signed 64 bits, planar
  AV_SAMPLE_FMT_S64P(11),

  /// < Number of sample formats. DO NOT USE if linking dynamically
  AV_SAMPLE_FMT_NB(12);

  final int value;
  const AVSampleFormat(this.value);

  static AVSampleFormat fromValue(int value) => switch (value) {
        -1 => AV_SAMPLE_FMT_NONE,
        0 => AV_SAMPLE_FMT_U8,
        1 => AV_SAMPLE_FMT_S16,
        2 => AV_SAMPLE_FMT_S32,
        3 => AV_SAMPLE_FMT_FLT,
        4 => AV_SAMPLE_FMT_DBL,
        5 => AV_SAMPLE_FMT_U8P,
        6 => AV_SAMPLE_FMT_S16P,
        7 => AV_SAMPLE_FMT_S32P,
        8 => AV_SAMPLE_FMT_FLTP,
        9 => AV_SAMPLE_FMT_DBLP,
        10 => AV_SAMPLE_FMT_S64,
        11 => AV_SAMPLE_FMT_S64P,
        12 => AV_SAMPLE_FMT_NB,
        _ => throw ArgumentError("Unknown value for AVSampleFormat: $value"),
      };
}

/// AVProfile.
final class AVProfile extends ffi.Struct {
  @ffi.Int()
  external int profile;

  /// < short name for the profile
  external ffi.Pointer<ffi.Char> name;
}

const int AV_NOPTS_VALUE = -9223372036854775808;

const int AVIO_FLAG_WRITE = 2;
